# 马尔可夫链

```python
%reset -f
import numpy as np
import matplotlib.pyplot as plt
np.set_printoptions(precision=3, suppress=True)
plt.style.use("default")
from IPython.display import Image
```

## 定义与示例

### 直观定义

**注意：** “马尔可夫链”这一术语在这里特指“时间上齐次的马尔可夫链”。

我们给定一个可数集 $E$：状态的集合。例如 $E = \{0, 1, 2, 3, 4, 5\}$。我们认为 $E$ 中的元素是一个图的顶点，箭头带有权重。

马尔可夫链 $t \to X_t$ 是一个随机过程，它在这个图上随机游走。在时间 $t = 0$ 时，它位于给定的顶点 $X_0$。如果在时间 $t$ 时它位于 $X_t$，它会以与权重成比例的概率选择从 $X_t$ 出发的一条箭头，并沿着这条箭头到达一个新的状态 $X_{t+1}$。

具体来说，设 $w_{x,y}$ 为从状态 $x$ 到状态 $y$ 的权重，则转移概率为：
$$
P(x,y) = \frac{w_{x,y}}{\sum_u w_{x,u}}
$$
这样，我们对权重进行了归一化，马尔可夫链满足
$$
\mathbf{P}[X_{t+1} = y \mid X_t = x] = P(x,y)
$$
自然地，如果 $x$ 和 $y$ 之间没有箭头，则 $P(x,y) = 0$。矩阵 $\big ( P(x,y) \big )_{x,y \in E}$ 被称为转移矩阵。

**备注：** 在前面的程序中，我们对转移矩阵 `P` 提供了多种归一化方法。请选择您喜欢的方法，但要注意避免使用循环（个人偏好 `np.newaxis`）。

**练习：** 在前面的图中，某一条箭头缺少权重。请问这个权重是多少？（标记为 $(1\heartsuit)$）

```python
# 返回与前图对应的转移矩阵
def premiere_chaine():
    P = np.zeros([6, 6])
    P[0, 3] = 4
    P[1, 0] = 2.1
    P[2, 1] = 2.5
    P[3, 1] = 3
    P[3, 4] = 2
    P[4, 1] = 2
    P[4, 2] = 0.2
    P[4, 5] = 6
    P[5, 2] = 7.3
    sumLine = np.sum(P, axis=1)
    """ 归一化 """
    P /= sumLine[:, np.newaxis]
    # 或者使用 P /= np.expand_dims(sumLine, axis=1)
    # 或者使用 P /= sumLine.reshape([-1,1])
    # 或者使用 for 循环归一化每一行
    return P

print(premiere_chaine())
```

***备注：*** 在前面的程序中，我提供了多种归一化 `P` 的方法。请选择您喜欢的方法，但要注意避免使用循环（个人偏好 `np.newaxis`）。

***练习：*** 在前面的图中，某一条箭头缺少权重。请问这个权重是多少？（标记为 $(1\heartsuit)$）

### 随机游走

随机游走是具有一定空间均匀性的马尔可夫链。以下是一些例子：

- **简单随机游走** 在 $E = \mathbb{Z}$ 上：以概率 $\frac{1}{2}$ 向上移动 1，或以概率 $\frac{1}{2}$ 向下移动 1。
  
- **非简单随机游走**：移动方式和概率更复杂。例如，可能的跳跃为 $\{+1, +2, -1\}$ ，概率分别为 $\{1/3, 1/3, 1/3\}$。

- **在 $E = \{0, 1, \ldots, n-1\}$ 上的简单吸收随机游走**：以概率 $\frac{1}{2}$ 向上或向下移动。一旦到达 0 或 $n-1$，便停留在该状态。

- **在 $E = \{0, 1, \ldots, n-1\}$ 上的简单反射随机游走**：以概率 $\frac{1}{2}$ 向上或向下移动。一旦到达 0，则向上移动到 1；一旦到达 $n-1$，则向下移动到 $n-2$。

**推广：** 我们还可以想象在 $\mathbb{R}$ 上的随机游走（例如高斯跳跃），但这超出了经典范围。

让我们模拟这些随机游走。对于在 $E = \{0, 1, \ldots, n-1\}$ 上的游走，我们首先定义转移矩阵。对于在 $\mathbb{Z}$ 上的游走，则使用“转移机制”。

```python
# 定义一个从转移矩阵模拟马尔可夫链的函数
def markov_from_P(t_max, P, x0):
    X = np.zeros(t_max, dtype=int)
    X[0] = x0
    for t in range(t_max - 1):
        X[t + 1] = np.random.choice(a=range(len(P)), p=P[X[t], :])
    return X

t_max = 150
P = premiere_chaine()
X = markov_from_P(t_max, P, 3)
plt.figure(figsize=(10, 3))
plt.plot(range(t_max), X, ".-")
plt.grid()
```

#### ♡

***练习：*** 通过肉眼观察，哪些状态被访问得最多？（标记为 $(1\heartsuit)$）我们能否通过观察图形推断出来？

**解答：**

观察到状态 0、1 和 3 被访问得最多。这并不完全显而易见，但我们可以注意到以下几点：

- 状态 1 是被指向最多的状态，具有相对较高的总权重。
- 状态 0 和 3 总是在状态 1 之后被访问。

### 马尔可夫链的正式定义

我们将以更数学化的方式重新定义马尔可夫链。

**定义：** 一个一般的马尔可夫链在 $E$ 上是一个随机过程 $t \to X_t$，它在 $t = 0$ 时取一个给定的值 $X_0$（可能是随机的），然后由方程控制：
$$
X_{t+1} = f_{t+1}(X_t, U_{t+1})
$$
其中

- $f_{t+1}$ 是一个取值在 $E$ 上的函数
- $U_{t+1}$ 是与之前所有随机抽样独立的随机变量，即与 $X_0, U_1, U_2, \ldots, U_t$ 独立。

如果 $f_t$ 不依赖于时间 $t$，则称为时间上齐次的马尔可夫链。对于大多数情况，“马尔可夫链”一词默认为“时间上齐次的马尔可夫链”。

转移矩阵定义为
$$
P_{t+1}(x,y) = \mathbf{P}[X_{t+1} = y \mid X_t = x]
$$
对于时间齐次的情况：对于所有 $t$，有 $P_t(x,y) = P_1(x,y)$。

#### ♡♡

**练习：** 在最初的直观定义中，我们讨论的是时间上齐次的马尔可夫链还是非齐次的？请简要说明理由。

**解答：**

在最初的直观定义中，我们讨论的是时间上齐次的马尔可夫链。因为转移概率 $P(x,y)$ 是固定的，并不随时间变化，这意味着每一步的转移规则相同，因此是齐次的。

### 基本性质

**定理：** 设 $t \to X_t$ 是一个一般的马尔可夫链。则 $X_{t+1}$ 的分布在给定 $X_t$ 时，与 $X_0, X_1, \ldots, X_{t-1}$ 无关，即：
$$
\mathbf{P}[X_{t+1} = x_{t+1} \mid X_t = x_t, X_{t-1} = x_{t-1}, \ldots, X_0 = x_0] = \mathbf{P}[X_{t+1} = x_{t+1} \mid X_t = x_t]
$$
如果此外它是时间上齐次的，那么
$$
\mathbf{P}[X_{t+1} = y \mid X_t = x] = \mathbf{P}[X_1 = y \mid X_0 = x]
$$
该定理有一个逆命题：如果一个过程 $(X_t)$ 满足上述条件，则它是一个一般的马尔可夫链。如果再满足第二个条件，则它是一个时间上齐次的马尔可夫链。

**注意：** 通常，我们使用条件独立性来定义马尔可夫链。我的定义更接近实践：马尔可夫链总是通过类似于 $X_{t+1} = f_{t+1}(X_t, U_{t+1})$ 的方程构建的，其中 $U_{t+1}$ 通常表示随机数生成器。例如，在模拟我们的第一个马尔可夫链的程序中，我们使用了：
```python
X[t + 1] = np.random.choice(a=range(6), p=P[X[t], :])
          = function(X[t], rand())
```
其中 `rand()` 代表计算机的随机数生成器，每次调用生成一个独立的 [0,1] 之间的均匀实数。

### 术语的模糊性

在我们之前的定义中，一个马尔可夫链 $(X_t)$ 是一个由初始分布 $\mu_0$ 和转移核 $P$ 参数化的随机过程。

然而，“马尔可夫链”这个词也常被用来指所有从每个状态 $x \in E$ 出发并具有转移矩阵 $P$ 的过程集合 $(X^x_t, x \in E)$。起始点的具体性也可以通过条件化来进一步明确：
$$
\mathbf{E}[f(X^x_t)] = \mathbf{E}[f(X_t) \mid X_0 = x]
$$
由于大多数作者省略了术语的严格定义，我们也采用这种模糊性。上下文通常能帮助理解具体指的是什么（这是人类的常态 😀）。

## 度量与函数

在马尔可夫链理论中：

- 行向量被视为 $E$ 上的度量（measure）。
- 列向量被视为 $E$ 上的函数。

例如，考虑一个初始分布 $\mu_0$ 的马尔可夫链 $X$ 及其转移矩阵 $P$。我们希望将 $\mu_0$ 视为一个行向量，以便进行矩阵乘法：
$$
\mu_0 P (y) = \sum_x \mu_0(x) P(x,y) = \sum_x \mathbf{P}[X_0 = x] \cdot \mathbf{P}[X_1 = y \mid X_0 = x] = \mathbf{P}[X_1 = y]
$$
同样，如果 $\mu_t$ 是 $X_t$ 的分布，那么 $\mu_t P$ 就是 $X_{t+1}$ 的分布。递归地，$X_t$ 的分布由 $\mu_0 P^t$ 给出。

特别地，当 $\mu_0 = \delta_x$ 时，我们有
$$
P^t(x,y) = \mathbf{P}[X_t = y \mid X_0 = x]
$$

另一方面，列向量可以看作是 $E$ 上的函数。例如，设 $f$ 是 $E$ 上的一个列向量，我们可以计算：
$$
(P^t f)(x) = \sum_y P^t(x,y) f(y) = \mathbf{E}[f(X_t) \mid X_0 = x]
$$
或者
$$
\mu_0 P^t f = \mathbf{E}[f(X_t)]
$$

某些度量和函数特别重要：

- **不变度量** 满足 $\pi P = \pi$。
- **不变函数** 满足 $P\gamma = \gamma$，其中最著名的是常数函数 1。

我们将在后面详细讨论这些内容。

## 不变度量

### 不变度量的定义

**定义：** 一个不变度量是一个正向量 $\pi$ 满足 $\pi P = \pi$，即
$$
\forall y \in E, \quad \sum_x \pi(x) P(x,y) = \pi(y)
$$
如果 $\pi$ 还满足 $\sum_{x \in E} \pi(x) = 1$，则称为**不变概率**。

**定理：** 总存在一个不变度量。

**推论：** 当 $E$ 是有限集时，总存在一个不变概率分布：只需将一个不变度量 $\pi$ 归一化，即除以其总和 $\sum_x \pi(x)$。

#### ♡♡♡

**练习：** 重新考虑简单随机游走在 $\mathbb{Z}$ 上。给出一个不变度量（尝试用一个非常简单的 $\pi$ 解这个系统）。是否可以将其归一化为一个不变概率？对于非简单随机游走在 $\mathbb{Z}$ 上情况如何？

**解答：**

对于简单随机游走在 $\mathbb{Z}$ 上，每个状态的转移概率是对称的，即向左和向右的概率相等。因此，一个自然的不变度量是所有状态的概率相等。然而，由于 $\mathbb{Z}$ 是无限的，这个度量无法归一化为一个概率分布。因此，对于无限状态空间，可能存在不变度量但无法将其归一化为概率。

对于非简单随机游走，情况类似，具体取决于转移概率的对称性和状态空间的性质。

### 有限情况

让我们假设状态空间 $E$ 是有限的。

#### ♡♡

**练习：** 找出一个线性代数的方法来证明不变度量的存在。提示：转移矩阵 $P$ 有一个非常容易找到的右特征向量。

**解答：**

可以利用线性代数中的特征值问题。由于 $P$ 是一个转移矩阵，每行之和为 1，因此 $P^T$ 总有一个特征值为 1。对应于这个特征值的右特征向量就是不变度量。由于 $E$ 是有限的，根据定理，总存在至少一个不变度量。通过将这个不变度量归一化，可以得到一个不变概率分布。

```python
""" 计算我们第一个马尔可夫链的唯一不变概率分布 """
def proba_invariante(P):
    val_pr, vec_pr = np.linalg.eig(P.T)
    val_pr = np.real(val_pr)
    vec_pr = np.real(vec_pr)
    pi = vec_pr[:, 0]
    pi /= np.sum(pi)
    return pi

P = premiere_chaine()
pi = proba_invariante(P)
plt.bar(range(6), pi);
```

#### ♡♡

**评论：**

- 为什么要转置矩阵 $P$ 在 `np.linalg.eig(P.T)` 中？因为我们需要找到右特征向量，即 $\pi P = \pi$，对应于 $P^T$ 的左特征向量。
- 我们使用 `np.real` 是因为在数值计算中，可能会得到复数的结果，而实际的不变度量应为实数。
- 我们通过除以 $\pi$ 的总和 `np.sum(pi)` 来归一化，以确保 $\pi$ 成为一个概率分布。

#### ♡♡♡♡

**练习：** 上述程序在稳健性方面存在问题。特征值分解算法并不保证最大特征值（这里是 1）位于第一位。请修改此程序以提高其稳健性。

**解答：**

为了确保选择的是特征值为 1 的特征向量，我们可以寻找所有特征值中最接近 1 的那个，并选择对应的特征向量。此外，还可以使用 `np.isclose` 来判断哪些特征值接近 1。

```python
def proba_invariante_robuste(P):
    val_pr, vec_pr = np.linalg.eig(P.T)
    val_pr = np.real(val_pr)
    vec_pr = np.real(vec_pr)
    # 找到最接近 1 的特征值
    index = np.argmin(np.abs(val_pr - 1))
    pi = vec_pr[:, index]
    # 保证所有元素非负
    pi = np.abs(pi)
    pi /= np.sum(pi)
    return pi

pi = proba_invariante_robuste(P)
plt.bar(range(6), pi);
```

## 状态停留时间

### 埃尔戈德定理

**注意：** 从现在开始，直到另有说明，我们假设状态空间 $E$ 是有限的。稍后我们将讨论无限状态空间带来的困难，特别是引入了瞬态/重现的二分法。

当一个图是**不可约的**时，意味着从任何一个状态总能通过箭头到达另一个状态。一个马尔可夫链是不可约的，当且仅当其图是不可约的。

**定理：** 当一个有限的马尔可夫链是不可约的时，它只有一个不变度量，且该不变度量在乘以常数后唯一。因此，存在唯一的不变概率分布。

*备注：* 从线性代数的角度来看，这个定理表明对应于特征值 1 的特征空间的维度为 1。

现在设 $X^x_t$ 是从状态 $x$ 出发的马尔可夫链。记
$$
\Gamma_{T}^x(y) = \frac{1}{T} \sum_{t=0}^{T-1} 1_{\{X^x_t = y\}}
$$
这是从 $x$ 出发，在时间 $T$ 内平均停留在状态 $y$ 的时间。

**埃尔戈德定理：** 当 $T$ 趋近于无穷时：

- $\Gamma_{T}^x$ 收敛于一个不变概率分布。
- 特别地，当链是不可约的时，$\Gamma_{T}^x$ 收敛于唯一的不变概率分布。

通常，我们称这个定理为“马尔可夫链的强大数定律”。

### 与大数定律的联系

寻找一个特殊的马尔可夫链，使得埃尔戈德定理简化为大数定律。

考虑 $(X_t)$ 是一组独立同分布（i.i.d.）的随机变量，且分布为 $\nu$。这显然是一个马尔可夫链：其转移矩阵 $P$ 是所有行都等于 $\nu$ 的矩阵。我们注意到 $\nu P = \nu$，因此 $\nu$ 是一个不变概率分布。

埃尔戈德定理告诉我们：
$$
\frac{1}{T} \sum_{t=0}^{T-1} 1_{X_t = y} \to \nu(y)
$$
这表明时间平均收敛于期望。

我们可以对一个函数 $f$ 求和：
$$
\frac{1}{T} \sum_{t=0}^{T-1} \sum_y f(y) 1_{X_t = y} \to \sum_y f(y) \nu(y)
$$
即
$$
\frac{1}{T} \sum_{t=0}^{T-1} f(X_t) \to \mathbf{E}[f(X_0)]
$$
这就是大数定律的一种形式（稍作推广）。

### 数值示例

让我们用数值方法来展示埃尔戈德定理：

```python
t_max = 5000
P = premiere_chaine()
pi = proba_invariante(P)
X = markov_from_P(t_max, P, 3)
ts = [50, 100, 200, 400]

Gamma = np.zeros((6, len(ts) + 1))
Gamma[:, -1] = pi

for i in range(6):
    for j, t in enumerate(ts):
        Gamma[i, j] = np.mean(X[:t] == i)

import pandas as pd
df = pd.DataFrame(data=Gamma, columns=ts + ["∞"])
df
```

注意，为了计算在时间点 $T_1, T_2, \ldots, T_{\text{max}}$ 的平均值，必须对同一个马尔可夫链进行计算（从 0 到 $T_{\text{max}}$ 的模拟），而不是分别模拟从 0 到 $T_1$、0 到 $T_2$ 等多个链。

## 小结

本部分介绍了马尔可夫链的基本定义、性质以及一些具体的例子和数值模拟。通过定义不变度量和不变概率分布，并结合埃尔戈德定理，我们理解了马尔可夫链在长期行为上的稳定性。数值示例进一步验证了理论结果，展示了时间平均趋向于不变概率分布的现象。

在后续部分，我们将探讨无限状态空间的马尔可夫链及其特有的性质，如瞬态与重现性。