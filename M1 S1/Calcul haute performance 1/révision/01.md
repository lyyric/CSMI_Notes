# MPI 并行计算入门

---

## 目录
1. 引言
2. 环境设置
3. 点对点通信

---

## 1. 引言

### 为什么要进行并行化？

- **数据规模大**：需要解决的问题数据量可能非常大，导致计算时间过长（可能需要数天、数周甚至数月），即使使用最强大的处理器也是不现实的。
- **内存限制**：单个处理器的内存可能不足以处理大规模数据。

**解决方案**：并行化  
并行化是通过软硬件技术，使多个处理器同时执行独立的指令序列。如果算法可以并行化，主要有以下优点：
- **加快程序执行速度**：通过分配任务到不同处理器，实现更快的计算。
- **解决更大规模的问题**：利用更多的硬件资源，尤其是内存。

### 如何进行并行化？

1. **数据与任务分配**：将数据和计算任务分配到不同的核心、处理器或机器上。
2. **数据通信与同步**：通过网络进行数据传输和同步，最好使用高速网络。

---

## 2. 环境设置

### 执行模型

- **SPMD（Single Program Multiple Data）**：相同的程序在不同的数据上并行执行。
- **MPMD（Multiple Program Multiple Data）**：不同的程序在不同的数据上并行执行。

本课程主要使用 **SPMD** 模型。

### 顺序编程模型

- 程序由单一进程执行。
- 所有变量和常量分配在该进程的内存中。
- 一个进程运行在机器的一个物理处理器上。

### 消息传递编程模型

- 每个进程执行一个子程序，通常使用相同的编程语言（如 C、C++、Fortran）。
- 每个子程序有独立的内存空间，变量私有。
- 进程通过网络使用特定的发送和接收函数进行通信。

### MPI 环境

- **MPI（Message Passing Interface）** 是一种便携、高效且灵活的消息传递库，支持多种编程语言（C、C++、Fortran、Python）。
- MPI 提供同步和异步通信模式、集体通信等功能。

---

## 3. 点对点通信

### 基本概念

- **发送方和接收方**：通信发生在两个进程之间，一个发送数据，一个接收数据。
- **消息封装**：消息包含发送者和接收者的标识、标签（tag）、通信上下文（communicator）及数据类型和长度。

### 发送操作：`MPI_Send`

```cpp
int MPI_Send(const void *buf, int count, MPI_Datatype datatype,
             int dest, int tag, MPI_Comm comm);
```
- `buf`：数据缓冲区的起始地址。
- `count`：发送数据的数量。
- `datatype`：数据类型。
- `dest`：目标进程的编号。
- `tag`：消息标签，用于标识消息。
- `comm`：通信器，定义进程组和通信上下文。

**注意**：`MPI_Send` 是阻塞操作，直到消息可以安全地复制到发送缓冲区。

### 接收操作：`MPI_Recv`

```cpp
int MPI_Recv(void *buf, int count, MPI_Datatype datatype,
             int source, int tag, MPI_Comm comm, MPI_Status *status);
```
- `buf`：接收数据的缓冲区起始地址。
- `count`：接收数据的数量。
- `datatype`：数据类型。
- `source`：发送进程的编号。
- `tag`：消息标签。
- `comm`：通信器。
- `status`：接收状态信息。

**注意**：`MPI_Recv` 也是阻塞操作，直到消息完全接收。

### 示例：发送和接收整数

```cpp
#include <iostream>
#include <mpi.h>

int main() {
    MPI_Init(nullptr, nullptr);
    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

    int valeur = 0;
    int tag = 123;
    if (world_rank == 2) {
        valeur = 1000;
        MPI_Send(&valeur, 1, MPI_INT, 5, tag, MPI_COMM_WORLD);
        std::cout << "rank=2 send valeur=" << valeur << "\n";
    }
    else if (world_rank == 5) {
        MPI_Recv(&valeur, 1, MPI_INT, 2, tag, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        std::cout << "rank=5 recv valeur=" << valeur << "\n";
    }
    MPI_Finalize();
    return 0;
}
```

**编译与运行**：

```bash
$ mpicxx hello.cpp -o hello
$ mpiexec -n 7 ./hello
rank=2 send valeur=1000
rank=5 recv valeur=1000
```

### 主要数据类型

| MPI 数据类型        | C 数据类型          |
|---------------------|---------------------|
| `MPI_CHAR`          | `char`              |
| `MPI_SHORT`         | `short`             |
| `MPI_INT`           | `int`               |
| `MPI_LONG`          | `long int`          |
| `MPI_UNSIGNED_CHAR` | `unsigned char`     |
| `MPI_UNSIGNED_SHORT`| `unsigned short`    |
| `MPI_UNSIGNED`      | `unsigned int`      |
| `MPI_UNSIGNED_LONG` | `unsigned long int` |
| `MPI_FLOAT`         | `float`             |
| `MPI_DOUBLE`        | `double`            |
| `MPI_LONG_DOUBLE`   | `long double`       |

### 同时发送和接收：`MPI_Sendrecv`

```cpp
int MPI_Sendrecv(const void *sendbuf, int sendcount, MPI_Datatype sendtype,
                int dest, int sendtag, void *recvbuf, int recvcount,
                MPI_Datatype recvtype, int source, int recvtag,
                MPI_Comm comm, MPI_Status *status);
```
- `sendbuf`, `sendcount`, `sendtype`：发送缓冲区、数据数量和类型。
- `dest`, `sendtag`：目标进程和消息标签。
- `recvbuf`, `recvcount`, `recvtype`：接收缓冲区、数据数量和类型。
- `source`, `recvtag`：发送进程和消息标签。
- `comm`：通信器。
- `status`：接收状态信息。

### 示例：同时发送和接收

```cpp
#include <iostream>
#include <mpi.h>

int main() {
    MPI_Init(nullptr, nullptr);
    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);

    int valeurSend = 1000 + world_rank; // 例如：rank 0 -> 1000, rank 1 -> 1001
    if (world_rank == 0 || world_rank == 1) {
        int rankToComm = (world_rank + 1) % 2; // 0 -> 1, 1 -> 0
        int tag = 123, valeurRecv = 0;
        MPI_Sendrecv(&valeurSend, 1, MPI_INT, rankToComm, tag,
                     &valeurRecv, 1, MPI_INT, rankToComm, tag,
                     MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        std::cout << "rank=" << world_rank
                  << " valeurSend=" << valeurSend
                  << " valeurRecv=" << valeurRecv << "\n";
    }
    MPI_Finalize();
    return 0;
}
```

**运行结果**：

```bash
$ mpiexec -n 2 ./myprog
rank=0 valeurSend=1000 valeurRecv=1001
rank=1 valeurSend=1001 valeurRecv=1000
```

---

## 总结

本部分内容介绍了使用 MPI 进行并行计算的基础知识，包括环境设置、点对点通信以及基本的发送和接收操作。通过示例代码，展示了如何在不同进程之间传递数据，并解释了 MPI 中常用的数据类型和通信函数的使用方法。

在后续的学习中，我们将深入探讨 MPI 的其他功能，如集体通信、动态进程管理和并行 I/O 等，进一步提升并行编程的能力。