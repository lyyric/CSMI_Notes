{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "authorship_tag": "ABX9TyOsLCuHKR7p2NePO3/OHx1l"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {"id": "vzf_U8cSb5xc"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "Li1f-pCnGwdU"}, "source": ["# Compression 2\n", "\n", "We finish the work started in the previous chapter: we present the tools used in JPEG and also in JPEG2000.\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Zwqi4-O-qA7d"}, "source": ["## Setting"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "gTZTpq1NlTFq"}, "source": ["### Pull data"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "obXAQQP9tqCC", "colab": {"base_uri": "https://localhost:8080/", "height": 134}, "executionInfo": {"status": "ok", "timestamp": 1585173615325, "user_tz": -60, "elapsed": 3190, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "4248f110-c011-4177-f965-7e5d67ef571d"}, "source": ["\"we import (=clone) all the data or just update (=pull) them\"\n", "\n", "import os\n", "\n", "if not os.path.exists(\"assets_signal\"):\n", "    print(\"the directory assets_signal is create\")\n", "    !git clone https://github.com/vincentvigon/assets_signal\n", "else:\n", "    print(\"the directory assets_signal is updated\")\n", "    %cd assets_signal\n", "    !git pull https://github.com/vincentvigon/assets_signal\n", "    %cd .."], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "PmqBzzq1xE8W"}, "source": ["### Import"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "r-me_kSGxOiB"}, "source": ["%reset -f"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "vZhvJKqjvBmB"}, "source": ["import numpy as np\n", "np.set_printoptions(linewidth=50000,precision=1,suppress=True,)\n", "\n", "import scipy\n", "import scipy.signal\n", "import scipy.fftpack\n", "\n", "import  matplotlib.pyplot as plt\n", "plt.style.use(\"default\")\n", "\n", "import imageio\n", "import IPython\n", "import json"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "v2pnPrxmhL1r"}, "source": ["## YCbCr color encoding\n", "\n", "In the previous chapter, we saw the JPEG compression for gray-level images. What about color images?"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ALvujhpZqFPm"}, "source": ["### Principle"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "qKiPmZzKhDbU", "colab": {"base_uri": "https://localhost:8080/", "height": 499}, "executionInfo": {"status": "ok", "timestamp": 1585173616144, "user_tz": -60, "elapsed": 3997, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "dac47d05-b104-4442-e08e-285b1effd7a0"}, "source": ["IPython.display.Image(\"assets_signal/YCrCb.jpg\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "eO4s70V9Kgwn"}, "source": ["\n", "\n", "YCbCr is the color encoding used in the JPEG compression. The 3 components are Y (luma), Cb ( Chroma blue) and Cr (Chroma red). They are linear transformations of the R,G,B components.\n", "\n", "* Y  represent the gray level of the image:\n", "\n", "        Y = 0.299*R +  0.587*G + 0.114*B\n", "\n", "The 3 constants which appear in this formula are the same 3 constants used usualy to transform a color image into a gray-level image.\n", "\n", "*  (Cb, Cr)  are sort of projections onto the plane which is orthogonal to the Y-axis: see drawing above.\n", "\n", "\n", "\n", "One can compress more the components Cb and Cr than the component Y:  because  human eyes are more sensible to the lumunosity than to the hue.\n", "\n", "\n", "Remark: A similar compression could be done with HSV of HSL encoding (using V or L in place of Y), but formulas for the  YCbCr encoding are linear and consequently faster to compute.\n", "\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "JS8fggKrK-HV"}, "source": ["def rgb2ycbcr(rgb):\n", "    xform = np.array([[.299, .587, .114], [-.1687, -.3313, .5], [.5, -.4187, -.0813]])\n", "    ycbcr = rgb @ xform.T\n", "    ycbcr[:,:,[1,2]] += 128.\n", "    return np.clip(ycbcr,0,255).astype(np.uint8)\n", "\n", "def ycbcr2rgb(ycbcr):\n", "    xform = np.array([[1, 0, 1.402], [1, -0.34414, -.71414], [1, 1.772, 0]])\n", "    copy=ycbcr.astype(np.float64)\n", "    copy[:,:,[1,2]] -= 128.\n", "    rgb=copy@xform.T\n", "    return np.clip(rgb,0,255).astype(np.uint8)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "5Xmf63qNi9pe"}, "source": ["***To you:***\n", "\n", "* $(2\\heartsuit)$ From the code above, write the formulas of the change of variable  $(R,G,B)\\leftrightarrow (Y,C_b,C_r)$.\n", "\n", "* $(1\\heartsuit)$  Is it precisely a linear transform?\n", "\n", "* $(1\\heartsuit)$   Show that, without the `np.clip()`, some $(Y,C_b,C_r)$ triple of `unint8` does not give a proper RGB color.\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "lWeWlL7_Lpsw", "colab": {"base_uri": "https://localhost:8080/", "height": 50}, "executionInfo": {"status": "ok", "timestamp": 1585173616145, "user_tz": -60, "elapsed": 3989, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "c2abbd82-166c-4ce7-f9b0-dc838aff9780"}, "source": ["img = imageio.imread(\"assets_signal/babouin/babouin_moyen.jpg\")\n", "img.shape"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "FNiqbsuzO94W", "colab": {"base_uri": "https://localhost:8080/", "height": 229}, "executionInfo": {"status": "ok", "timestamp": 1585173616681, "user_tz": -60, "elapsed": 4516, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "cf6098be-71a6-4622-98bd-71a353830726"}, "source": ["fig,axs=plt.subplots(1,3)\n", "for i in [0,1,2]:\n", "    axs[i].imshow(img[:,:,i],cmap=\"gray\")\n", "    axs[i].axis(\"off\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ctEltGDfL1T4", "colab": {"base_uri": "https://localhost:8080/", "height": 50}, "executionInfo": {"status": "ok", "timestamp": 1585173616681, "user_tz": -60, "elapsed": 4508, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "7a16c7c3-c24d-442a-f910-0bd533ed8971"}, "source": ["img_YCbCr= rgb2ycbcr(img)\n", "img_YCbCr.shape"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ANTfoBm6MB5O", "colab": {"base_uri": "https://localhost:8080/", "height": 229}, "executionInfo": {"status": "ok", "timestamp": 1585173617630, "user_tz": -60, "elapsed": 5449, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "23af1e87-8282-41c9-dd7c-948a7d94e14d"}, "source": ["fig,axs=plt.subplots(1,3)\n", "for i in [0,1,2]:\n", "    axs[i].imshow(img_YCbCr[:,:,i],cmap=\"gray\")\n", "    axs[i].axis(\"off\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "VMw2FjOnLLPU", "colab": {"base_uri": "https://localhost:8080/", "height": 452}, "executionInfo": {"status": "ok", "timestamp": 1585173617630, "user_tz": -60, "elapsed": 5442, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "0be6c6ad-dd0e-486e-9a29-2525853bb6d6"}, "source": ["img_back=ycbcr2rgb(img_YCbCr)\n", "plt.imshow(img_back);"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "lp9GXCiK0wCH"}, "source": ["***To you:*** $(2\\heartsuit)$ Transform the image by setting to 0 the component `Cb`, and then the component `Cr`, then the component `Y`."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "3uvrKMpPnrI3"}, "source": ["### Compress color\n", "\n", "Here is the recipe of the JPEG pipeline for color images:\n", "\n", "* Take a RGB color.\n", "* Change it to YCbCr.\n", "* Keep the Y component unchanged.\n", "* For Cb and Cr make a sub-sampling: for each $n\\times n$ square of pixels, you keep only the mean.\n", "* Then make the discrete-cosinus compression of the 3 channels as explained in the previous chapter.\n", "\n", "\n", "***To you:***  In this exercice, you do not have to do the last step of the JPEG compression (no  cosinus-transform).\n", "\n", "\n", "* $(8 \\heartsuit)$ Make a function which  compress the babouin for $n=2,4,8,16,32$ (actualy, in JPEG $n=2$). Help: use a rolling window (and not a convolution which would compute too much means). Make a function which decompress.  Test the process compression+decompression for various $n$.  \n", "* $(2\\heartsuit)$ Compute theoriticaly the compression rate according to $n$.\n", "* $(5 \\heartsuit\\flat)$ generalize your programs so that it works for any image-size and any $n$.   Help: use the fonction `np.pad` with a good `mode` argument (see docstring).\n", "\n", "\n", "\n", "\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-ib86aXUlpV0"}, "source": ["###  JPEG  Color\n", "\n", "***To you:*** $(8\\heartsuit\\flat)$. Make a function that perform the JPEG compression for color images. The result must be a string as in the previous chapter. Compare the length of this string with the lengt of the image simply converted to a string.\n", "\n", "For the quantisation, use the two following matrices.\n", "\n", "***Remark:*** To do the previous exercice, you probably copy-paste your grey-level JPEG program in the present notebook. It is not a very good habit: the good technic  to `import` functions from a file to an other (we will see how to do this later on).\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "RZZTzcbBkJnY", "colab": {"base_uri": "https://localhost:8080/", "height": 319}, "executionInfo": {"status": "ok", "timestamp": 1585173617631, "user_tz": -60, "elapsed": 5436, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "c9bf48e4-5a50-465d-e631-2c478809f7c9"}, "source": ["Qlum_str=\"\"\"\n", "16 11 10 16 24 40 51 61\n", "12 12 14 19 26 58 60 55\n", "14 13 16 24 40 57 69 56\n", "14 17 22 29 51 87 80 62\n", "18 22 37 56 68 109 103 77\n", "24 36 55 64 81 104 113 92\n", "49 64 78 87 103 121 120 101\n", "72 92 95 98 112 100 103 99\n", "\"\"\"\n", "\n", "Qchrom_str=\"\"\"\n", "17 18 24 47 99 99 99 99\n", "18 21 26 66 99 99 99 99\n", "24 26 56 99 99 99 99 99\n", "47 66 99 99 99 99 99 99\n", "99 99 99 99 99 99 99 99\n", "99 99 99 99 99 99 99 99\n", "99 99 99 99 99 99 99 99\n", "99 99 99 99 99 99 99 99\n", "\"\"\"\n", "\n", "def to_matrix(Q_str):\n", "    Q=Q_str.split()\n", "    Q=np.array(Q,dtype=np.int64)\n", "    return Q.reshape([8,8])\n", "\n", "Qlum=to_matrix(Qlum_str)\n", "print(Qlum)\n", "print()\n", "Qchrom=to_matrix(Qchrom_str)\n", "print(Qchrom)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "lAIZhvw_qeCC"}, "source": ["## Huffmann encoding"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "IFnr4sJv-0uN"}, "source": [" ### Principle\n", "\n", " We have letters to encode with sequences of 0 and 1. This letters  appears with some given frequencies: ex:\n", "\n", "    letter_to_freq={\"A\":15,\"B\":7,\"C\":6,\"D\":6,\"E\":5}\n", "\n", " To gain place, we want to attribute shortest sequences to highest frequecies. Ex:\n", "    \n", "    encoding={'A': '1', 'B': '011', 'C': '010', 'D': '001', 'E': '000'}\n", "    \n", "The constraint is that no encoding-sequence is the prefix of an other encoding-sequence. This constraint is satisfied with the above encoding.\n", "    \n", "    \n", "***To you:*** $(2\\heartsuit)$ Why this constraint? Help:  If you have no idea, try to code and decode some word.  \n", "\n", "\n", "The constraint can be express graphicaly: all letters can be placed at the leaf of a binary tree whose branchs are labeled with 0 and 1. The encoding-sequence is given by the path from the root to the leaf.\n", "\n", "Above is the construction of a tree corresponding to our `letter_to_freq`. This tree is obtained by  progressive gathering: this is the principle of the 'Huffman encoding'."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "ZKZujYeD_2io", "colab": {"base_uri": "https://localhost:8080/", "height": 793}, "executionInfo": {"status": "ok", "timestamp": 1585173617631, "user_tz": -60, "elapsed": 5429, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "03961423-4da7-4bac-e979-b967c028b049"}, "source": ["IPython.display.Image(\"assets_signal/huffman.png\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "UYe0RaCcDvjM"}, "source": ["***To you:*** $(1\\heartsuit)$ How do we choose the order of the consecutive gatherings?"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "OrbPSn3CEDgP"}, "source": ["### Code\n", "\n", "Here is a program (made by a student of Strasbourg) which create the Huffman encoding for a given alphabet with frequencies."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "vlUsGPzfqc42"}, "source": ["def codageHuffman(dico:dict):\n", "    dact=dico.copy()\n", "    L=[]\n", "    totOcurrence=0\n", "    for key,values in dico.items():\n", "        totOcurrence+=values\n", "        L+=[([key],values)]\n", "    while len(L)!=1:\n", "        min1=totOcurrence\n", "        min2=totOcurrence\n", "        for numKey,occurence in enumerate(L):\n", "            if occurence[1]<min1 or occurence[1]<min2:\n", "                if min1<=min2:\n", "                    min2=occurence[1]\n", "                    indiceMin2=numKey\n", "                else:\n", "                    min1 = occurence[1]\n", "                    indiceMin1 = numKey\n", "\n", "        if min1<min2 : indiceMin2,indiceMin1=indiceMin2,indiceMin1\n", "\n", "        if len(L[indiceMin1][0])==1:\n", "            dact[L[indiceMin1][0][0]]='0'\n", "        else:\n", "            for i in range(len(L[indiceMin1][0])):\n", "                    dact[L[indiceMin1][0][i]]+='0'\n", "\n", "        if len(L[indiceMin2][0])==1:\n", "            dact[L[indiceMin2][0][0]]='1'\n", "        else:\n", "            for i in range(len(L[indiceMin2][0])):\n", "                dact[L[indiceMin2][0][i]]+='1'\n", "\n", "\n", "        L.append((L[indiceMin2][0]+L[indiceMin1][0],min1+min2))\n", "        del L[max(indiceMin1,indiceMin2)]\n", "        del L[min(indiceMin1,indiceMin2)]\n", "\n", "\n", "    for key in dact.keys():\n", "        a = ''\n", "        for let in range(len(dact.get(key))):\n", "            a+=dact.get(key)[len(dact.get(key))-let-1]\n", "        dact[key]=a\n", "    return dact"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Ute5B6yTqqZi", "colab": {"base_uri": "https://localhost:8080/", "height": 50}, "executionInfo": {"status": "ok", "timestamp": 1585173617632, "user_tz": -60, "elapsed": 5420, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "8396ff0c-22b6-4ca8-804a-4611ec816f6a"}, "source": ["dico={'a':200,'b':7,'c':9,'d':10,'e':10,'f':100}\n", "print(codageHuffman(dico))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "p5ptcrscEfXh"}, "source": ["***To you:***\n", "\n", "* $(1\\heartsuit)$ On a sheet of paper, draw the consecutive trees which lead to this encoding.\n", "* $(1\\heartsuit)$ Does this program gives THE good result?"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Tfc2yA6GCZwo"}, "source": ["***To you:*** $(3\\heartsuit)$ Associate the three following code the the good dictionary. Try to do this before to runing a program.\n", "\n", "    {'a': '01', 'b': '000', 'c': '001', 'd': '1'}\n", "    {'a': '1', 'b': '010', 'c': '011', 'd': '00'}\n", "    {'a': '001', 'b': '01', 'c': '000', 'd': '1'}"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "4hpovMHzAUcS"}, "source": ["dico1={'a':200,'b':50,'c':3,'d':400}\n", "dico2={'a':400,'b':50,'c':3,'d':400}\n", "dico3={'a':40,'b':250,'c':3,'d':400}"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "5OPgwNXAFeh6"}, "source": ["### Letter frequencies in french and english\n", "\n", "\n", "Below are the frequencies of the letter for french and english.\n", "\n", "***To you:***\n", "\n", "* $(3\\heartsuit)$ Make some graphical comparison between the two languages. Look for letters that are 5 times more frequent in english than in french.  \n", "* $(3\\heartsuit)$  Create encodings for each language. Help:\n", "    * start to cut strings with  `split(\"\\n\")`.\n", "    * Use `float()` to convert string into floats.\n", "    * You can extract subtring with the slicing. ex: `hello[1:3]` gives `el`.\n", "* $(3\\heartsuit)$   Compute the proportion of place you win with these encodings. Help: you have to compute fistly the length of an encoding with constant length (like the ASCII encoding). Then the length with the Huffman encoding (taking in concideration the frequencies).\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "4SuUGIIVuuQX"}, "source": ["\n", "english_str=\"\"\"\n", "a\t0.08167\n", "b\t0.01492\n", "c\t0.02782\n", "d\t0.04253\n", "e\t0.12702\n", "f\t0.02228\n", "g\t0.02015\n", "h\t0.06094\n", "i\t0.06966\n", "j\t0.00153\n", "k\t0.00772\n", "l\t0.04025\n", "m\t0.02406\n", "n\t0.06749\n", "o\t0.07507\n", "p\t0.01929\n", "q\t0.00095\n", "r\t0.05987\n", "s\t0.06327\n", "t\t0.09056\n", "u\t0.02758\n", "v\t0.00978\n", "w\t0.02360\n", "x\t0.00150\n", "y\t0.01974\n", "z\t0.00074\n", "\"\"\"\n", "\n", "french_str=\"\"\"\n", "A\t8,13%\n", "B\t0,93%\n", "C\t3,15%\n", "D\t3,55%\n", "E\t15,10%\n", "F\t0,96%\n", "G\t0,97%\n", "H\t1,08%\n", "I\t6,94%\n", "J\t0,71%\n", "K\t0,16%\n", "L\t5,68%\n", "M\t3,23%\n", "N\t6,42%\n", "O\t5,27%\n", "P\t3,03%\n", "Q\t0,89%\n", "R\t6,43%\n", "S\t7,91%\n", "T\t7,11%\n", "U\t6,05%\n", "V\t1,83%\n", "W\t0,04%\n", "X\t0,42%\n", "Y\t0,19%\n", "Z\t0,21%\n", "\u0152\t0,01%\n", "\u00c0\t0,54%\n", "\u00c2\t0,03%\n", "\u00c7\t0,00%\n", "\u00c8\t0,35%\n", "\u00c9\t2,13%\n", "\u00ca\t0,24%\n", "\u00cb\t0,01%\n", "\u00ce\t0,03%\n", "\u00cf\t0,00%\n", "\u00d4\t0,07%\n", "\u00d9\t0,02%\n", "\u00db\t0,05%\n", "\u00dc\t0,02%\n", "\"\"\""], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qxnmd9FZRANA"}, "source": ["### Entropy\n", "\n", "\n", "\n", "\n", "\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Ei_e9YacTeNE"}, "source": ["Consider $p$ the vector of frequencies of letters, renormalized to get probabilities. Ex:\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "Scbp2P0bSJUf", "colab": {"base_uri": "https://localhost:8080/", "height": 50}, "executionInfo": {"status": "ok", "timestamp": 1585173618488, "user_tz": -60, "elapsed": 6259, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "4f75d317-cd80-48a8-dc50-54101c80caa4"}, "source": ["letter_to_freq={\"A\":15,\"B\":7,\"C\":6,\"D\":6,\"E\":5}\n", "l=len(letter_to_freq)\n", "probas=np.empty([l])\n", "for i,val in enumerate(letter_to_freq.values()):\n", "    probas[i]=val\n", "\n", "probas/=probas.sum()\n", "probas"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "k6IG2xRZTqb-"}, "source": ["The associated entropy is\n", "$$\n", "H(p) = - \\sum p_i  \\log_2( {p_i})\n", "$$\n", "where $\\log_2$ is the logarithm in basis 2: $\\log_2(x)= \\log(x)/\\log(2)$. And we use the convention $0\\log(0)=0$ when a proba is zero.\n", "\n", "\n", "Considere $f$ a binary encoling i.e an application which associate to any letter $a$ the conding sequence $f(a_i)$. The Average length of $f$ is\n", "$$\n", "AL_p(f) = \\sum_i  lenght(f(a_i))\\ p_i\n", "$$\n", "where $p_i$ is the probability of the letter $a_i$.\n", "\n", "***Remark:*** To reply to the exercice of the previous section, you already have computed some average lengths.\n", "\n", "\n", "The shanon information theorem says that, for any encoding, we have:\n", "$$\n", "H(p) \\leq AL_p(f)\n", "$$\n", "And in particular, if $f$ is the huffman encoding, we get:\n", "$$\n", "H(p) \\leq AL_p(f)  \\leq H(p) + 1\n", "$$\n", "\n", "\n", "*** To you:***\n", "\n", "* $(2\\heartsuit)$ Check the previous inequalities for your french and english encoding.\n", "* $(2\\heartsuit)$ What must we change in these formulas if we work with hexadecimal encoding instead of binary encoding?\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "oO2OYXBfsKEK"}, "source": ["###  JPEG and encodings\n", "\n", "\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "pYjdU5z2vw-H", "colab": {"base_uri": "https://localhost:8080/", "height": 334}, "executionInfo": {"status": "ok", "timestamp": 1585173618489, "user_tz": -60, "elapsed": 6251, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "a5e02415-c9b6-476f-90f1-ec3e921012da"}, "source": ["IPython.display.Image(\"assets_signal/JPEG_process.png\",width=600)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "xGFaYzZh-jXP"}, "source": ["We call \"entropy coding\" a code that associate to the most frequent symbols the shortest code. The final step of JPEG is to encode the quantized coefficients with an entropy coding. The JPEG standard let you two choices:\n", "\n", "* The Huffman coding which we present before.\n", "* The arithmetic coding which gives better result (about 5% shorter) but require more calculus, and so, it is rarely used.\n", "\n", "\n", "But just before entropy coding, we separate the quantized coefficients in two categories:  \n", "\n", "*  the 'DC'='directe coefficient' coefficients are the coefficients (0,0) of each $8\\times 8$-block.\n", "* The 'AC' coefficients are the 63 coefficients remainings in each blocks (but actually, we trucate most of them).\n", "\n", "\n", "The 'AC' ='alternative coefficient' coefficients are stored following the zigzag path, block by block, suppressing the zero sequency at the end of each block (see previous chapter).\n", "\n", "The DC coefficients are the average values of the blocks. Because images are \"continuous\", the DC coefficients of two neighbor blocks are close. So the idea to store only the differences of the DC coefficients: we ordonnated the blocks, then we store DC(0) and  DiffDC(i) = DC(i) - DC(i-1). This achieve further compression due to the smaller range of the coefficient values.\n", "\n", "The precise technic to encode of this DC and AC coefficients is still too long to explain. I send you to this [reference](https://en.wikibooks.org/wiki/JPEG_-_Idea_and_Practice/The_Huffman_coding) is you want to understand all details.\n", "\n", "\n", "***To you:***\n", "\n", "* $(1\\heartsuit)$ Did you understant why \"smaller range for the coefficient values\" implies a better compression?\n", "*  $(1\\heartsuit)$ Look at the scheme above: What are the \"Quantization tables\"?\n", "*  $(1\\heartsuit)$ What are \"Huffman table\"? Why these tables appear at two different places in the scheme?\n", "\n", "\n", "***Remark:*** Actually JPEG does not impose the Quantization tables and the Huffman table. When you create a JPEG file you can:\n", "\n", "* either include tables\n", "* or indicate that you want to use the default ones.\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "sp9H4CYq5wjp"}, "source": ["### Last words about  JPEG\n", "\n", "We gave a lot of details about JPEG (not all) which is a family of standards edited from 1986. Of course it is not useful to know by heart all these: you will probably never have to write a JPEG compression program (even if you will probably become a chief ingenieur).  But this allow us to discover a lot of famous compression tricks:\n", "\n", "    * change of basis\n", "    * clever quantization\n", "    * zigzag reading\n", "    * color encoding\n", "    * differential storing\n", "    * huffman encoding\n", "   \n", "Secondly, JPEG is you a good example of collective intelligence, shared without patent! JPEG compression is so efficient that it became universal. More recent standards like JPEG2000 never manage to replace it.\n", "\n", "The equivalent for video is MPEG (nowaday: version 4,  part 10). Of course it is not a compression frame by frame: it use the fact that a wide part of images does not evolute from a frame to another.  MPEG is also very efficient, but probably better standards will take the place in the futur (one speak a lot of the H.265 standard... wait an see).\n", "\n", "Come back to JPEG: They are several way to precisely implement the compressing+decompressing process. In 2017, a team from google, playing with the quantization step, published the new implementation called \"Guetzli\":\n", "\n", "* which reduce the file size of 35%\n", "* which is fully compatible with the JPEG standards: so, no need to change the existing decoding codes (JPEG let you the choice of the quantizations table).\n", "* but which require more calculus"], "outputs": []}, {"cell_type": "code", "source": [], "metadata": {"id": "6f0_IvF6b-sO"}, "execution_count": null, "outputs": []}]}