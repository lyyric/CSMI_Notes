III. Transformation de Fourier rapide

> [!review]
> On a vu que l'on peut multiplier 2 polynômes en $O(n^{1 + \epsilon})$, où $\epsilon > 0$ est arbitraire.

On va faire mieux pour les polynômes à coefficient complexe.

---

Deux façons de voir un polynôme:

(i) $\rightarrow$ coefficients: $P(x) = a_0 + a_1 x + ... + a_{n-1} x^{n-1}$

(ii) $\rightarrow$ paires point/valeur $(x_0, y_0), ..., (x_{n-1}, y_{n-1})$, où les $x_i$ sont distincts et $y_i = P(x_i)$, $0 \leq i \leq n-1$.

(iii) facile d'additionner 2 polynômes:
$$(a_0, ..., a_{n-1}) \oplus (b_0, ..., b_{n-1})$$
$$= (a_0 + b_0, ..., a_{n-1} + b_{n-1})$$

(i) pas pratique pour la multiplication

(ii) facile pour l'addition et pour la multiplication:
$$(x, P(x_0)), ..., (x_{n-1}, P(x_{n-1}))$$
$$(x, Q(x_0)), ..., (x_{n-1}, Q(x_{n-1}))$$

le polynôme $P+Q$ est déterminé par
$$(x_0, (P + Q)(x_0)), ..., (x_{n-1}, (P + Q)(x_{n-1}))$$

$$(P + Q)(x_0)=(P + Q)(x_i), (P + Q)(x_{n-1})= P(x_i) + Q(x_i)$$

le polynôme $P \cdot Q$ est déterminé par
$$(x_0, P(x_0)Q(x_0)), \cdots, (x_{n-1}, P(x_{n-1})Q(x_{n-1})),\cdots , (x_{2n-2}, P(x_{2n-2})Q(x_{2n-2}))$$

**Attentions**

comme $\text{deg} (PQ) \leq 2n - 2$

on doit évaluer $P \cdot Q$ en $2n - 1$ points

---

On va procéder ainsi pour mult. 

$P(x) = a_0 + ... + a_{n-1} x^{n-1}$ et $Q(x) = b_0 + ... + b_{n-1} x^{n-1}$

![](assets/Pasted%20image%2020240923084840.png)


$$(a_0, ..., a_{n-1})$$

$\xrightarrow{\text{(x)}}$

$$(x_0, P(x_0)), ..., (x_{n-1}, P(x_{n-1}))$$

$$(b_0, ..., b_{n-1})$$

$\xrightarrow{\text{(x)}}$

$$(x_0, Q(x_0)), ..., (x_{n-1}, Q(x_{n-1}))$$

Mult. facile

$$(x_0, P(x_0)Q(x_0)), ..., (x_{n-1}, P(x_{n-1})Q(x_{n-1}))$$

(ii) $(b_0, ..., b_{n-1})$

Interpolation de Lagrange: coût $O(n^2)$

---

(Chap. 30 de Cormen-Leiserson-Rivest-Stein)


Coût de $(x)$

Données: $x_0, P(x)$

Coût du calcul de $P(x_0)$?

$P(x) = a_0 + a_1 x + ... + a_n x^n$

$1 + 2 + ... + n = \frac{n(n+1)}{2} = \Theta(n^2)$ 

Note: $\Theta(f(n)) \geq C f(n)$ 

---

Règle de Horner:
$$P(x) = a_0 + x_0 (a_1 + x_0 (a_2 + x_0 (a_3 + ... + x_0 (a_{n-2} + x_0 a_{n-1}))))$$

$\approx 2n$ opérations

Bref, le calcul de $(x_0, P(x_0)), ..., (x_{n-1}, P(x_{n-1}))$ coûte $O(n^2)$, et avec ça on ne risque pas d'améliorer les résultats connus!

---

On va choisir $x_0, ..., x_{n-1}$ de sorte que le calcul de $P(x_0),\cdots, P(x_{n-1})$ soit plus rapide.

Idée: On prend $x_j = e^{2i\pi j / n}$

On suppose que $n$ est une puissance de 2.

---

En écrivant $P(x) = P^{[0]}(x^2) + xP^{[1]}(x^2)$, où deg $P^{[0]} < \frac{n}{2}$, deg $P^{[1]} < \frac{n}{2}$

$P^{[0]}(x^2) = a_0 + a_2 x^2 + a_4 x^4 + \dots + a_{n-2} x^{n-2}$

$xP^{[1]}(x^2) = a_1 x + a_3 x^3 + \dots + a_{n-1} x^{n-1}$

ainsi,

$$\mathcal{L}(e^{2i\pi j / n}) = P^{[0]}(e^{2i\pi j / (n/2)}) + e^{2i\pi j / n} P^{[1]}(e^{2i\pi j / (n/2)})$$

Le calcul des valeurs de $P$ (de degré < $n$) en les $e^{2i\pi j / n}$ se ramène à celui de $P^{[0]}$ et $P^{[1]}$ (de degré < $n/2$) en les $e^{2i\pi j / (n/2)}$.

---

n : puissance de 2

FFT - récursive $(P, n)$

Si $n = 1$ retourner $P$

Sinon:
- $\omega_0 \leftarrow e^{2i\pi/n}$, $\omega \leftarrow 1$

$$P^{[0]} = (a_0, a_2, ..., a_{n-2})$$
$$P^{[1]} = (a_1, a_3, ..., a_{n-1})$$

$$y^{[0]} \leftarrow \text{FFT-récursive } (P^{[0]}, n/2)$$
$$y^{[1]} \leftarrow \text{FFT-récursive } (P^{[1]}, n/2)$$

Pour $k = 0$ à $n/2 - 1$:
- faire $y_k \leftarrow y_k^{[0]} + \omega y_k^{[1]}$
- $y_{k+n/2} \leftarrow y_k^{[0]} - \omega y_k^{[1]}$
- $\omega \leftarrow \omega \omega_n$

Retourner $(y_k)$

---

Formules:

$$y_k^{[0]} = P^{[0]}(e^{2i\pi k / (n/2)})$$
$$y_k^{[1]} = P^{[1]}(e^{2i\pi k / (n/2)})$$
$$y_k = P(e^{2i\pi k / n}) = y_k^{[0]} + e^{2i\pi k / n} y_k^{[1]}$$

---

Coût de cet algorithme?

Notons-le $T(n)$

$$T(n) \leq 2T(n/2) + 5n$$
$2$ appels récursifs $\quad$ coût de la boucle **pour** 

Majeur $T(n)$?

$$T(n) \leq 2T(n/2) + 5n$$

$$\leq 2(2T(n/4) + 5n/2) + 5n$$

$$n = 2^k$$

$$T(2^k) \leq 2T(2^{k-1}) + 5 \cdot 2^k$$

$$\leq 2(2T(2^{k-2}) + 5 \cdot 2^{k-1}) + 5 \cdot 2^k$$

$$= 2^2T(2^{k-2}) + 5 \cdot 2^k + 5 \cdot 2^k$$

$$
\leq 2^2 \left( 2T(2^{k-3}) + 5 \cdot 2^{k-2} \right) + 5 \cdot 2^k
$$

$$
= 2^3 T(2^{k-3}) + 5 \cdot 2^k + 5 \cdot 2^k + 5 \cdot 2^k
$$

$$
\leq 2^k T(2^0) + k \cdot 5 \cdot 2^k
$$

$$
\leq (5k + 1) \cdot 2^k
$$

$$
n = 2^k \quad \Leftrightarrow \quad k = \log_2 n
$$

Donc $T(n) = O(n \log n)$

---

Comment passer de la donnée des paires point/valeur à la représentation usuelle d’un polynôme?

$$
\begin{pmatrix}
y_0 \\
\vdots \\
y_{n-1}
\end{pmatrix}
=
\begin{pmatrix}
1 & 1 & \dots & 1 \\
1 & \omega_n & \dots & \omega_n^{n-1} \\
1 & \omega_n^2 & \dots & \omega_n^{2(n-1)} \\
\vdots & \vdots & \ddots & \vdots \\
1 & \omega_n^{n-1} & \dots & \omega_n^{(n-1)(n-1)}
\end{pmatrix}
\begin{pmatrix}
a_0 \\
a_1 \\
\vdots \\
a_{n-1}
\end{pmatrix}
$$

$$Y = V \cdot A$$

$$V = (v_{ij})_{0 \leq i,j \leq n-1}, \quad v_{ij} = \omega_n^{ij}$$

$$A = V^{-1} Y$$
**Théorème**: Écrivons $V^{-1} = (\tilde v_{ij})_{0 \leq i,j \leq n-1}$

Alors $\tilde v_{ij} = \dfrac{\omega_n^{-ij}}{n}$.

Démonstration: (exercice)

On obtient 

$$a_j = \frac{1}{n} \sum_{k=0}^{n-1} y_k \omega_n^{-kj}$$

Pour déterminer les coefficients $a_0, a_1, \dots, a_{n-1}$, on utilise l’analogie de FFT-récursive avec $\omega_{2n} \gets e^{-2i\pi / n}$ et on divise par $n$.

---

meme complexe: $O(n \log n)$

En resume, si $P$ et $Q$ deux polynômes, a $n$ coefficients $(n = 2^k)$.

Alors, 
$$P \cdot Q = FFT_{2n}^{-1} \left( FFT_{2n}(P) \otimes FFT_{2n}(Q) \right)$$

![](assets/Pasted%20image%2020240923093358.png)

**Exercice**: On a vu plusieurs problèmes de taille $n$ dont la résolution se ramène à celle de $a$ problèmes de taille $n/b$ avec un coût $f(n)$ pour la reconstruction.

On suppose que $n = b^k$, on a alors

$$C(n) = a \cdot C\left(b^k\right) = a \cdot C\left(b^{k-1}\right) + f(n)$$

où $C(n)$ est coût de la resolution du problème.


**Définitions**:

1. **$\Omega(g)$** : On note $f = \Omega(g)$ s'il existe $c > 0$ tel que $f(n) \geq c \cdot g(n)$ pour tout $n$.
   
2. **$\Theta(g)$** : On note $f = \Theta(g)$ s'il existe $c_1, c_2 > 0$ tels que $c_1 \cdot g(n) \leq f(n) \leq c_2 \cdot g(n)$ pour tout $n$.


**Remarque**: Si $f = O(g)$ et $g = O(f)$, alors $f = \Theta(g)$.

Montrer que:

(i) $C(n) = \Theta\left(n^{\log_b a}\right)$ si $f(n) = O\left(n^{\log_b a - \epsilon}\right)$ avec $\epsilon > 0$.

(ii) $C(n) = \Theta\left(n^{\log_b a} \cdot \log n\right)$ si $f(n) = \Theta\left(n^{\log_b a}\right)$.

(iii) $C(n) = \Theta(f(n))$ s'il existe $\epsilon > 0$ tel que $f(n) = \Omega\left(n^{\log_b a + \epsilon}\right)$ et s'il existe $c < 1$ et $n_0$ tel que $a \cdot f(n/b) \leq c \cdot f(n)$ pour tout $n \geq n_0$.

(i) 
$$C(b^k) = a \cdot C(b^{k-1}) + f(b^k)$$

$$= a \left( a \cdot C(b^{k-2}) + f(b^{k-1}) \right) + f(b^k)$$

$$= a^2 \cdot C(b^{k-2}) + a \cdot f(b^{k-1}) + f(b^k)$$

$$= a^2 \left( a \cdot C(b^{k-3}) + f(b^{k-2}) \right) + a \cdot f(b^{k-1}) + f(b^k)$$

$$= a^3 \cdot C(b^{k-3}) + a^2 \cdot f(b^{k-2}) + a \cdot f(b^{k-1}) + f(b^k)$$

$$= a^4 \cdot C(b^{k-4}) + a^3 \cdot f(b^{k-3}) + a^2 \cdot f(b^{k-2}) + a \cdot f(b^{k-1}) + f(b^k)$$
$$\vdots$$
$$= a^k \cdot C(1) + \sum_{j=0}^{k-1} a^j \cdot f(b^{k-j})$$
Par hypothèse, il existe $k > 0$ tel que

$$f(n) \leq K \cdot n^{\log_b a - \epsilon}$$

Alors,

$$f(b^{k-j}) \leq K \left( b^{k-j} \right)^{\log_b a - \epsilon}$$

et

$$\sum_{j=0}^{k-1} a^j \cdot f(b^{k-j}) \leq \sum_{j=0}^{k-1} (a^{j\log_b a}) \cdot (b^{(k-j)(\log_b a - \epsilon)})$$

$$\leq \sum_{j=0}^{k-1} b^{k \log_b a - \epsilon (k-j)}$$

$$\leq a^k \left( b^{-\epsilon} + b^{-2\epsilon} + \dots \right)$$
$$C(b^k) \leq a^k C(1) + K a^k b^{-\epsilon} \cdot \frac{1}{1 - b^{-\epsilon}}$$

$$C(b^k) = O(a^k)$$

$$C(n) = O\left(n^{\log_b a}\right)$$
