V. Graphes bipartis  

Déf. Un graphe $G$ est biparti s'il existe une partition $S = S_1 \cup S_2$ de l'ensemble de ses sommets telle que toute arête de $G$ a une extrémité dans $S_1$ et l'autre dans $S_2$.  

Ex. Tout graphe sans cycle est biparti.  

$C_{2n}$ est biparti pour $n \geq 1$.
![[Pasted image 20241202081739.png|300]]
Notions de graphe biparti, quadriparti.  

**Théorème** : Un graphe est biparti si et seulement s'il ne contient pas de cycle de longueur impaire.  

$C_5$  
![[Pasted image 20241202081721.png]]
$A_1 \to S_1$  
Donc $A_2, A_5 \to S_2$ , voisins de $A_1$
Donc $A_3, A_4, A_1 \to S_1$ , voisins de $A_2$ et $A_5$
Donc $A_4 \to S_2$ , voisin de $A_3$  
**Contradiction.**  

**Démonstration**  

$\Rightarrow$  
Soit $S = S_1 \cup S_2$ une partition des sommets de $G$.  
Soit $s_0, s_1, \ldots, s_l$ un cycle de longueur $l$ avec $s_0 \in S_1$.  

Alors $s_1 \in S_2$, $s_2 \in S_1$, $s_3 \in S_2$, ...  
Ainsi, $s_{2h} \in S_1$, $s_{2h+1} \in S_2$.  
$s_0 \in S_2$. Donc $l-1$ est de forme $2h+1$ : l'entier $l$ est pair.  
Tout cycle est de longueur paire.  

$\Leftarrow$  
On peut supposer $G$ connexe.  
On note $d(s, s_0)$ la longueur du plus court chemin entre $s$ et $s_0$.  

On se fixe un sommet $s_0$ (sommet ajouté).  
On pose  
$S_1 = \{s \in S : d(s_0, s) \text{ impaire}\}$  
$S_2 = \{s \in S : d(s_0, s) \text{ paire}\}$  

**Fait** : Il n’y a pas d’arête entre deux sommets de $S_1$, ni entre deux sommets de $S_2$.  

$a_0, a_1 \in S_1$.  

![[Pasted image 20241202083340.png|300]]
![[Pasted image 20241202083351.png|300]]

Remarque : Tout arbre est biparti.  
![[Pasted image 20241202083407.png|300]]

**VI. Matrice d'adjacence**  

$G$ graphe, $A_1, \ldots, A_n$ sommets.  
On lui associe la matrice $A_G = (a_{ij})_{1 \leq i,j \leq n}$ définie par :  
$$
a_{ij} =
\begin{cases} 
1 & \text{si } A_i \text{ et } A_j \text{ ont une arête}, \\ 
0 & \text{sinon.}
\end{cases}
$$  

**Rappel** : $G$ est un graphe simple.  

**Quelques propriétés de $A_G$** :  
- $A_G$ est symétrique.  
- Il n'y a que des $0$ sur la diagonale.  
- Les coefficients de $A_G^m = (a_{ij}^{(m)})_{1 \leq i,j \leq n}$ donnent le nombre de chemins de longueur $m$ entre $A_i$ et $A_j$.  
![[Pasted image 20241202085940.png|300]]
$$
a_{ij}^{(m)} = \sum_{k=1}^n a_{ik}^{(m-1)} a_{kj}.
$$

Comment voir si $G$ est connexe ?  
Il suffit que tous les coefficients de  
$$
A_G + A_G^{(2)} + \ldots + A_G^{(n)}
$$  
soient $\geq 1$.  

$A_G$ dépend de la numérotation des sommets :  
Changement de numérotation $\Rightarrow$ multiplication à gauche et à droite par une matrice de permutation.  

**VII. Colorage**  

Le nombre chromatique d'un graphe $G$, noté $\chi(G)$, est le nombre minimal de couleurs nécessaires pour colorier les sommets de $G$ telle sorte que deux sommets soient toujours de couleur différente.  

$$
\chi(K_n) = n
$$  
$$
\chi(C_n) =
\begin{cases} 
2 & \text{si } n \text{ est pair}, \\
3 & \text{si } n \text{ est impair.}
\end{cases}
$$

**Théorème :**  
$G$ connexe.  
Alors $\chi(G) \leq 1 + \max d(a)$ où $a \in G$.  

**Démonstration :**  
On utilise l’algorithme glouton :  
- On numérote les sommets $A_1, A_2, \ldots, A_n$.  
- On dispose des couleurs $c_1, c_2, \ldots$.  
- On colorie $A_1$ en $c_1$.  
- On colorie $A_2$ en $c_1$, si $A_2$ n’a pas une arête avec $A_1$, et en $c_2$ sinon.  
- Si $A_1, \ldots, A_{j-1}$ sont coloriés, alors on colorie $A_j$ avec la couleur $c_i$, où $i$ est le plus petit possible.  

En particulier, comme $A_j$ a $d(A_j)$ voisins, on a récemment :  
$$
\chi(G) \leq 1 + d(A_j) \leq 1 + \max d(A), \; \text{avec } a \in \text{Deg}.
$$  
Le pire des cas étant celui où tous les voisins de $A_j$ sont parmi $A_1, \ldots, A_{j-1}$.  

**Remarque :**  
Le résultat (le nombre de couleurs utilisées) dépend de la numérotation des sommets.  

![[Pasted image 20241202091407.png]]

**VIII. Parcours de graphes**  

$G$ graphe orienté, avec poids.  
$s$ sommet origine.  
$\delta(s, v)$ poids du plus court chemin de $s$ à $v$  
($\delta(s, v) = +\infty$ s’il n’y a pas de chemin).  
$\omega(v_1, v_2)$ poids de l’arête.  

![[Pasted image 20241202093318.png]]

$d[v]$ : valeur courante de la distance de $s$ à $v$.  
On initialise par $d[s] = 0$, $d[v] = +\infty$ si $v \neq s$.  

**L’idée principale est le "relâchement"** :  
Relâcher ($u, v$)  
Si $d[v] > d[u] + \omega(u, v)$, alors  
$$
d[v] = d[u] + \omega(u, v).
$$  
On regarde s'il existe, pour aller de $s$ à $v$, un chemin plus court qui se termine par l’arête $(u, v)$

**DIJKSTRA** $(G, \omega, s)$  
1. $E \gets \varnothing$ (sommets visités).  
2. $F \gets \{\text{sommets de } G\}$.  
   Tant que $F \neq \varnothing$ :  
   - Faire :  
     $u \gets \text{sommets de } F \text{ de poids minimum}$.  
     $F \gets F \setminus \{u\}$.  
     $E \gets E \cup \{u\}$.  
     Pour chaque sommet $v$ tel que $u \to v$,  
     - Faire : relâchement $(u, v, \omega)$.  

Fin tant que.  

![[Pasted image 20241202094355.png]]

**Coût de l'algorithme :**  
- $|S|$ fois la boucle « tant que » détermine le sommet de poids minimum : coût $\propto |S|$.  
- Chaque arête est relâchée une seule fois.  

En tout : $O(|S|^2 + |A|)$.  
Comme $|A| \leq |S|(|S|-1)$, on obtient $O(|S|^2)$.  

**Attention :**  
Cet algorithme ne fonctionne pas s’il y a des poids $< 0$.  

**Algo. de Bellman-Ford**  
(Traite aussi les poids $< 0$)  

1. $d[s] = 0$, $d[v] = +\infty$ pour $v \neq s$.  
2. Pour $i$ de 1 à $|S|-1$, faire :  
   - Pour chaque arête $u \to v$, relâcher $(u, v, \omega)$.  
     Si $d[v] > d[u] + \omega(u, v)$, alors :  
     $$
     d[v] = d[u] + \omega(u, v).
     $$  

3. Faire :  
   - Si $d[v] > d[u] + \omega(u, v)$, alors écrire :  
     "Il existe un circuit de poids négatif accessible depuis $s$".  

**Coût :**  
Chaque arête est relâchée $|S|-1$ fois.  
Coût total : $O(|S| \cdot |A|)$.  

**Remarque :**  
Cet algorithme est meilleur que Dijkstra s’il n’y a pas beaucoup d’arêtes.  

