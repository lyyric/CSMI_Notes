## Chapitre 1 ‚Äì Principe du Maximum de Pontryagin (PMP)

**a)** Exemple introductif

Consid√©rons le probl√®me d‚Äôoptimisation :
$$
\inf_{u \in L^2(0,T)} J(u)
$$
o√π
$$
J(u) = \frac{1}{2} \int_0^T \big(x_u(s) - 1\big)^2 , ds
$$
et $x_u$ est la solution de

$$
\begin{cases}
- x_u'' + x_u = u & \text{sur } (0,1), \\
  x_u(0) = x_u(1) = 0.
\end{cases}
$$

**Calculons le gradient de $J$**,
c‚Äôest-√†-dire l‚Äôunique √©l√©ment de $L^2$, not√© $\nabla J(u)$,
tel que
$$
DJ(u),h = \langle \nabla J(u), h \rangle_{L^2}
$$
(th√©or√®me de Riesz)

et
$$
DJ(u),h = \lim_{\varepsilon \to 0} \frac{J(u + \varepsilon h) - J(u)}{\varepsilon}.
$$
---

**Calculons la d√©riv√©e directionnelle :**

$$
\frac{J(u+\varepsilon h) - J(u)}{\varepsilon}
= \frac{1}{2} \int_0^T \frac{(x_{u+\varepsilon h}(s) - 1)^2 - (x_u(s) - 1)^2}{\varepsilon} , ds
$$
$$
= \frac{1}{2} \int_0^T \frac{(x_u(s) + \varepsilon x_h(s) - 1)^2 - (x_u(s) - 1)^2}{\varepsilon} , ds
$$
$$
= \frac{1}{2} \int_0^T \frac{2 \varepsilon x_h(s)(x_u(s) - 1) + \varepsilon^2 x_h(s)^2}{\varepsilon} , ds
$$
$$
= \frac{1}{2} \int_0^T \left(2 x_h(s)(x_u(s) - 1) + \varepsilon x_h(s)^2\right) ds
$$
Quand $\varepsilon \to 0$ :
$$
\int_0^T x_h(s)(x_u(s) - 1), ds = DJ(u) , h
$$

**Remarque :**

On d√©finit alors l‚Äôapplication lin√©aire
$$
h \mapsto \int_0^T x_h(s)(x_u(s) - 1) , ds
$$
qui est une **forme lin√©aire continue**, c‚Äôest-√†-dire :
$$
\exists, C > 0,\ \forall h \in L^2, \quad |DJ(u),h| \leq C \|h\|_{L^2}.
$$
Autrement dit,
$$
\Big| \int_0^T x_h(s)(x_u(s) - 1), ds \Big| \le C \|h\|_{L^2}.
$$

---

On avait :
$$
DJ(u),h = \int_0^T x_h(s),(x_u(s) - 1), ds
$$
Pour montrer que cette forme lin√©aire est **continue**, on utilise l‚Äôin√©galit√© de Cauchy‚ÄìSchwarz :
$$
\Big|\int_0^T x_h(s)(x_u(s) - 1), ds \Big|
\le
\sqrt{\int_0^T x_h(s)^2, ds}\times
\sqrt{\int_0^T (x_u(s) - 1)^2, ds}
$$
$$
\le C_u |x_h|_{L^2} \quad \text{o√π} C_u = |x_u - 1|_{L^2}.
$$
---

Or $x_h$ est la solution du probl√®me diff√©rentiel :
$$
\begin{cases}
- x_h'' + x_h = h, \\
  x_h(0) = x_h(1) = 0.
\end{cases}
$$
On multiplie l‚Äô√©quation par $x_h$ et on int√®gre par parties :
$$
\int_0^T \big( (x_h')^2 + x_h^2 \big), ds = \int_0^T x_h h , ds.
$$
D‚Äôo√π :
$$
|x_h|_{L^2}^2 \le |x_h|_{H^1_0}^2 = \int_0^T x_h h \le |x_h|_{L^2}|h|_{L^2}.
$$
$$
\Rightarrow |x_h|_{L^2} \le |h|_{L^2}.
$$
---

Ainsi :
$$
|DJ(u),h| \le C_u |h|_{L^2}.
$$
Donc la forme est bien **continue sur $L^2$**.

---

**Conclusion :**

On peut donc √©crire
$$
DJ(u),h = \int_0^T x_h(s),(x_u(s) - 1), ds
= \langle \text{‚Äútruc‚Äù}, h \rangle_{L^2}.
$$
C‚Äôest-√†-dire que le **gradient** (au sens de Riesz) est :
$$
\nabla J(u) = \text{‚Äútruc‚Äù} = x_u - 1,
$$
o√π le terme $x_h$ est la r√©ponse de l‚Äôop√©rateur diff√©rentiel $(-d^2/dx^2 + I)^{-1}$ appliqu√© √† $h$.

---

**Suite du raisonnement :**

On avait √† la ligne pr√©c√©dente :
$$
DJ(u),h = \int_0^T x_h(s),(x_u(s) - 1),ds.
$$
On veut exprimer cela **sous forme adjointe**, pour identifier le gradient.

---

**Introduction de la fonction $p$ :**

Introduisons la fonction (p) solution de

$$
\begin{cases}
\mathcal{L}^* p = g, \\
p(0) = b_1, \quad p(1) = b_2,
\end{cases}
$$
o√π
$$
\mathcal{L} = -\frac{d^2}{dx^2} + I,
$$
et $\mathcal{L}^*$ d√©signe l‚Äô**op√©rateur adjoint** de $\mathcal{L}$.
$Remarque sur le tableau : *op√©rateur de l‚Äô√©quation*$.

On choisit les conditions aux bords $b_1, b_2$ de fa√ßon appropri√©e,
et on constate que **dans ce cas particulier,**
$$
\mathcal{L}^* = \mathcal{L} = -\frac{d^2}{dx^2} + I.
$$
---

**√âquation explicite pour $p$ :**
$$
\begin{cases}
- p'' + p = g, \\
  p(0) = b_1, \quad p(1) = b_2.
  \end{cases}
$$
---

**Calcul par int√©gration par parties :**

On multiplie l‚Äô√©quation de (p) par $x_h$, puis on int√®gre par parties :
$$
\int_0^T (-p'' + p),x_h
= \int_0^T g,x_h
$$
$$
\Rightarrow
\int_0^T p',x_h'

* p(T),x_h'(T)

- p'(0),x_h(0)
- \int_0^T p,x_h
  = \int_0^T g,x_h.
$$
Dans notre probl√®me particulier, les conditions aux bords sont nulles : $x_h(0)=x_h(1)=0$, donc les termes de bord s‚Äôannulent.

---

**Suite : identification du gradient via l‚Äô√©quation adjointe**

On multiplie l‚Äô√©quation de $x_h$ par (p), et on int√®gre par parties :
$$
\int_0^T x_h'',p
= -x_h'(T)p(T) + x_h'(0)p(0) + \int_0^T x_h' p',ds
$$
et donc :
$$
\int_0^T (-x_h'' + x_h)p
= \int_0^T h,p.
$$
---

Comme $-x_h'' + x_h = h$, on obtient :
$$
\int_0^T x_h' p' + x_h p = \int_0^T h,p.
$$
Si on choisit les conditions aux bords $p(0)=p(1)=0$, les termes de bord disparaissent.

---

**Comparaison avec la d√©finition de $DJ(u),h$**

On avait pr√©c√©demment :
$$
DJ(u),h = \int_0^T x_h(x_u - 1),ds.
$$
On choisit donc :
$$
g = x_u - 1.
$$
Or, par d√©finition de (p),
$$
* p'' + p = g = x_u - 1.
$$
---

**Conclusion :**

Ainsi :
$$
DJ(u),h = \int_0^T h,p.
$$
Donc, par identification :
$$
\nabla J(u) = p,
$$
o√π (p) est la solution de l‚Äô√©quation **adjointe** :
$$
\begin{cases}
- p'' + p = x_u - 1,\\
  p(0) = p(1) = 0.
  \end{cases}
$$
---

**Remarque ‚Äî R√©solution num√©rique**

Si on souhaite **r√©soudre num√©riquement** le probl√®me
$$
\inf_{u \in L^2(0,T)} J(u),
$$
on utilise le fait que
$$
\nabla J(u) = p,
$$
o√π (p) est la **solution de l‚Äô√©quation adjointe**.

---

### ‚öôÔ∏è **Algorithme de descente de gradient**

On peut donc appliquer une **m√©thode de descente de gradient** :
$$
\text{Donn√© : } u_0 \in L^2(0,T), \ \varepsilon > 0
$$
$$
\text{Pour } k = 0,1,2,\dots :
\begin{cases}
- x_{u_k}'' + x_{u_k} = u_k, & x_{u_k}(0)=x_{u_k}(T)=0, \\
- p_k'' + p_k = x_{u_k} - 1, & p_k(0)=p_k(T)=0, \\
  u_{k+1} = u_k - \varepsilon p_k.
  \end{cases}
$$
Ici :

* la premi√®re √©quation est **l‚Äô√©tat direct**,
* la seconde est **l‚Äô√©tat adjoint**,
* la troisi√®me est **la mise √† jour du contr√¥le** par descente de gradient.

---

### üí° **Remarques √† droite du tableau**

* $p$ satisfait l‚Äô**√©quation adjointe** :
$$
-p'' + p = x_u - 1, \quad p(0) = p(T) = 0.
$$
* Cette √©quation est appel√©e *l‚Äô√©quation adjointe* notation : ¬´ Rq. L‚Äô√©quation de $p$ s‚Äôappelle l‚Äô√©quation adjointe ¬ª.

---

### üîπ **2) Probl√®me LQ**

**On consid√®re un syst√®me lin√©aire autonome**

((T > 0))
$$
\begin{cases}
\dot{x}*u = A x_u + B u,\\
x_u(0) = x_0 \in \mathbb{R}^n,
\end{cases}
$$
avec $A \in M_n(\mathbb{R}),; B \in M*{n,m}(\mathbb{R})$.

---

### **On introduit la fonction co√ªt**
$$
J : L^2([0,T];\mathbb{R}^m) \to \mathbb{R}
$$
d√©finie par
$$
J(u) = \frac{1}{2} \Big(
\int_0^T \big[ \langle Q x_u, x_u \rangle + \langle R u, u \rangle \big],dt

* \langle M x_u(T), x_u(T) \rangle
  \Big),
$$
  o√π $Q \in S^+(n),\ R \in S^{++}(m),\ M \in S^+(n)$.

---

### **avec**

* $S^+(n)$ : ensemble des matrices de $\mathbb{R}^{n\times n}$ sym√©triques semi-d√©finies positives,
  c.-√†-d. $\langle Mx, x\rangle \ge 0,\ \forall x \in \mathbb{R}^n$.
* $S^{++}(n)$ : ensemble des matrices sym√©triques d√©finies positives,
  c.-√†-d. $\langle Mx, x\rangle > 0,\ \forall x \ne 0.$

---

### **Remarque compl√©mentaire**

On note aussi :

* $S(n)$ : ensemble des matrices sym√©triques r√©elles $n\times n$,
* $S^+(n)\subset S(n)$ : celles dont les valeurs propres sont $\ge 0$,
* $S^{++}(n)\subset S^+(n)$ : celles dont les valeurs propres sont (>0).

---

**Rappel :**

Si $M \in S^{+}(n,\mathbb{R})$, alors
$$
M = P^{T} D P,
$$
o√π $D = \mathrm{diag}(\lambda_1, \ldots, \lambda_n)$ et (P) est une matrice orthogonale de $\mathbb{R}^{n\times n}$.

---

Pour tout $x \in \mathbb{R}^n$ :
$$
\langle Mx, x \rangle
= \langle P^{T} D P x, x \rangle
= \langle D P x, P x \rangle
= \sum_{i=1}^n \lambda_i y_i^2,
$$
o√π $y = P x$.

---

Soit $M \in S^{+}(n, \mathbb{R})$.
Alors il existe $\lambda_i > 0$ pour tout (i).

Sans perte de g√©n√©ralit√©, on suppose :
$$
0 < \lambda_{\min} \le \lambda_i \le \lambda_{\max}.
$$
---

On en d√©duit :
$$
\lambda_{\min} \sum_i y_i^2
\le \sum_i \lambda_i y_i^2
\le \lambda_{\max} \sum_i y_i^2.
$$
Ce qui est √©quivalent √† :
$$
\lambda_{\min} |x|^2
\le \langle Mx, x \rangle
\le \lambda_{\max} |x|^2.
$$
---

### Conclusion

Donc :
$$
\sqrt{\langle Mx, x \rangle}
$$
est **une norme √©quivalente** √† la norme euclidienne (|x|).

*(mention sur le tableau : ¬´ la norme euclidienne ¬ª entre parenth√®ses)*

---

**a) Existence et unicit√©**

#### **Rappel :**

Une **fonction faiblement semi-continue inf√©rieurement** (f.s.c.i.)
v√©rifie que pour toute suite $(u_n)*n$,
$$
\liminf_{n\to\infty} J(u_n)
\ge J\Big(\lim_{n\to\infty} u_n\Big)
\quad\text{(ou plus petit valeur inf√©rieure).}
$$
Autrement dit :
$$
\liminf_{n\to\infty} J(u_n)
= \lim_{N\to\infty} \inf_{n\ge N} J(u_n).
$$
---

*Un petit dessin sur le tableau illustre une suite oscillante qui converge faiblement, montrant visuellement la notion de ¬´ lim inf ¬ª par rapport √† la limite ordinaire.*

---

### **Th√©or√®me :**

Le **probl√®me LQ**
$$
\begin{cases}
\inf J(u),\\
u \in L^2(0,T;\mathbb{R}^m),
\end{cases}
$$
poss√®de **une unique solution**.

---

### **Preuve (esquisse) :**

On suit la **m√©thode directe du calcul des variations**.

**M√©thode directe ‚Äì √âtapes de la preuve**

#### 1Ô∏è‚É£ On consid√®re une suite minimisante $(u_k)_k$

c‚Äôest-√†-dire :
$$
J(u_k) \to \inf J \quad \text{dans } L^2(0,T).
$$
---

#### 2Ô∏è‚É£ On montre que $(u_k)$ converge pour une certaine topologie

par exemple, la **topologie faible** de $L^2$ :
$$
u_k \rightharpoonup u \quad \text{faiblement dans } L^2
\quad \Leftrightarrow \quad
\langle u_k, \psi \rangle_{L^2} \to \langle u, \psi \rangle_{L^2}.
$$
---

#### 3Ô∏è‚É£ On v√©rifie que (J) est **semi-continue inf√©rieurement** pour cette topologie :
$$
u_k \rightharpoonup u
\Rightarrow
\liminf_{k\to\infty} J(u_k) \ge J(u).
$$
---

### **Compacit√© de $u_k$**

On veut extraire une **sous-suite convergente** de $(u_k)$.

Comme $(J(u_k))_k$ est convergente,
il existe $C > 0$ tel que :
$$
\forall k, \quad |J(u_k)| \le C.
$$
---

On a, pour tout $x$ et $u$ :
$$
\langle Q x, x \rangle > 0,
\quad
\langle R u, u \rangle > 0,
$$
avec $Q, R \in S_n^{+}$.


D‚Äôo√π, pour tout $u \in L^2$,
$$
J(u) \ge \frac{1}{2} \int_0^T \langle R u, u \rangle.
$$
Or, pour tout $v \in \mathbb{R}^m$,
$$
\langle Rv, v \rangle \ge \lambda_{\min} |v|^2,
$$
o√π $\lambda_{\min}$ est la **plus petite valeur propre** de $R$.

---

Il vient donc :
$$
J(u) \ge \frac{1}{2} \lambda_{\min} \int_0^T |u(t)|^2,dt
= \frac{1}{2} \lambda_{\min} |u|_{L^2(0,T)}^2.
$$
---

On en d√©duit que $(u_k)$ est **born√©e** dans $L^2(0,T)$.


Donc, il existe $u \in L^2$
tel que, √† une sous-suite pr√®s,
$$
u_k \rightharpoonup u.
$$
---

### **Propri√©t√© de continuit√© de (J)**

On a la solution d‚Äô√©tat :
$$
x_u(t) = e^{tA} x_0 + \int_0^t e^{(t-s)A} B u(s),ds.
$$
La (j)-√®me composante de $x_u(t)$ est :
$$
\langle x_u(t), e_j \rangle_{\mathbb{R}^n}
= \langle e^{tA} x_0, e_j \rangle

* \int_0^t \langle u(s), B^T e^{(t-s)A^T} e_j \rangle, ds.
$$
---

$$
\Rightarrow
\langle e^{tA} x_0, e_j \rangle

* \int_0^t \langle u_k(s), B^T e^{(t-s)A^T} e_j \rangle, ds
  \longrightarrow
  \langle e^{tA} x_0, e_j \rangle
* \int_0^t \langle u(s), B^T e^{(t-s)A^T} e_j \rangle, ds
$$
  c‚Äôest-√†-dire :
$$
x_{u_k}(t) \to x_u(t)
$$
---

Donc $x_{u_k}$ **converge simplement vers** $x_u$.

---

On en d√©duit, par le **th√©or√®me de convergence domin√©e** :
$$
\int_0^T \langle Q x_{u_k}, x_{u_k} \rangle
\longrightarrow
\int_0^T \langle Q x_u, x_u \rangle,
$$
et, par convergence simple :
$$
\langle M x_{u_k}(T), x_{u_k}(T) \rangle
\longrightarrow
\langle M x_u(T), x_u(T) \rangle.
$$
---


On traite le terme :
$$
\int_0^T \langle R u_k, u_k \rangle.
$$
---

Consid√©rons :
$$
\Phi(u) = \int_0^T \langle R u, u \rangle,
$$
et $F : x \in \mathbb{R}^m \mapsto \langle R x, x \rangle \in \mathbb{R}.$

---

On a :
$$
\nabla^2 F = 2R \in S_m^{++}(\mathbb{R}).
$$
Donc (F) est **strictement convexe**.

---

Pour tout $u, v \in L^2$ et tout $\varepsilon \in (0,1)$,
on d√©finit
$$
\Phi(\varepsilon u + (1-\varepsilon)v)
= \int_0^T F(\varepsilon u + (1-\varepsilon)v).
$$
Or,
$$
F(\varepsilon u + (1-\varepsilon)v)
\le
\varepsilon F(u) + (1-\varepsilon) F(v)
$$
car $F$ est convexe, donc
$$
\Phi(\varepsilon u + (1-\varepsilon)v)
\le
\varepsilon \Phi(u) + (1-\varepsilon) \Phi(v).
$$
---

Donc **$\Phi$ est convexe.**

---

Montrons que $\Phi$ est **continue pour la topologie faible de $L^2$**.

Soit $v_k \rightharpoonup v$ dans $L^2$.

---

On a :
$$
\Phi(v_k) - \Phi(v)
= \int_0^T \big( \langle R v_k, v_k \rangle - \langle R v, v \rangle \big)
= \int_0^T \langle R (v_k - v), v_k - v \rangle

* 2 \int_0^T \langle R (v_k - v), v \rangle.
$$
---

On obtient donc :
$$
|\Phi(v_k) - \Phi(v)|
\le M \int_0^T |v_k - v|^2

* 2C \int_0^T |v_k - v| |v|.
$$
Les deux termes tendent vers (0) lorsque $v_k \rightharpoonup v$,

Donc $\Phi$ est continue dans $L^2$.

**Conclusion :**
$\Phi$ est **semi-continue inf√©rieurement (s.c.i.)** dans $L^2$ fort,
et comme $\Phi$ est convexe, elle est aussi **s.c.i. dans $L^2$ faible.**

---

Comme (J) est somme de fonctions :

* continues pour la topologie faible,
* et s.c.i. pour la topologie faible,

alors **(J) est s.c.i. pour la topologie faible**.

---

Donc
$$
J(u) = \lim_{k\to\infty} J(u_k)
= \liminf_{k\to\infty} J(u_k)
\Rightarrow J(u) = \inf J.
$$
On en d√©duit que (u) **minimise (J)**.

---

### **Unicit√© :**

On a
$$
G : u \mapsto \int_0^T \langle R u, u \rangle
$$
est **strictement convexe**.

De m√™me,
$$
G : x \mapsto \int_0^T \langle Q x_u, x_u \rangle
$$
est aussi **strictement convexe**.


On a :
$$
\frac{d}{dt}(x_{u+v}) = A x_{u+v} + B(u+v)
$$
et plus g√©n√©ralement, pour tout $\lambda \in [0,1]$ :
$$
\frac{d}{dt}(x_{u + \lambda v}) = A x_{u + \lambda v} + B(u + \lambda v),
$$
avec $x_{u+\lambda v}(0) = x_0.$

---

De plus :
$$
\begin{cases}
\dot{x}*{u+\lambda v} = A x*{u+\lambda v} + B$u+\lambda v$,\
x_{u+\lambda v}(0) = x_0.
\end{cases}
$$
Par **unicit√©** de la solution du syst√®me diff√©rentiel,
on a :
$$
x_{u+\lambda v} = x_u + \lambda x_v.
$$
---


Donc $G$ est **convexe**
(par composition d‚Äôune fonction convexe avec une fonction lin√©aire).

---

M√™me argument pour montrer que :
$$
u \mapsto \langle M x_u(T), x_u(T) \rangle
$$
est **convexe**.

---

Comme **somme de fonctions convexes**,
et comme $J = G + \Phi$,
et que $\Phi$ est **strictement convexe**,
on en d√©duit que **$J$ est strictement convexe**.

### **c) PMP**

*Principe du Maximum de Pontryagin*

#### **Pr√©liminaire :**

Soit $F : \mathbb{R}^m \to \mathbb{R}$ d√©fini par
$$
F(z) = \langle Rz, z \rangle.
$$
Calculons sa diff√©rentielle :
$$
DF(z),h = \lim_{\varepsilon \to 0}
\frac{F(z + \varepsilon h) - F(z)}{\varepsilon}.
$$
---

On a :
$$
F(z + \varepsilon h) - F(z)
= \langle R(z + \varepsilon h), z + \varepsilon h \rangle

* \langle Rz, z \rangle
  = 2\varepsilon \langle Rz, h \rangle + \varepsilon^2 \langle Rh, h \rangle.
$$
D‚Äôo√π :
$$
DF(z),h = 2 \langle Rz, h \rangle.
$$
Ainsi :
$$
\nabla F(z) = 2Rz.
$$
---

### **Conditions d‚Äôoptimalit√©**

On cherche maintenant les **conditions n√©cessaires d‚Äôoptimalit√©** pour $J(u)$.

Soit (u) une solution du probl√®me d‚Äôoptimisation,
et $x_u$ l‚Äô√©tat associ√© :
$$
\dot{x}_u = A x_u + B u, \quad x_u(0) = x_0.
$$
---

On consid√®re une **perturbation** :
$$
v = u + \varepsilon h, \quad y = x_v - x_u,
$$
d‚Äôo√π :
$$
\dot{y} = A y + B h, \quad y(0) = 0.
$$
---

### **Suite du PMP (Principe du Maximum de Pontryagin)**

On consid√®re la variation du co√ªt :
$$
J(v) - J(u) = \frac{1}{2\varepsilon} [J(u + \varepsilon h) - J(u)].
$$
---

En d√©veloppant :
$$
J(v) - J(u)
= \frac{1}{2} \int_0^T \Big(
\langle Q(x_u + \varepsilon y), (x_u + \varepsilon y) \rangle

* \langle Qx_u, x_u \rangle
  \Big),dt

- \frac{1}{2} \int_0^T
  \big( \langle R(u + \varepsilon h), (u + \varepsilon h)\rangle - \langle Ru, u \rangle \big),dt
- \frac{1}{2} \big(
  \langle D(x_u + \varepsilon y)(T), x_u(T) + \varepsilon y(T)\rangle - \langle D x_u(T), x_u(T)\rangle
  \big).
$$
---

En d√©veloppant et simplifiant, on obtient :
$$
\frac{J(v) - J(u)}{\varepsilon}
= \int_0^T \big( \langle Qx_u, y\rangle + \langle R u, h\rangle \big),dt

* \langle D x_u(T), y(T)\rangle
* O(\varepsilon).
$$
---

### **Introduction de l‚Äô√©tat adjoint :**

Soit $p_u$ la fonction **adjointe**, solution de :
$$
\begin{cases}
-\dot{p}_u - A^T p_u = Q x_u,\\
p_u(T) = D x_u(T).
\end{cases}
$$
---

On multiplie la premi√®re √©quation par (y) et on int√®gre :
$$
\int_0^T \langle \dot{p}_u, y\rangle + \langle A^T p_u, y\rangle
= - \int_0^T \langle Qx_u, y\rangle.
$$
---

### **Suite du calcul (Principe du Maximum de Pontryagin ‚Äì PMP)**

On **int√®gre par parties** :
$$
-\int_0^T \langle \dot{p}_u, y\rangle
= -\big[\langle p_u, y\rangle \big]_0^T + \int_0^T \langle p_u, \dot{y}\rangle.
$$
D‚Äôapr√®s l‚Äô√©quation de (y) :
$$
\dot{y} = A y + B h, \quad y(0) = 0,
$$
et les conditions de $p_u$ :
$$
-\dot{p}_u - A^T p_u = Qx_u, \quad p_u(T) = D x_u(T),
$$
on obtient :
$$
\langle p_u(T), y(T)\rangle

* \int_0^T \langle Qx_u, y\rangle
  = \int_0^T \langle h, B^T p_u\rangle.
$$
---

### **Variation du co√ªt**
$$
DJ(u),h
= \int_0^T \big( \langle R u, h\rangle + \langle B^T p_u, h\rangle \big),dt.
$$
D‚Äôo√π :
$$
\nabla J(u) = R u + B^T p_u.
$$
---

### **Conditions d‚Äôoptimalit√©**

On veut que :
$$
DJ(u),h = 0 \quad \forall h \in L^2,
$$
c‚Äôest-√†-dire :
$$
R u + B^T p_u = 0.
$$
Ainsi, la **commande optimale** est :
$$
u^* = -R^{-1} B^T p_u.
$$
---

**Suite du PMP ‚Äì conclusion + exemple**

On avait :
$$
\int_0^T \langle \nabla J(u), h \rangle , dt \ge 0, \quad \forall h \in L^2.
$$
En choisissant $h = -\nabla J(u)$, on obtient :
$$
* \int_0^T |\nabla J(u)|^2 , dt \ge 0.
$$
Donc :
$$
\nabla J(u) = 0.
$$
---

### **Th√©or√®me (PMP ‚Äì cas LQ)**

Si (u) est une solution du probl√®me (LQ) et (x) la trajectoire associ√©e,
alors (u) satisfait :
$$
u = -R^{-1} B^T p,
$$
o√π (p) v√©rifie :
$$
\begin{cases}
-\dot{p} = A^T p - Qx,\
p(T) = D x(T).
\end{cases}
$$
---

### **Exemple**

Consid√©rons le cas :
$$
\min_u \frac{1}{2} \int_0^T (x(t)^2 + u(t)^2) , dt,
$$
sous la contrainte :
$$
\dot{x} = u, \quad x(0) = 1.
$$
---

On prend :
$$
n = 1,\quad m = 1,\quad A = (0),\quad B = (1),
$$
et :
$$
R = (1),\quad Q = (1),\quad D = (0).
$$
De plus :
$$
R, Q, D \in S_1^{++}(\mathbb{R}).
$$
---

**Application du PMP √† l‚Äôexemple scalaire $cas (n=m=1)$**

D‚Äôapr√®s le **th√©or√®me**, le probl√®me (LQ) admet une **unique solution**.

L‚Äôoptimum est caract√©ris√© par le syst√®me :
$$
\begin{cases}
\dot{x} = u,\\
\dot{p} = -x,\\
x(0) = 1,\\
p(T) = 0,
\end{cases}
$$
et la **relation d‚Äôoptimalit√©** :
$$
u = -p.
$$
---

En particulier :
$$
\dot{x} = -p, \quad \dot{p} = -x.
$$
D‚Äôo√π :
$$
x'' - x = 0.
$$
---

L‚Äô**√©quation caract√©ristique** est :
$$
r^2 - 1 = 0
\quad\Longrightarrow\quad r = \pm 1.
$$
---

### **Solution g√©n√©rale**
$$
x(t) = \alpha e^{t} + \beta e^{-t}.
$$
---

La condition $x(0) = 1$ donne :
$$
\alpha + \beta = 1.
$$
Donc :
$$
x(t) = \alpha e^{t} + (1-\alpha)e^{-t}.
$$
---

### **Pour $p(t)$**

On a :
$$
p' = -x', \quad p'' = -x'' = -x = u = -p.
$$
D‚Äôo√π :
$$
p'' = -x = -(\alpha e^{t} + \beta e^{-t}),
$$
et la solution g√©n√©rale :
$$
p(t) = \gamma e^{t} + \delta e^{-t}.
$$
---

En utilisant $p' = -x$, on obtient la relation :
$$
\gamma e^{t} - \delta e^{-t}
= -\alpha e^{t} + (\alpha - 1)e^{-t}.
$$
---

**Suite et fin de l‚Äôexemple LQ scalaire**

On avait :
$$
p(t) = \gamma e^{t} + \delta e^{-t},
\quad\text{avec}\quad
\gamma = -\alpha,\ \delta = 1 - \alpha.
$$
---

Donc :
$$
p(t) = -\alpha e^{t} + (1-\alpha)e^{-t}.
$$
---

En utilisant la condition terminale $p(T) = 0$ :
$$
0 = -\alpha e^{T} + (1-\alpha)e^{-T}
$$
$$
\Rightarrow \alpha(e^{T} + e^{-T}) = e^{-T}
\Rightarrow \alpha = \frac{e^{-T}}{e^{T} + e^{-T}}
= \frac{e^{-T}}{2\cosh(T)}.
$$
---

Ainsi :
$$
1 - \alpha = \frac{e^{T}}{e^{T} + e^{-T}}
= \frac{e^{T}}{2\cosh(T)}.
$$
---

### **Expression finale de $p(t)$**
$$
p(t) = -\frac{e^{-T}}{2\cosh(T)} e^{t}

* \frac{e^{T}}{2\cosh(T)} e^{-t}.
$$
$$
\Rightarrow
p(t) = \frac{1}{2\cosh(T)} (e^{T-t} - e^{t-T})
= \frac{\sinh(T-t)}{\cosh(T)}.
$$
---

### **Rappel :**
$$
x = -p', \quad u = -p.
$$
---

Donc :
$$
x(t) = -p'(t) = -\frac{d}{dt}!\left(\frac{\sinh(T-t)}{\cosh(T)}\right)
= \frac{\cosh(T-t)}{\cosh(T)},
$$
et :
$$
\boxed{u(t) = -p(t) = -\frac{\sinh(T-t)}{\cosh(T)}}.
$$
---

Voici la **transcription fid√®le et proprement organis√©e** du contenu du tableau :

---

### **Rappel : Introduction √† l‚ÄôHamiltonien**

On d√©finit la fonction d‚ÄôHamilton :
$$
H : \mathbb{R}^n \times \mathbb{R}^m \times \mathbb{R}^n \to \mathbb{R}
$$
par
$$
H(x, u, p) = \frac{1}{2}\langle R u, u\rangle

* \frac{1}{2}\langle Q x, x\rangle
* \langle p, A x + B u\rangle.
$$
---

### **Les conditions d‚Äôoptimalit√© s‚Äô√©crivent :**
$$
\begin{cases}
\dot{x} = \dfrac{\partial H}{\partial p}
= A x + B u, \\
\dot{p} = -\dfrac{\partial H}{\partial x}
= -Q x - A^T p.
\end{cases}
$$
et la **condition d‚Äôoptimalit√© sur $u$** :
$$
\dfrac{\partial H}{\partial u} = 0
\quad \Longrightarrow \quad
R u + B^T p = 0
\quad \Longrightarrow \quad
u = -R^{-1} B^T p.
$$
---

### **(2) Commande en temps minimal**

Soit le syst√®me :
$$
\begin{cases}
\dot{x} = A x + B u,\\
x(0) = x_0,
\end{cases}
$$
avec $A \in M_n(\mathbb{R}),\ B \in M_{n,m}(\mathbb{R})$.

On cherche (u) dans $L^2(0,T; \mathbb{R}^m)$ $ou (u \in \mathbb{R}^m)$
tel que le syst√®me atteigne un **√©tat final $x(T) = x_f$** en **temps minimal**.

---

**Rappel : condition pour pouvoir atteindre $x_f$ en temps (T)**

Si $U = \mathbb{R}^m$, alors
$$
\operatorname{rg}(B,|,AB,|,A^2B,|,\dots,|,A^{n-1}B) = n
$$
= **condition de contr√¥labilit√©**.

---

Ici, $U$ **n‚Äôest pas n√©cessairement** √©gal √† $\mathbb{R}^m$.

---

On consid√®re :
$$
\inf_{u \in L^2(0,T;U)} T
\quad \text{tel que } \quad x_u(T) = x_f.
$$
---

### **D√©finition :**

L‚Äô**ensemble des points accessibles** √† partir de $x_0$ en un temps (T > 0) est d√©fini par :
$$
A(x_0, T)
= {,x_u(T) \mid u \in L^2(0,T;U),}.
$$
---

### **Th√©or√®me :**

On suppose que (U) est **compact, convexe, non vide** de $\mathbb{R}^m$.

Alors, pour tout (T > 0),
$$
A(x_0, T) \text{ est compact, convexe, et varie contin√ªment par rapport √† } T.
$$
---

### **Th√©or√®me (Existence)**

On suppose (U) **compact**.

Si le point $x_1$ est atteignable avec un contr√¥le √† valeurs dans (U),
alors il existe une **trajectoire minimale** reliant $x_0$ √† $x_1$.

De plus, $u^*$ est n√©cessairement **extr√©mal**, autrement dit :
$$
x^*(t) = x_{u^*}(t).
$$
---

### **Th√©or√®me (Caract√©risation ‚Äì Principe du Maximum de Pontryagin)**

Soit $u^* \in L^2(0,T;U)$ un contr√¥le qui transf√®re $x_0$ en $x_1$ en un temps minimal.

Alors il existe $p \neq 0$, non identiquement nul, tel que le syst√®me adjoint :
$$
p'(t) = -A^T p(t)
$$
soit satisfait, et pour presque tout $s \in [0,T]$,
le contr√¥le $u(s)$ **r√©alise instantan√©ment le maximum du Hamiltonien** :
$$
H(x,p,u) = \langle p(s), A x(s) + B u(s) \rangle.
$$
Autrement dit :
$$
u(s) = \arg\max_{v \in U} \langle p(s), B v \rangle.
$$
---

**Remarque Contr√¥le Bang-Bang**

Comme nous l‚Äôavons vu, une particularit√© du **probl√®me de temps minimal**
est que la **commande optimale** se trouve n√©cessairement
sur le **bord des contraintes** $U$.

---

Lorsque $U$ est un **intervalle de $\mathbb{R}$**,
la commande saute d‚Äôune **extr√©mit√©** √† l‚Äôautre
√† des instants de **commutation**.

On parle alors de **contr√¥le bang-bang**.

---

**Exemple :**
$$
U = [-1, 1].
$$
Sch√©ma de commande rectangulaire alternant entre $+1$ et $-1$

---

### **Exemple : Commande optimale d‚Äôun train**
$$
\begin{cases}
x' = y,\\
y' = v,
\end{cases}
\quad
x(0) = x_0, \ y(0) = y_0,
\quad |v| \leq 1.
$$
---

Ici, on a :
$$
A =
\begin{pmatrix}
0 & 1\\
0 & 0
\end{pmatrix}
,
\qquad
B =
\begin{pmatrix}
0\\
1
\end{pmatrix}
$$.
$$
n = 2,\quad m = 1,\quad U = [-1,1].
$$
---

* Les **valeurs propres** de (A) sont de **partie r√©elle nulle**.
* La matrice de Kalman :
$$
[B | AB] =
  \begin{pmatrix}
  0 & 1\\
  1 & 0
  \end{pmatrix}
$$
  est de **rang 2**,
  donc le **crit√®re de Kalman** est **v√©rifi√©**.

---

**Application du PMP au probl√®me de commande en temps minimal (exemple du train)**

Donc, il **existe une trajectoire en temps minimal**.

Le syst√®me peut √™tre **conduit √† l‚Äôorigine** en **temps fini**.

On note $T^*$ le **temps minimal**,
et $u^*$ la **commande optimale**.

---

D‚Äôapr√®s le **PMP**, il existe $p \neq 0$ telle que :
$$
\dot{p} = -A^T p.
$$
Dans notre cas :
$$
A =
\begin{pmatrix}
0 & 1\\
0 & 0
\end{pmatrix}
\quad \Longrightarrow \quad
-A^T =
\begin{pmatrix}
0 & 0\\
-1 & 0
\end{pmatrix}.
$$
---

Donc :
$$
p(s) = e^{-A^T s} p_0
= e^{\begin{pmatrix} 0 & 0 \\ -1 & 0 \end{pmatrix} s} p_0
= \begin{pmatrix} p_1(s) \\ p_2(s) \end{pmatrix}.
$$
---

Et pour presque tout (s) :
$$
u(s) = \arg\max_{v \in [-1,1]} \langle p(s), B v \rangle,
\quad B = \begin{pmatrix} 0 \\ 1 \end{pmatrix}.
$$
$$
\Rightarrow\ u(s) = \arg\max_{v \in [-1,1]} p_2(s) , v.
$$
---

### **R√®gle de commande :**
$$
\begin{cases}
\text{si } p_2(s) > 0 \Rightarrow u(s) = +1,\\
\text{si } p_2(s) < 0 \Rightarrow u(s) = -1.
\end{cases}
$$
---

‚ö†Ô∏è Si $p_2(s) = 0$ sur une partie de mesure positive,
alors cette partie du contr√¥le s‚Äôappelle un **arc singulier**.

---

**Question : l‚Äôensemble des (s) tels que $p_2(s)=0$**

Peut-il √™tre d‚Äôune **mesure positive** ?

---

On a le syst√®me adjoint :
$$
\begin{cases}
p_1' = 0,\\
p_2' = -p_1.
\end{cases}
$$
---

Donc :
$$
\exists, p_1^0, p_2^0 \in \mathbb{R} \text{ tels que }
\begin{cases}
p_1(s) = p_1^0,\\
p_2(s) = -p_1^0 s + p_2^0.
\end{cases}
$$
---

Comme $p$ est non nul, on a $(p_1^0, p_2^0) \neq (0,0)$.

---

**√âtude de l‚Äôensemble**
$$
E = \{ s \mid p_2(s) = 0 \}
= \{ s \mid -p_1^0 s + p_2^0 = 0 \}.
$$
---

C‚Äôest donc un **singleton** :
$$
E = \left\{ \frac{p_2^0}{p_1^0} \right\}
$$
Sa mesure est donc **nulle** :
$$
|E| = 0.
$$
---

**Conclusion :**
$$
u(s) =
\begin{cases}
+1, & \text{si } p_2(s) = -p_1^0 s + p_2^0 > 0,\\
-1, & \text{si } p_2(s) = -p_1^0 s + p_2^0 < 0.
\end{cases}
$$
---

On en d√©duit que $u$ est **bang-bang**
avec **un seul point de commutation**.

---

1Ô∏è‚É£ Si $u(s) = +1$ pr√®s de $T$, alors :
$$
\begin{cases}
x' = y,\\
y' = u = +1,
\end{cases}
$$
d‚Äôo√π :
$$
\begin{cases}
y(s) = s - T \le 0,\\
x(s) = \dfrac{1}{2}s^2 - Ts + \dfrac{1}{2}T^2
= \dfrac{1}{2}(s - T)^2.
\end{cases}
$$
$$
x(T) = y(T) = 0.
$$
---

2Ô∏è‚É£ Si $u(s) = -1$ pr√®s de $T$, alors :
$$
\begin{cases}
x' = y,\\
y' = u = -1,
\end{cases}
$$
donc :
$$
\begin{cases}
y(s) = -s + T,\\
x(s) = -\dfrac{1}{2}s^2 + Ts - \dfrac{1}{2}T^2
= -\dfrac{1}{2}(s - T)^2 + 1.
\end{cases}
$$
$$
x(T) = y(T) = 1.
$$
---

**Cas 1 : $u(s) = +1$ pr√®s de $0$**
$$
\begin{cases}
y'(s) = u = +1,\\
x'(s) = y,\\
x(0) = x_0,\ y(0) = y_0.
\end{cases}
$$
On en d√©duit :
$$
\begin{cases}
y(s) = s + y_0,\\
x(s) = \dfrac{1}{2}s^2 + y_0 s + x_0.
\end{cases}
$$
---

**Cas 2 : $u(s) = -1$ pr√®s de $0$**
$$
\begin{cases}
y'(s) = -1,\\
x'(s) = y,\\
x(0) = x_0,\ y(0) = y_0.
\end{cases}
$$
Donc :
$$
\begin{cases}
y(s) = -s + y_0,\\
x(s) = -\dfrac{1}{2}s^2 + y_0 s + x_0
= -\dfrac{1}{2}(y_0 - y)^2 + y_0 (y_0 - y) + x_0.
\end{cases}
$$
---

