# 应用性能概念

---

## 目录
1. 引言
2. 性能测量
3. 性能分析
4. 使用 MPI 的应用

---

## 1. 引言

### 引言

假设我们编写了一个并行程序。在单核上运行需要 **T₁** 秒，而在 **N** 核上并行运行需要 **$T_{N}$** 秒。

**加速比（Speedup）** 定义为：
$$ A(N) = \frac{T_1}{T_N} $$

在理想情况下，我们期望加速比 **$A(N)$** 为 **$N$**。

然而，实际测量中我们发现：
![加速比图](https://via.placeholder.com/400x200?text=加速比图)

**目标**：理解为什么我们很少能达到理想的加速比，并学习如何提升并行应用的性能。

---

## 2. 性能测量

### 时间测量

衡量程序性能的参考标准是测量程序的执行时间。我们可以定义多种“时间”：

- **执行时间（$T_{exe}$）**：程序从开始执行到结束所经历的物理时间。包括 CPU 时间、I/O 时间、内存访问时间以及系统中其他任务所占用的时间。
- **CPU 时间（$T_{CPU}$）**：程序实际在处理器上执行所花费的时间。包括用户时间和系统时间。
- **用户时间（$T_{user}$）**：用户程序执行指令所花费的时间。

关系：
$$ T_{user} \leq T_{CPU} \leq T_{exe} $$

### 生产率

**生产率（P）** 定义为在给定时间内完成的工作量。关系式为：
$$ W = P \cdot T_{exe}$$
其中，**W** 是程序执行的指令数量。

进一步关系：
$$ T_{exe} = \frac{W \cdot CPI}{F} $$
- **CPI**：每条指令的时钟周期数，取决于指令集架构（ISA）。
- **F**：处理器频率，取决于硬件。

**示例练习**：

一个程序在机器 A 上运行 10 秒，处理器频率为 4GHz。工程师提议开发一台机器 B，使用新处理器在 6 秒内执行该程序，但这些处理器的架构每条指令需要多 1.2 个周期。请问机器 B 的处理器频率应选择多少？

**注意**：
- 性能不仅依赖于程序，还依赖于运行程序的架构以及程序与架构的适配。例如，优先考虑 CPU 计算性能而非内存访问，选择高效的基本操作等。

---

## 3. 性能分析

### 并行性能

对于并行程序，我们定义以下性能指标：

- **加速比（A(N)）**：
  $$ A(N) = \frac{T₁}{T_{N}} $$
  可能出现超线性加速（superlinear speedup），通常由于缓存效果或加速器的使用，也可能由于算法复杂度变化（如从线性变为平方级别等）。
  
- **效率（E(N)）**：
  $$ E(N) = \frac{A(N)}{N} $$
  
- **强可扩展性（Strong Scalability）**：程序在固定总工作量 **W** 下，随着处理器数量增加，保持高效的能力。通过加速比或效率随处理器数量变化来分析。

- **弱可扩展性（Weak Scalability）**：程序在每个处理器上保持固定工作量 **W/N**，随着处理器数量增加，总工作量 **W** 也相应增加，程序执行时间应保持不变。

### 加速比的类型

- **线性加速比（Linear Speedup）**：最佳并行性，A(N) = N。
- **超线性加速比（Superlinear Speedup）**：A(N) > N，可能由于缓存优化或其他硬件加速因素。
- **亚线性加速比（Sublinear Speedup）**：A(N) < N，通常由于通信开销、负载不均或并行不可分的部分。

### Amdahl 定律

**Amdahl 定律** 描述了程序加速的理论上限，基于程序中不可并行的部分。

假设：
- **σ(W)**：程序中不可并行的部分所需的时间。
- **φ(W)**：程序中可并行的部分所需的时间。
- **A(N)**：加速比。

对于 **N** 个处理器：
$$ A(N) = \frac{T₁}{T_{N}} \leq \frac{\sigma(W) + \phi(W)}{\sigma(W) + \frac{\phi(W)}{N}} = \frac{1}{s + \frac{1 - s}{N}} $$
其中，$$ s = \frac{\sigma(W)}{\sigma(W) + \phi(W)} $$ 为程序中不可并行部分的比例。

**练习**：

1. 对于大数量的处理器，A(N) 的理论极限是多少？
2. 如果程序中 90% 可并行，8 个处理器的最大理论效率是多少？

**解答**：

1. 当 **N** 趋近于无穷大时：
   $$ A(N) \leq \frac{1}{s} $$
   
2. 设 **s = 10%**：
   $$ E(N) = \frac{A(N)}{N} = \frac{1}{s \cdot N} $$
   当 **N = 8**：
   $$ E(8) = \frac{1}{0.1 \cdot 8} = 1.25 $$
   但根据加速比的定义，实际最大效率为 0.1，即 10%。

**Amdahl 定律的局限性**：
- 假设总工作量 **W** 固定，不随处理器数量增加而增加。
- 没有考虑并行化带来的额外开销，如通信开销。
- 实际情况中，随着 **W** 增加，程序的可并行部分比例可能增加，Amdahl 定律的适用性有限。

### Karp-Flatt 指标

**Karp-Flatt 指标** 用于衡量并行化开销对加速比的影响。

定义：
$$ e(W, N) = \frac{1}{A(N)} - \frac{1}{N} = \frac{\sigma(W) + N \cdot \kappa(W, N)}{T₁(W)} $$
其中：
- **σ(W)**：不可并行部分的时间比例。
- **κ(W, N)**：并行化带来的额外开销。

**指标意义**：
- **e(W, N)** 表示并行化带来的开销。
- 如果 **e(W, N)** 保持不变，说明开销可忽略。
- 如果 **e(W, N)** 随 **N** 增加，则并行化开销对加速比的影响增大。

**练习**：

**基准测试 1**：
$$ 
\begin{array}{c|ccccccc}
N & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
A(N) & 1.82 & 2.50 & 3.08 & 3.57 & 4.00 & 4.38 & 4.71 \\
\end{array}
$$
**问题**：为什么在 8 个处理器上加速比只有 4.71？

**解答**：
计算实验性顺序部分比例 **e(W, N)**：
$$ e(W, N) = 0.1 $$
即 10% 的计算是顺序执行的，开销可忽略不计。因此，主要原因是 10% 的代码不可并行。

---

## 4. 使用 MPI 的应用

### 性能测量

#### 使用 Unix `time` 命令

`time` 命令用于测量命令的执行时间，如 MPI 程序。它会在程序执行结束后显示实际时间、用户 CPU 时间和系统 CPU 时间。

**示例**：

1. **测量整个并行应用的执行时间**：
   ```bash
   user$ time mpiexec -n 4 ./myapp
   real    0m0.618s
   user    0m1.491s
   sys     0m0.229s
   ```

2. **测量每个 MPI 进程的执行时间**：
   ```bash
   user$ mpiexec -n 4 time ./myapp
   0.54 real 0.36 user 0.04 sys
   0.55 real 0.36 user 0.04 sys
   0.55 real 0.36 user 0.04 sys
   0.56 real 0.36 user 0.06 sys
   ```

#### 使用 C++ 标准库 `chrono`

`chrono` 库用于评估代码段的耗时，并以不同单位显示（秒、毫秒、微秒等）。

**示例代码**：

```cpp
#include <iostream>
#include <chrono>
#include <unistd.h>

int main() {
    auto start = std::chrono::steady_clock::now();

    // 执行一些操作
    sleep(3);

    auto end = std::chrono::steady_clock::now();

    std::cout << "Elapsed time in microseconds : "
              << std::chrono::duration_cast<std::chrono::microseconds>(end - start).count()
              << " μs" << std::endl;
    std::cout << "Elapsed time in milliseconds : "
              << std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count()
              << " ms" << std::endl;
    std::cout << "Elapsed time in seconds : "
              << std::chrono::duration_cast<std::chrono::seconds>(end - start).count()
              << " sec" << std::endl;
    return 0;
}
```

### MPI 代码性能分析

一种常见的方法包括：

1. **同步所有进程**：
   ```cpp
   MPI_Barrier(MPI_COMM_WORLD);
   ```
2. **启动计时器**：
   ```cpp
   auto start = std::chrono::steady_clock::now();
   ```
3. **执行代码段**：
   ```cpp
   // 执行部分代码
   ```
4. **停止计时器**：
   ```cpp
   auto end = std::chrono::steady_clock::now();
   ```
5. **计算本地时间**：
   ```cpp
   int localTime = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();
   ```
6. **收集所有进程的最大时间**：
   ```cpp
   int globalTime;
   MPI_Reduce(&localTime, &globalTime, 1, MPI_INT, MPI_MAX, 0, MPI_COMM_WORLD);
   if (rank == 0)
       std::cout << "Elapsed time in milliseconds : " << globalTime << std::endl;
   ```

### 在超级计算机上运行作业

**超级计算机 Gaya** 由多个计算节点（当前 6 个）和一个前端（用于连接）组成。每个节点有 128 个物理计算核心。

**查看作业队列**：
```bash
user$ squeue
JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)
407    public    bash   chabanne R 5:39:03 1 gaya5
408    public    bash   chabanne PD 0:00 4 (Resources)
```

**提交作业脚本（Slurm）**：

```bash
#!/bin/bash
#SBATCH -J my-job             # 作业名称
#SBATCH -N 1                 # 节点数量
#SBATCH -n 12                # 核心数量
#SBATCH -t 00:20:00          # 作业时间
#SBATCH --output=run_%j.out  # 标准输出
#SBATCH --error=run_%j.err   # 错误输出

mpiexec -bind-to core ./myapp
```

**提交作业**：
```bash
user$ sbatch my-job.slurm
```

**注意事项**：
- **前端节点** 不应用于需要大量资源的计算，最好在计算节点上运行作业。
- **Slurm** 是超级计算机常用的任务管理器，根据优先级分配资源。
- **脚本中添加 `#SBATCH --exclusive`** 确保作业独占节点，避免资源冲突。

### 并行排序算法性能测量

**练习**：

1. **创建 CMake 项目**：
   - 添加 MPI 依赖，使用以下命令检测 MPI：
     ```cmake
     find_package(MPI REQUIRED)
     ```
   - 链接可执行文件到 MPI：
     ```cmake
     target_link_libraries(myapp MPI::MPI_CXX)
     ```

2. **添加性能测量代码**：
   - 测量程序的不同部分（顺序部分和并行部分）的执行时间。

3. **设定算法限制**：
   - 确定排序序列的最大长度，选择合适的顺序排序算法。
   - 从单个进程开始，逐步增加进程数量，注意 Scatter 和 Gather 的通信开销。

4. **执行性能测试**：
   - 对给定元素数量（如 10⁹）进行强可扩展性测量，直到 24 个核心。
   - 将测量结果存储为 CSV 文件，以便绘制可扩展性曲线。

5. **测量弱可扩展性**：
   - 固定每个进程的工作量，随着进程数量增加，测量程序执行时间。

---

## 总结

本节内容介绍了应用程序性能的基本概念，包括执行时间的测量、生产率、加速比以及可扩展性。通过 Amdahl 定律和 Karp-Flatt 指标，深入分析了并行化带来的性能提升及其限制。还介绍了如何在 MPI 应用中进行性能测量和分析，以及在超级计算机上运行和管理并行作业的方法。

掌握这些性能概念和分析方法，有助于优化并行程序，提高计算效率，充分利用多核和分布式计算资源。

在后续学习中，我们将继续探讨更多高级性能优化技术，如负载均衡、通信优化以及缓存优化等，以进一步提升并行应用的性能。