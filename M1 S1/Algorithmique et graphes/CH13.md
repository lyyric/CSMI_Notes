**Autre multiplier deux matrices, on souhaite:**
- calculer l'inverse d'une matrice inversible.
- calculer le déterminant d'une matrice.
- résoudre des systèmes linéaires.

**Fait :** Le coût de chacune de ces opérations est comparable au coût de la multiplication de deux matrices.  

**Ex :** Notons $\text{Inv}(n)$ le coût du calcul de l'inverse d'une matrice inversible de taille $n$.  
Alors 
$$
M(n) = O(\text{Inv}(3n))
$$
où $M(n)$ est coût de de la multiplication de deux matrices.

**Si**: $A, B$ sont deux matrices $n \times n$, on pose  
$$
D = \begin{pmatrix} I_n & A & 0 \\ 0 & I_n & B \\ 0 & 0 & I_n \end{pmatrix}
$$

On a  
$$
D^{-1} = \begin{pmatrix} I_n & -A & AB \\ 0 & I_n & -B \\ 0 & 0 & I_n \end{pmatrix}
$$

**On admet que**  
$$
\text{Inv}(n) = O(M(n))
$$
(algèbre linéaire, compléments de Schur)

À quelle condition a-t-on  
$$
\text{Inv}(3n) = O(\text{Inv}(n)) ?
$$

$$
e^{3n} \neq O(e^n)
$$
$$
\log(3n) = \log 3 + \log n = O(\log n)
$$
$$
(3n)^{\alpha} \not\subseteq O(n^{\alpha}), \, \alpha > 1
$$
$$
(3n)^{\alpha} = 3^{\alpha} \cdot n^{\alpha} = O(n^{\alpha})
$$

indép. de $n$
$$
A = (a_{ij})_{1 \leq i,j \leq n}
$$
$$
\text{det} \, A = \sum_{\sigma \in S_n} a_{1\sigma(1)} \cdot ... \cdot a_{n\sigma(n)}
$$
et  $(n! - 1)$ additions, et $(n-1)(n! - 1)$ mult.
$$
n_1 \leq n^2, \, n! \sim \sqrt{2\pi n} \left( \frac{n}{e} \right)^n
$$
$$
n! = 1 \times 2 \times ... \times \frac{n}{2} \times (\frac{n}{2} + 1) ... \times n \, (\text{n pair})
$$
$$
n/2 \, \text{termes} \geq n/2
$$
donc  $n! \geq \left( \frac{n}{2} \right)^{n/2}$.


Meilleure idée pour calculer $\text{det} A$ : pivot de Gauss
$$
A = 
\begin{pmatrix} a_{11} & a_{12} &\ldots &a_{1n} \\ 
a_{21} & & \\ 
\vdots \\
a_{n1} & && A' 
\end{pmatrix}
$$
(sinon, on permute les lignes)

hyp. : $a_{11} \neq 0$

pour $j \geq 2$, $L_j \gets a_{j1}a_{11}^{-1}L_1 - L_j$.

Au plus $2n^2-1$ opérations. ($(n-1) + (n-1)(2(n-1))$)

On obtient 

$$
\begin{pmatrix} a_{11} & a_{12}& \ldots &a_{1n} \\ (0) & & \\ & & A'' \end{pmatrix}
$$

et  $\text{det} A = a_{11} \cdot \text{det } A''$

$D(n)$ : coût du calcul des déterminants

$$
D(n) \leq 2n^2 + D(n-1)
$$

Donc
$$
D(n) \leq 2 \sum_{j=1}^{n} j^2 = O(n^3)
$$
---
$$
\sum_{j=1}^{n} j = \frac{n(n+1)}{2}
$$
$$
\sum_{j=1}^{n} j^2 = \frac{n(n+1)(2n+1)}{6}
$$
$$
\sum_{j=1}^{n} j^3 = \left( \frac{n(n+1)}{2} \right)^2
$$
$$
\sum_{j=1}^{n} j^a = O(n^{a+1})= \frac{n^{a+1}}{a+1} + O(n)
$$
---
$(a \geq 1)$

$x \longmapsto x^a$

Une primitive :

$x \longmapsto \frac{x^{a+1}}{a+1}$

$x \longmapsto x^a$

```tikz
\begin{document}
\begin{tikzpicture}[scale=0.5]
    % 轴
    \draw[->] (0,0) -- (5,0) node[right] {$x$};
    \draw[->] (0,0) -- (0,17) node[above] {};

    % 曲线 y = x^a
    \draw[domain=0:4,smooth,variable=\x,black] plot ({\x},{(\x)^2});

    % 标注
    \node at (4,3.5) {$x^a$};

    % 刻度和点
    \foreach \x in {1,2,3,4}
    {
        \draw (\x,0) -- (\x,-0.1) node[below] {\x};
        \draw (0,\x) -- (-0.1,\x);
        \draw[dashed] (\x,0) -- (\x,\x^2);
    }
    \foreach \x in {1,2,3,4}
    {
        \draw[dashed] (\x,\x^2) -- (0,\x^2);
    }

    % 原点
    \node at (0,0) [below left] {$0$};
\end{tikzpicture}
\end{document}

```

**th.**: Le coût du calcul de $\text{det} A$ est comparable à celui de la mult. de deux matrices de la taille de $A$.

$(D(n) = O(M(n)) \text{ et } M(n) = O(D(n)))$

**Th.**: Toute matrice A s’écrit sous la forme $A = LUP$, où:
- L est une matrice triangulaire inférieure,
- U est une matrice triangulaire supérieure,
- P est une matrice de permutation.

$P$ : un et un seul 1 sur chaque ligne et sur chaque colonne, des 0 ailleurs.

Alors $\text{det } A = (\text{det } L)(\text{det } U)(\text{det } P)$

facile.

**Th.**: Le coût de la décomposition $LUP$ d'une matrice de taille $n$ est comparable à $M(n)$.

Intérêt résoudre des systèmes linéaires.

Données: matrice $A$  
vecteur $\underline{b}$

Pb: trouver $\underline{x}$ tel que $A \underline{x} = \underline{b}$

$$
\begin{cases}
a_{11} x_1 + \ldots + a_{1n} x_n = b_1 \\
a_{21} x_1 + \ldots + a_{2n} x_n = b_2 \\
\ldots \\
\end{cases}
$$

1-ère façon: inverse $A$ !

$\underline{x} = A^{-1} \underline{b}$

$O(n^2)$ opérations

$A = LUP$
$LUP\underline{x} = \underline{b}$
$\underline{y} = P\underline{x}$
$LU\underline{y} = \underline{b}$
$U\underline{y} = \underline{z}$
$L\underline{z} = \underline{b}$
$\implies$ système
$$
\begin{cases}
l_{11} z_1 = b_1 \\
l_{21} z_1 + l_{22} z_2 = b_2 \\
\ldots \\
l_{n1} z_1 + \ldots + l_{nn} z_n = b_n \\
\end{cases}
$$

**Retour** à la multiplication de deux polynômes
$$(a_0 + a_1 X)(b_0 + b_1 X) = a_0 b_0 + (a_1 b_0 + a_0 b_1) X + a_1 b_1 X^2$$
$$P(X) = a_0 + a_1 X$$
$$Q(X) = b_0 + b_1 X$$

Déterminer $R(X) = P(X) Q(X)$

Trouver les coeffs de $R(X)$
$$R(0) = a_0 b_0$$
$$R(1) = (a_0 + a_1)(b_0 + b_1)$$
$$R(\infty) = a_1 b_1$$

$$
R(X) = r_0 + r_1 X + r_2 X^2
$$
$$
R(0) = r_0
$$
$$
R(1) = r_0 + r_1 + r_2
$$
$$
R(\infty) = r_2
$$

**Th.** (Interpolation de Lagrange):  
On se donne n points $(x_j, y_j)$, où les $x_j$ sont distincts. Alors il existe un unique polynôme $P(X)$ de degré au plus $n-1$, tel que
$$P(x_j) = y_j \quad \text{pour } j=1,\ldots,n$$
$$
P(X) = \sum_{j=0}^{n-1} y_j \frac{\prod_{k \neq j} (X - x_k)}{\prod_{k \neq j} (x_j - x_k)}.
$$
---
$$
\begin{pmatrix}
R(0) \\
R(1) \\
R(\infty)
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 \\
1 & 1 & 1 \\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
r_0 \\
r_1 \\
r_2
\end{pmatrix}
$$

$$
\begin{pmatrix}
r_0 \\
r_1 \\
r_2
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 \\
1 & 1 & 1 \\
0 & 0 & 1
\end{pmatrix}^{-1}
\begin{pmatrix}
a_0 b_0 \\
(a_0 + a_1)(b_0 + b_1) \\
a_1 b_1
\end{pmatrix}
$$
$$
=
\begin{pmatrix}
1 & 0 & 0 \\
-1 & 1 & -1 \\
0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
a_0 b_0 \\
(a_0 + a_1)(b_0 + b_1) \\
a_1 b_1
\end{pmatrix}
$$

Le calcul des coeffs $r_0, r_1, r_2$ se ramène à 3 mult $(R(0), R(1), R(\infty))$ et quelques additions.

Les points 0, 1, $\infty$ sont choisis arbitrairement pour que les calculs soient simples.


Autre ex:

$$
\begin{matrix}
P(X) = a_0 + a_1 X + a_2 X^2 \\
Q(X) = b_0 + b_1 X + b_2 X^2 \\
R(X) = P(X) Q(X) \\
K(X) = r_0 + r_1 X + \ldots + r_4 X^4
\end{matrix}
$$

$$
\begin{pmatrix}
R(0) \\
R(1) \\
R(-1) \\
R(-2) \\
R(\infty)
\end{pmatrix}
=
\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
1 & 1 & 1 & 1 & 1\\
1 & -1 & 1 & -1 & 1\\
1 & -2 & 4 & -8 & 16\\
0 & 0 & 0 & 0 & 1
\end{pmatrix}
\begin{pmatrix}
r_0 \\
r_1 \\
r_2 \\
r_3 \\
r_4
\end{pmatrix}
$$
$$
M =
\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
1 & 1 & 1 & 1 & 1\\
1 & -1 & 1 & -1 & 1\\
1 & -2 & 4 & -8 & 16\\
0 & 0 & 0 & 0 & 1
\end{pmatrix}
$$
$$
\begin{pmatrix}
r_0 \\
r_1 \\
r_2 \\
r_3 \\
r_4
\end{pmatrix}
=
M^{-1}
\begin{pmatrix}
R(0) \\
R(1) \\
R(-1) \\
R(-2) \\
R(\infty)
\end{pmatrix}
= M^{-1}
\begin{pmatrix}
a_0 b_0 \\
(a_0 + a_1 + a_2)(b_0 + b_1 + b_2) \\
(a_0 - a_1 + a_2)(b_0 - b_1 + b_2) \\
(a_0 - 2a_1 + 4a_2)(b_0 - 2b_1 + 4b_2) \\
a_2 b_2
\end{pmatrix}
$$

$r_0, r_1, r_2, r_3$ et $r_4$ sont des combinaisons linéaires de $a_0 b_0, (a_0 + a_1 + a_2)(b_0 + b_1 + b_2), \ldots, a_2 b_2$

Bref, ceci montre que l'on peut mult. deux polynômes de degré $\leq 2$ en faisant $5 = 2d + 1$ multiplications (et quelques additions).

En raisonnant ainsi, on voit que l'on peut mult. deux polynômes de degré $d-1$ (à $d$ coeffs) à l'aide de $2d-1$ multiplications et de $a(d)$ additions.

On fixe $d$.

Coût de la mult. de deux polynômes de degré $d^n - 1$ ? (à $d^n$ coeffs)

$d = 2$ : Karatsuba

$d = 3$ : Toom-Cook

$$
\begin{matrix}
&(a_0 + a_1 X + \dots + a_{d^{n-1}-1} X^{d^{n-1}-1})\\
&+(a_{d^{n-1}} X^{d^{n-1}} + \dots + a_{2d^{n-1}-1} X^{2d^{n-1}-1})\\
&+\dots+(a_{(d-1)d^{n-1}} X^{(d-1)d^{n-1}} + \dots + a_{d^n-1} X^{d^n-1})
\end{matrix}
$$

Le mult. de deux polynômes à $d^n$ coeffs se ramène à $(2d-1)$ mult de pol. à $d^{n-1}$ coeffs (plus des additions)

Notons $C_d(d^n)$ le coût de la mult. de deux polynômes à $d^n$ coeffs.

Alors 
$$
C_d(d^n) \leq (2d-1) C_d(d^{n-1}) + A_d \cdot d^n
$$
(nombre d'additions)
$$
C_2(2^n) \leq 3C(2^{n-1}) + 4.2^n
$$

On itère

$$
C_d(d^n) \leq (2d-1) \left( (2d-1) C_d(d^{n-2}) + A_d d^{n-1} \right) + A_d d^n
$$
$$
\leq (2d-1) \left( (2d-1) \left( (2d-1) C_d(d^{n-3}) + A_d d^{n-2} \right) + A_d d^{n-1} \right) + A_d d^n
$$
$$
= (2d-1)^3 C_d(d^{n-3}) + (2d-1)^2 A_d d^{n-2} + (2d-1) A_d d^{n-1} + A_d d^n
$$
(récurrence)
$$
\leq (2d-1)^k C_d(d^{n-k}) + A_d \left( (2d-1)^{k-1} d^{n-k+1} + (2d-1)^{k-2} d^{n-k+2}+\ldots + d^n \right)
$$
$$
\leq (2d-1)^k C_d(d^{n-k-1}) + A_d d^n
$$

$$
\leq (2d-1)^n C_d(1) + A_d \left( d^n + (2d-1) d^{n-1} + \ldots + (2d-1)^{n-1} d \right)
$$
$$
\leq (2d-1)^n + (2d-1)^n A_d \left(\left( \frac{d}{2d-1} \right)^n+ \left( \frac{d}{2d-1} \right)^{n-1} + \ldots + \left( \frac{d}{2d-1} \right)\right)
$$
$$
\leq (2d-1)^n + A_d (2d-1) \left( \frac{1}{1 - \frac{d}{2d-1}} \right)
$$
$$
= O((2d-1)^n)
$$
$$
C_d(d^n) = O((2d-1)^n) = O \left( {d^n}^{\log_{d} (2d-1)} \right)
$$

centré 

$$
C_2(n) = O(n \log^3 n)
$$

général complexité

$$
C_d(n) = O(n^{\log_d (2d-1)})
$$

$$
\log_d (2d-1) = \frac{\log (2d-1)}{\log d} \longrightarrow 1
$$

$d = 3$

$$
\log_{3} 5
$$

$$
\log_{4} 7 < \log_{2} 3
$$

Sous $\epsilon > 0$, il existe un algo. de complexité 

$$
O(n^{1 + \epsilon})
$$

qui mult. $2$ pol. à $n$ coeffs.

---
