{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Partie 1  (sur papier) : Analyse de sensibilité linéaire\n",
    "\n",
    "## Exercice 1 : Analyse du modèle linéaire\n",
    "\n",
    "On suppose que les variables aléatoires $X_i$ sont indépendantes, avec une espérance $E(X_i)$ et une variance $V(X_i)$, pour $i=1,2,\\ldots,p$.\n",
    "On suppose par ailleurs que $Y$ est une fonction affine des variables $X_i$ :\n",
    "$$\n",
    "Y = g(X) = \\beta_0 + \\sum_{i=1,2,\\ldots,p} \\beta_i X_i,\n",
    "$$\n",
    "où $\\beta_i$ sont des paramètres réels, pour $i=1,2,\\ldots,p$.\n",
    "\n",
    "L'espérance de la somme des variables est la somme des espérances, donc\n",
    "\n",
    "\\begin{align*}\n",
    "E(Y) \n",
    "&=& E(\\beta_0) + \\sum_{i=1,2,\\ldots,p} E(\\beta_i X_i) \\\\\n",
    "&=& \\beta_0 + \\sum_{i=1,2,\\ldots,p} \\beta_i E(X_i).\n",
    "\\end{align*}\n",
    "\n",
    "Cette égalité est valable  même si les variables sont corrélées. On suppose les variables indépedantes tout de même pour pouvoir plus tard faire un raisonnement similaire sur les variances.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "Le coefficient de regression standardisé est donné par :\n",
    "\n",
    "$$\n",
    "SRC_i = \\frac{\\beta_i^2 V(X_i)}{V(Y)},\n",
    "$$\n",
    "\n",
    "pour $i=1,2,\\ldots,p$.\n",
    "\n",
    "On observe trivialement que  $SRC_i\\geq 0$, pour $i=1,...,p$. \n",
    "\n",
    "**Question:** Montrez que la somme des coefficients de regression standardisés est égale à 1 :\n",
    "\n",
    "$$\n",
    "SRC_1 + SRC_2 + \\ldots + SRC_p = 1. \\qquad \\textrm{(1)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercice 2 : Corrélation de Pearson et indices SRC\n",
    "\n",
    "On se place dans les mêmes hypothèses que pour l'Exercice 1.\n",
    "\n",
    "La covariance et la corrélation de Pearson sont définies, pour  $i=1,2,\\ldots,p$, par\n",
    "$$\n",
    "Cov(Y,X_i) = E[(Y-E(Y))(X_i-E(X_i))],\n",
    "$$\n",
    "et\n",
    "$$\n",
    "Corr(Y,X_i) = \\frac{Cov(Y,X_i)}{\\sqrt{V(Y)}\\sqrt{V(X_i)}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "**Question 1:** Déterminez $Cov(\\beta_0,X_i)$.\n",
    "\n",
    "**Question 2:** Montrez que $Cov(Y,X_i)=\\beta_i V(X_i)$\n",
    "\n",
    "**Question 3:** En déduire que $Corr(Y,X_i)^2 = SRC_i$ pour $i=1,2,\\ldots,p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : fonction produit\n",
    "\n",
    "On considère la fonction :\n",
    "$$\n",
    "Y:=g(X_1,X_2)=X_1 X_2\n",
    "$$\n",
    "pour tout $X_1,X_2\\in\\mathbb{R}$. \n",
    "On suppose que les variables sont indépendantes.  \n",
    "Pour $i=1,2$, notons $\\mu_i = E(X_i)$ l'espérance et $\\sigma_i^2=V(X_i)$ la variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** On rappelle que $V(X_i)=E(X_i^2) -E(X_i)^2$\n",
    "et $Cov(Y,X_i)=E(YX_i)-E(Y)E(X_i)$. \n",
    "Montrer que \n",
    "$Cov(Y,X_1)= \\sigma_1^2 \\mu_2$ et $Cov(Y,X_2)= \\sigma_2^2\\mu_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Montrer que $V(Y)= \\sigma_1^2 \\sigma_2^2 + \\sigma_1^2 \\mu_2^2 + \\sigma_2^2 \\mu_1^2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** En déduire que $Corr(Y,X_1)=\\dfrac{\\sigma_1 \\mu_2}{\\sqrt{\\sigma_1^2 \\sigma_2^2 + \\sigma_1^2 \\mu_2^2 + \\sigma_2^2 \\mu_1^2}}$\n",
    "et $Corr(Y,X_2)=\\dfrac{\\sigma_2 \\mu_1}{\\sqrt{\\sigma_1^2 \\sigma_2^2 + \\sigma_1^2 \\mu_2^2 + \\sigma_2^2 \\mu_1^2}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complément : Régression linéaire\n",
    "\n",
    "En général, on ne sait pas si la fonction $g$ est linéaire. Dans les méthodes que nous décrivons, la fonction $g$ est une boîte noire dans laquelle la seule information observable est la sortie en fonction de l'entrée. Dans ce cas, on peut créer un modèle de regression linéaire comme une approximation de la fonction $g$. Cela permet ensuite d'utiliser les indices SRC, si le modèle linéaire est de qualité. Nous allons voir que cette qualité peut être quantifiée grâce au coefficient $R^2$. \n",
    "\n",
    "Le vecteur des prédictions du modèle linéaire est une combinaison linéaire des composantes du vecteur $X$ :\n",
    "$$\n",
    "y = \\beta_0 + X^T \\beta + \\epsilon\n",
    "$$\n",
    "où $\\epsilon$ est une variable aléatoire et $(\\beta_0,\\beta_1,...,\\beta_p)^T\\in\\mathbb{R}^{p+1}$ est le vecteur des paramètres. \n",
    "Soit $n$ la taille de l'échantillon et soit $X^{(1)},...,X^{(n)}$ un échantillon i.i.d. du vecteur aléatoire $X$. La matrice de conception du modèle linéaire est :\n",
    "$$\n",
    "A = \n",
    "\\begin{pmatrix}\n",
    "1 & X_1^{(1)} & ... & X_p^{(1)} \\\\\n",
    "1 & X_1^{(2)} & ... & X_p^{(2)} \\\\\n",
    "\\vdots & \\vdots & & \\vdots \\\\\n",
    "1 & X_1^{(n)} & ... & X_p^{(n)}\n",
    "\\end{pmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Soit $y$ le vecteur des sorties de la fonction $g$ :\n",
    "$$\n",
    "y^{(j)} = g\\left(X^{(j)}\\right), \\quad j=1,...,n.\n",
    "$$\n",
    "Le problème de regression linéaire consiste à résoudre le problème :\n",
    "$$\n",
    "\\min_{\\beta\\in\\mathbb{R}^p} \\|y - A\\beta\\|_2.\n",
    "$$\n",
    "Si la matrice $A$ est de rang plein, la solution est unique. C'est celle donnée par les équations normales :\n",
    "$$\n",
    "\\hat{\\beta} = \\left(A^T A\\right)^{-1} A^T y.\n",
    "$$\n",
    "En pratique, bien que la méthode des équations normales soit appropriée dans certaines circonstances, on utilise le plus souvent une méthode fondée sur une décomposition orthogonale de la matrice $A$, comme par exemple la décomposition QR ou la décomposition SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Complément : Qualité de la regression linéaire\n",
    "\n",
    "Une fois que les coefficients $\\beta$ sont calculés, on doit déterminer si le modèle linéaire est une approximation appropriée de la fonction $g$. \n",
    "Soit \n",
    "$$\n",
    "\\bar{y} = \\frac{1}{n} \\sum_{j=1}^n y^{(j)}\n",
    "$$\n",
    "la moyenne empirique des sorties $y$. \n",
    "Soit $\\hat{y}$ le vecteur des prédictions du modèle de regression linéaire :\n",
    "$$\n",
    "\\hat{y} = A\\hat{\\beta}.\n",
    "$$\n",
    "Le coefficient $R^2\\in[0,1]$ est :\n",
    "$$\n",
    "R^2 = 1- \\frac{\\sum_{j=1}^n \\left(y^{(j)} - \\hat{y}^{(j)}\\right)^2}{\\sum_{j=1}^n \\left(y^{(j)} - \\bar{y}\\right)^2}\n",
    "$$\n",
    "Le coefficient $R^2$ mesure la part de variance expliquée par le modèle linéaire. \n",
    "\n",
    "On considère souvent qu'un coefficient de prédictivité $R^2>0.9$ est le signe d'une qualité suffisante. Un coefficient $R^2<0.5$ est inacceptable pour une utilisation pratique : c'est le signe que, vraisemblablement, le modèle n'est *pas* linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
