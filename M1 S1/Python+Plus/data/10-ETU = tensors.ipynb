{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "metadata": {"id": "r832EvznwNm_"}, "source": ["# Tensors\n", "\n", "Attention, si vous ne maitrisez pas d\u00e9j\u00e0 numpy, vous devez faire le TP sp\u00e9cifique numpy (dossier `py`).  "], "outputs": []}, {"cell_type": "code", "metadata": {"id": "ucYKZBJ3Nb2C"}, "source": ["%reset -f"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "essvPFQfMeS9"}, "source": ["import numpy as np\n", "import tensorflow as tf\n", "import torch\n", "\n", "import matplotlib.pyplot as plt\n", "import os\n", "np.set_printoptions(linewidth=500,precision=2,suppress=True)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "QHcgFOYASZX0"}, "source": ["## Tenseurs"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "H9UySOPLXdaw"}, "source": ["### Definition\n", "\n", "Un tenseur est un tableau multidimensionnel. Ils ont un type de donn\u00e9es `dtype` et une forme `shape`. Nous allons comparer 3 lib. \u00c0 la fin, vous devrez pouvoir comprendre le tableau ci-dessous"], "outputs": []}, {"cell_type": "markdown", "source": ["\n", "|  | numpy | tensorflow | pytorch |\n", "|:---|:--- |:---|:---|\n", "| d\u00e9faut  | 64 bits | 32 bits | 32float/64int bits |\n", "| d\u00e9faut  | CPU | GPU | CPU\n", "| GPU possible | non | oui | oui |\n", "| tenseurs mutables  | oui | non | oui|\n", "| cast automatique | oui | non |oui |\n", "| op\u00e9ration inplace | certaines | aucune | au choix |\n", "| diff\u00e9rentiation | non | oui | oui |\n", "\n", "Attention: numpy ne peut pas servir pour cr\u00e9er des r\u00e9seaux de neurone, mais elle est bien pratique pour pr\u00e9traiter les donn\u00e9es."], "metadata": {"id": "qbEC41GVhGJO"}, "outputs": []}, {"cell_type": "code", "source": ["data = [[1., 2],[3, 4],[5,6]]\n", "X_torch = torch.tensor(data)\n", "X_tf = tf.constant(data)\n", "X_np = np.array(data)"], "metadata": {"id": "F-UT94EAI6Y_"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["for X in [X_torch,X_tf,X_np]:\n", "    print(X.shape,X.dtype)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "QyADOSNBJdi6", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 6, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "941f103c-daca-422a-b5c7-fc7d50e7cf68"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "VJaxSfnYxRQi"}, "source": ["***\u00c0 vous:*** Qu'est-ce que cela donne avec `data = [[1, 2],[3, 4],[5,6]]` (le point en moins)?\n", "  "], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "amUz7KauU6xc"}, "source": ["***\u00c0 vous:*** Que v\u00e9rifie-t-on dans le programme ci-dessous?"], "outputs": []}, {"cell_type": "code", "source": ["def modify(X):\n", "    X[0,0]=7"], "metadata": {"id": "T0Eqc-07KRL5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "OTYyrNxEwzdZ", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "3e053146-93c2-4d78-f40a-f6b816e088d0"}, "source": ["for title,X in [(\"torch\",X_torch),(\"tf\",X_tf),(\"np\",X_np)]:\n", "    print(title)\n", "    try:\n", "        modify(X)\n", "        print(X)\n", "    except Exception as e:\n", "        print(e)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Conversions\n", "\n", "On peut appliquer des fonctions d'une lib sur des tenseurs d'autre lib, mais le r\u00e9sultat est impr\u00e9visible."], "metadata": {"id": "CZRwITe6K6W3"}, "outputs": []}, {"cell_type": "code", "source": ["for title_tensor,X in [(\"torch\",X_torch),(\"tf\",X_tf),(\"np\",X_np)]:\n", "    print(\"title_tensor:\",title_tensor)\n", "    for title_func,fn in [(\"torch\",torch.sin),(\"tf\",tf.sin),(\"np\",np.sin)]:\n", "        print(\"\\t title_func:\",title_func)\n", "        try:\n", "            res=fn(X)\n", "            print(\"\\t\\t\",X.dtype)\n", "        except Exception as e:\n", "            print(\"\\t\\t\",e)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "KbNyVV-OK5rD", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2fde663d-f88d-4d1b-e87b-3da5bd89786b"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Idem si on fait des op\u00e9rations entre tenseurs."], "metadata": {"id": "8XRyqbkOi70-"}, "outputs": []}, {"cell_type": "code", "source": ["for title_tensor1,X in [(\"torch\",X_torch),(\"tf\",X_tf),(\"np\",X_np)]:\n", "    print(\"title_tensor1:\",title_tensor1)\n", "    for title_tensor2,Y in [(\"torch\",X_torch),(\"tf\",X_tf),(\"np\",X_np)]:\n", "        print(\"\\t title_tensor2:\",title_tensor2)\n", "        try:\n", "            Z=X+Y\n", "            print(\"\\t\\t\",Z.dtype)\n", "        except Exception as e:\n", "            print(\"\\t\\t\",e)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "_WZfA1g3OB8w", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0a96849e-ca41-4770-e94a-5711b14f2cbe"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Certaine lib font des 'cast' automatique, d'autre nom:"], "metadata": {"id": "z6mHTk7olPVj"}, "outputs": []}, {"cell_type": "code", "source": ["np.zeros([3,3],dtype=np.float32)+np.zeros([3,3],dtype=np.float64)+np.zeros([3,3],dtype=np.int32)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "18C022C-krNO", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a919b28d-351c-4213-a870-609b83f02110"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["try:\n", "    tf.zeros([3,3],dtype=tf.float32)+tf.zeros([3,3],dtype=np.float64)\n", "except Exception as e:\n", "    print(e)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Bwy7uDaglDnA", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2de32a29-1584-43fd-e2c0-095388b3f4e8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.zeros([3,3],dtype=torch.float32)+torch.zeros([3,3],dtype=torch.float64)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "eiB8JwW1lDpq", "executionInfo": {"status": "ok", "timestamp": 1730760944159, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b6642773-f7e4-47fe-bacd-a320d3c33a5c"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### M\u00e9thode post/pr\u00e9traitement numpy"], "metadata": {"id": "NU6nX-1mtDgl"}, "outputs": []}, {"cell_type": "markdown", "source": ["***R\u00e8gle d'or:*** S\u00e9parer bien votre programme en plusieurs parties. Chaque partie avec sa lib ad hoc. Faites des conversions explicite entre ces parties. Exemple:"], "metadata": {"id": "6-yE4cO1O3gO"}, "outputs": []}, {"cell_type": "code", "source": ["#Cr\u00e9ation, pr\u00e9traitement des donn\u00e9es. Numpy est le plus pratique:\n", "X_np=np.random.normal(size=[1000])\n", "X_np[X_np<0]=0\n", "plt.hist(X_np,edgecolor='k');"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "tfuuJ2GpjQ3M", "executionInfo": {"status": "ok", "timestamp": 1730760944863, "user_tz": -60, "elapsed": 706, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4bbbdaa7-c5b9-4a7c-d56c-6ecdb5aafbbe"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#Traitement tensorflow:\n", "X_tf=tf.constant(X_np,dtype=tf.float32)\n", "X_tf=tf.sin(X_tf**3) #imaginer plein de gros calculs"], "metadata": {"id": "JxB3ydFbj9GX"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#post traitement\n", "plt.hist(X_tf.numpy(),edgecolor=\"k\");"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "wbZKY8X3kWZl", "executionInfo": {"status": "ok", "timestamp": 1730760946501, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bb3708f6-549a-4a56-bfd0-a6f9c5ecd871"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### M\u00e9thode quasi tout torch\n", "\n", "Torch est tr\u00e8s proche de numpy dans ses possibilit\u00e9s (en particulier le fait de pouvoir modifier des bouts de tenseurs).\n", "\n", "Perso, dans un projet de deeplearning, j'utilise quasi tout le temps torch, y compris pour les pr\u00e9traitements.\n", "\n", "Et dans un projet sans deeplearning, j'utilise uniquement numpy qui est un peu plus rapide si on travaille uniquement sur cpu."], "metadata": {"id": "hBFr4cv4tphz"}, "outputs": []}, {"cell_type": "code", "source": ["torch.set_default_dtype(torch.float64)\n", "A=torch.ones([10,10])\n", "A[3,3]=5\n", "A+=torch.randn(10,10)\n", "\n", "plt.matshow(A);"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 437}, "id": "5diDXZmptvUQ", "executionInfo": {"status": "ok", "timestamp": 1730760947028, "user_tz": -60, "elapsed": 529, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ac269fd8-378f-45fe-9e27-15445c4b72ba"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On verra plus tard qu'il faut parfois faire ceci:\n", "\n", "Si on bosse sur le GPU:\n", "\n", "    plt.matshow(A.cpu())\n", "\n", "Si on `A` est reli\u00e9 \u00e0 un graph de calcul\n", "\n", "    plt.matshow(A.detach())\n", "\n", "Et si les deux\n", "\n", "    plt.matshow(A.detach().cpu()\n", "\n"], "metadata": {"id": "a3ybmto1ugXT"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "PBNP8yTRfu_X"}, "source": ["## Acc\u00e9l\u00e9ration GPU\n", "\n", "En tf ou en torch, on peut acc\u00e9l\u00e9rer les calculs avec le GPU.\n"], "outputs": []}, {"cell_type": "markdown", "source": ["### Tensorflow"], "metadata": {"id": "uNOjLYKImJeJ"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-BFZCN-MZ63S"}, "source": ["\n", "Si dans colab, vous n'avez mis en route le GPU, la liste ci-dessous sera vide. Sinon, allez dans\n", "\n", "    Ex\u00e9cution>modifier le type d'exc\u00e9cution\n", "\n", "Colab vous propose alors 1 GPU. D'autre serveur peuvent en proposer plus.  "], "outputs": []}, {"cell_type": "code", "metadata": {"cellView": "code", "id": "3Twf_Rw-gQFM", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760947028, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "1a80577b-c7c9-4b9a-81c7-728e99175f70"}, "source": ["tf.config.list_logical_devices()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "5ghy9kO3Zp6f"}, "source": ["Quand on a cr\u00e9\u00e9 un tenseur, l'attribut `.device` fournit une chaine de caract\u00e8re qui caract\u00e9rise le dispositif l'h\u00e9berge."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "lr0XURaBZw6b", "executionInfo": {"status": "ok", "timestamp": 1730760947028, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/", "height": 36}, "outputId": "9169db30-62f2-4866-d608-7b9aa1d44d7a"}, "source": ["X_tf=tf.ones([3,3])\n", "X_tf.device"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "vpgYzgVXW2Ud"}, "source": ["Cette cha\u00eene de caract\u00e8re se termine par `cuda:N` ou `GPU:N` signifie que le tenseur est plac\u00e9 sur le `N`-\u00e8me GPU de l'h\u00f4te.\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "5chWIXpG3mHE"}, "source": ["size=7000\n", "X_tf=tf.ones([size,size])"], "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "X_tf@X_tf"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ndmym-VzmxDg", "executionInfo": {"status": "ok", "timestamp": 1730760947543, "user_tz": -60, "elapsed": 516, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0cf9dfcf-cbe5-4ca9-c908-9680c32d586d"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ZWZQCimzuqyP"}, "source": ["### Placement explicite\n", "\n", "Mais on peut d\u00e9cider soit m\u00eame du placement en utilisant le contexte-manager `tf.device`:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "LEhp_HmL3TWD", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760959251, "user_tz": -60, "elapsed": 11709, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "df3771d0-9a7f-4d34-cc42-8f5fbd53c5d7"}, "source": ["%%time\n", "with tf.device(\"CPU:0\"): #ou \"GPU:i\" pour utiliser le GPU num\u00e9ro i\n", "    print( (X_tf@X_tf).shape)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Torch"], "metadata": {"id": "_GMwd4ehmQy-"}, "outputs": []}, {"cell_type": "code", "source": ["X_torch=torch.ones([size,size])\n", "X_torch.device"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "A_rmc-DcmSVy", "executionInfo": {"status": "ok", "timestamp": 1730760959584, "user_tz": -60, "elapsed": 335, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a66c54ab-b4c0-49cf-b13e-b42390d9000a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X_torch=X_torch.to(\"cuda\")\n", "X_torch.device"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "M18r9nMYmYnF", "executionInfo": {"status": "ok", "timestamp": 1730760959584, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "d65fccbb-6199-48d5-d33c-48e9cf929ecb"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On pourrait revenir en arri\u00e8re avec:\n", "\n", "    X_torch=X_torch.to(\"cpu\")\n", "\n", "ou bien\n", "\n", "    X_torch=X_torch.cpu()\n", "\n"], "metadata": {"id": "gyC4FB77nRZI"}, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "X_torch@X_torch"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rcU0GCcLmhyD", "executionInfo": {"status": "ok", "timestamp": 1730760963040, "user_tz": -60, "elapsed": 3457, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "600870f2-e9e3-4842-c1fd-7b709dc5565b"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Fixer un cadre de travail"], "metadata": {"id": "4AkWsLlK_xSD"}, "outputs": []}, {"cell_type": "code", "source": ["torch.set_default_device(\"cuda\")\n", "torch.set_default_dtype(torch.float32)"], "metadata": {"id": "tfSoVVFy_3sj"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#dor\u00e9navent, si on ne pr\u00e9cise rien, on travaille sur cuda et en float32\n", "A=torch.ones([2,2])\n", "A.device, A.dtype"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "69KjCZbVAKaI", "executionInfo": {"status": "ok", "timestamp": 1730760963040, "user_tz": -60, "elapsed": 12, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "dd3e82a3-0828-4e86-f785-75bc43959e20"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#et si on a un doute:\n", "print(torch.get_default_device())\n", "print(torch.get_default_dtype())"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "3TnauasbAMa-", "executionInfo": {"status": "ok", "timestamp": 1730760963040, "user_tz": -60, "elapsed": 11, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "d17a0588-e5c8-4d51-f2d5-6d67fb189ddc"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Conseil:\n", "* Pour le deep-learning travaillez en float32\n", "* Pour des solver num\u00e9riques, travaillez en float64\n", "* Pour les entiers, d\u00e9cidez au cas par cas: si vous avez besoin de stocker d'\u00e9norme tenseur contenant des petits entiers, n'h\u00e9sitez pas \u00e0 choisir des `int16` ou m\u00eame des `uint8` (pour stocker des images par exemple)."], "metadata": {"id": "U7xkmtsqAeyB"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "HX7_I5Rg4NPb"}, "source": ["## Calcul tensoriel\n", "\n"], "outputs": []}, {"cell_type": "markdown", "source": ["### Variation sur les syntaxes"], "metadata": {"id": "cwhFpqZGBS7K"}, "outputs": []}, {"cell_type": "markdown", "source": ["Petites variations"], "metadata": {"id": "L3xkckEGonCf"}, "outputs": []}, {"cell_type": "code", "source": ["data = [[1., 2],[3, 4],[5,6]]\n", "X_torch = torch.tensor(data)\n", "X_tf = tf.constant(data)\n", "X_np = np.array(data)"], "metadata": {"id": "LO1M4wf2oLx4"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["tf.reduce_sum(X_tf,axis=0)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "HV97nczHoe3Z", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 11, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "52a2e9b5-79db-484f-daa1-9710dfb217a6"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["np.sum(X_np,axis=0)\n", "#ou bien X_np.sum(axis=0)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "e16eQr3Toe6F", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 10, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "12759f65-6393-4c8b-9e1e-4f683f12a838"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X_torch.sum(dim=0)\n", "#ou bien torch.sum(X_torch,dim=0)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "XZQ3xpcBoXSn", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 9, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "c4f93f80-44e3-4ab3-c796-394ac4ddf551"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X_torch.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "GhS8n3Vno0YN", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 8, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "c887732e-4a9c-4636-b2c3-41f604034f79"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### inplace/via des copies"], "metadata": {"id": "imEHqbCb-Wxb"}, "outputs": []}, {"cell_type": "code", "source": ["X=torch.ones([2,2])\n", "Y=torch.sin(X) # ou bien Y=X.sin()\n", "print(X,\"\\n\",Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ASprD-Nao87q", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4290cd25-31e2-4274-a70f-f6aa2b243db8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X=torch.ones([2,2])\n", "Y=torch.sin_(X)# ou bizn Y =X.sin_() # ou bien Y=torch ???\n", "print(X,\"\\n\",Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "GjbsQWxZ-qFH", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "3713e2d1-9176-4eff-c842-3760006e9767"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Le suffixe `_` d\u00e9signe les op\u00e9rations dites \"in-place\""], "metadata": {"id": "kLPQU1bleIUj"}, "outputs": []}, {"cell_type": "code", "source": ["X=tf.ones([2,2])\n", "Y=tf.sin(X)\n", "print(X,\"\\n\",Y)"], "metadata": {"id": "fS39tQ_M_CvP", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 6, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "e3ad2a29-aca2-4c6c-dbae-e49492c096c8"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Aucune op\u00e9ration n'est \"in place\" avec les tenseurs \"constant\" de `tf`. Tensorflow poss\u00e8de une seconde classe de tenseurs \"Variable\" qui permettent certaines op\u00e9rations inplace."], "metadata": {"id": "MGiTO8rFefH2"}, "outputs": []}, {"cell_type": "code", "source": ["X=np.ones([2,2])\n", "Y=np.sin(X)\n", "print(X,\"\\n\",Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "fY4XafWZeWkk", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9a3c4a8b-9ded-44cd-c65d-750ebae09495"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["En numpy les op\u00e9rations: `+=`, `-=`, `*=` sont 'inplace'. C'est tr\u00e8s souvent source de bug. Exemple:"], "metadata": {"id": "Zn6GWRA-eva0"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["def cov(X,Y):\n", "    X-=np.mean(X)\n", "    Y-=np.mean(Y)\n", "    return np.mean(X*Y)\n", "\"\"\"\n", "Cette fonction calcule la covariance.\n", "Mais l'utilisateur qui l'utilisera aura une mauvaise surprise.\n", "\"\"\""], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 54}, "id": "YKTmY08KXArS", "executionInfo": {"status": "ok", "timestamp": 1730760963041, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "5a46d33a-949f-43bf-8c3c-80e32cc2d331"}, "execution_count": null}, {"cell_type": "markdown", "source": ["Les affectations via les crochets qui cr\u00e9\u00e9es des \"vues\" sur les tenseurs:"], "metadata": {"id": "P1vx4uGJf2v4"}, "outputs": []}, {"cell_type": "code", "source": ["#pi\u00e8ge classique\n", "X=np.ones([3,3])\n", "Y=X[:2,:2]\n", "Y[:,:]=0\n", "X"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "T8P7-JyRe99p", "executionInfo": {"status": "ok", "timestamp": 1730760963346, "user_tz": -60, "elapsed": 309, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "3588f7f7-c321-4991-eb81-7c69e2d5feb2"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["C'est idem en torch. Observez:\n", "\n"], "metadata": {"id": "xXtAUO-0fR4K"}, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(0.)\n", "xs=[]\n", "for _ in range(5):\n", "    x+=1\n", "    xs.append(x)\n", "print(xs)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "B0hhx9fR_rBP", "executionInfo": {"status": "ok", "timestamp": 1730760963346, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6524a2cd-9159-486f-cb89-4d064119abd3"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(0.)\n", "xs=[]\n", "for _ in range(5):\n", "    x=x+1\n", "    xs.append(x)\n", "print(xs)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "V6e8tWDIAKG0", "executionInfo": {"status": "ok", "timestamp": 1730760963346, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bb2df139-386d-4397-ea23-4c2fd20a80f1"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Attention, les m\u00e9thodes `.numpy()` ou `.detach()` font des copies de surface:"], "metadata": {"id": "vfcLL9uHA4md"}, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(0.,device=\"cpu\")\n", "xs=[]\n", "for _ in range(5):\n", "    x+=1\n", "    xs.append(x.numpy())\n", "print(xs)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "oshSS5iy_9uk", "executionInfo": {"status": "ok", "timestamp": 1730761065779, "user_tz": -60, "elapsed": 335, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ab7e1dfc-ced6-4846-e19f-5a9989f6ca40"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(0.)\n", "xs=[]\n", "for _ in range(5):\n", "    x+=1\n", "    xs.append(x.detach())\n", "print(xs)"], "metadata": {"id": "QAzsL3rrwIDC", "executionInfo": {"status": "ok", "timestamp": 1730761071056, "user_tz": -60, "elapsed": 219, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "aa7d785a-fa26-4a23-e938-c33b18384b08"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Il faut utiliser `.clone()` pour une copie des donn\u00e9es"], "metadata": {"id": "PnS6Z1QTBBnk"}, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(0.)\n", "xs=[]\n", "for _ in range(5):\n", "    x+=1\n", "    xs.append(x.clone())\n", "print(xs)"], "metadata": {"id": "NduALvsoBErH", "executionInfo": {"status": "ok", "timestamp": 1730761074540, "user_tz": -60, "elapsed": 450, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "b2dd8fd8-9e36-4782-e714-b8246599f200"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["***A vous:*** Et la m\u00e9thode `.cpu()` d'apr\u00e8s vous, fait-elle une copie ?"], "metadata": {"id": "qLI1WACty5aR"}, "outputs": []}, {"cell_type": "markdown", "source": ["***Conseil:*** Testez pour savoir !"], "metadata": {"id": "vjcFyQmzAzgR"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Broadcasting\n", "\n", "C'est faire des op\u00e9rations entre des tenseurs qui n'ont pas la m\u00eame shape"], "metadata": {"id": "cUlyzzG_h4xX"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "v2Yb0WMHKpQY"}, "source": ["###  Lemme des shapes\n", "\n", "***Lemme:*** Consid\u00e9rons une op\u00e9ration \"terme \u00e0 terme\" entre deux tenseurs `A` et `B`. Par exemple l'op\u00e9ration `A+B`.\n", "Pour qu'elle soit valide, il faut que, pour chaque dimension `i` l'une des 3 contraintes suivantes soit satisfaite:\n", "\n", "* `A.shape[i]=B.shape[i]`\n", "* `A.shape[i]=1`\n", "* `B.shape[i]=1`\n", "\n", "Exemple d'op\u00e9ration valide:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0foo_FjjLXkC", "executionInfo": {"status": "ok", "timestamp": 1730761080274, "user_tz": -60, "elapsed": 232, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "cd341cdd-135b-440e-e04b-96e1d5af1bf9"}, "source": ["A=tf.random.uniform([3,1,1,2,3,1])\n", "B=tf.random.uniform([3,5,5,1,1,3])\n", "(A+B).shape"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qGt_F5JTLy8F"}, "source": ["Quand on a `A.shape[i]=n` et `B.shape[i]=1`, alors valeurs `B` sont r\u00e9p\u00e9t\u00e9e `n` fois le long de la i-\u00e8me dimension.\n", "\n", "Observons:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "k0EHmdOfMsQo", "executionInfo": {"status": "ok", "timestamp": 1730761081838, "user_tz": -60, "elapsed": 463, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "ca23f0d5-e7e7-44e5-bcb5-eb2d3015a854"}, "source": ["A=tf.constant([1,10,100]) # shape (3,)\n", "B=tf.constant([2,5]) # shape (2,)\n", "\n", "A = A [None,:]  #shape (1,3)\n", "B = B [:,None]  #shape (2,1)\n", "C=A*B\n", "C"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On a en fait effectuer $C_{ij}=A_j B_i$\n", "\n", "\n"], "metadata": {"id": "gw2BIFPohfmp"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "f9npUd2YTbH8"}, "source": ["### Utilisation\n", "\n", "On ajoute des dimensions suppl\u00e9mentaires pour faire des op\u00e9rations qu'on \u00e9crirait tr\u00e8s naturellement en math. Exemple au pif: on veut d\u00e9finir\n", "\n", "\n", "$$\n", "\\sum_{j,l} A_{i,j} \\sin(B_{j,k,l} - C_{i,l})\n", "$$\n", "On passe d'abord par le tenseur:\n", "$$\n", "D_{i,j,k,l} =A_{i,j} \\sin(B_{j,k,l} - C_{i,l})\n", "$$\n", "que l'on somme ensuite suivant les axes $j,l$\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "Fc4MASEVTS3j", "executionInfo": {"status": "ok", "timestamp": 1730761082943, "user_tz": -60, "elapsed": 247, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "432c87e2-5891-40ca-81dc-413c4d35f923"}, "source": ["A=tf.random.uniform([3,3])\n", "B=tf.random.uniform([3,3,3])\n", "C=tf.random.uniform([3,3])\n", "\n", "#On ajoute des 'None' sur les axes absents\n", "D=A[:,:,None,None]* tf.sin(B[None,:,:,:]-C[:,None,None,:])\n", "result=tf.reduce_sum(D,axis=[1,3])\n", "result"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Attention, si on fait des op\u00e9rations entre tenseurs de dimensions diff\u00e9rentes, les lib ajoutent des `None` au d\u00e9but:"], "metadata": {"id": "voIo35vvkbCL"}, "outputs": []}, {"cell_type": "code", "source": ["A=tf.random.uniform([3,3])\n", "B=tf.random.uniform([3])\n", "A+B"], "metadata": {"id": "IBXDOqtEkpdo", "executionInfo": {"status": "ok", "timestamp": 1730761084483, "user_tz": -60, "elapsed": 445, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "7497ba3c-da5d-481f-edea-0c37a519296f"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["A+B[None,:]"], "metadata": {"id": "coULQQvRkwPi", "executionInfo": {"status": "ok", "timestamp": 1730761084816, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "1a44ef9a-5efa-4c82-bd40-b767ccad9cc6"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "uur4qq9qDzrx"}, "source": ["***\u00c0 vous:*** Consid\u00e9rons:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "L2VWkhBrD3yx"}, "source": ["a=tf.constant([[1.,2,3],[4,5,6],[7,8,9]])\n", "b=tf.constant([1.,1,1])\n", "c = 5"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "cI4lWyPBEE0n"}, "source": ["calculez\n", "\n", "    Sum_i (a[ij] - b[i] +c )^2\n", "    Sum_i (a[ij] - b[j] +c )^2"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "hwnk5GscUKE4"}, "source": ["## Coller des tenseurs"], "outputs": []}, {"cell_type": "markdown", "source": ["C'est une op\u00e9ration courante: on cr\u00e9e des donn\u00e9es dans une boucle, puis on veut les r\u00e9unir en un seul gros tenseur.\n", "\n", "Prenons l'exemple de vecteurs que l'on veut r\u00e9unir en une matrice.\n", "\n", "En numpy, on peut faire cela comme ceci:"], "metadata": {"id": "eRZXzj268QTE"}, "outputs": []}, {"cell_type": "code", "metadata": {"id": "bEPv8I4qUJVl", "executionInfo": {"status": "ok", "timestamp": 1730761092052, "user_tz": -60, "elapsed": 332, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "4e8abe1e-d307-4f2e-b78c-f82be92f9a83"}, "source": ["nb_line=5\n", "A=np.zeros([nb_line,2])\n", "for i in range(nb_line):\n", "    A[i,:] = i*np.ones([2])\n", "A"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On pourrait aussi le faire en torch, mais pas en tf. Cependant, il est souvent plus efficace d'utiliser la fonction `stack` qui existe dans les 3 lib:\n", "\n"], "metadata": {"id": "6_NONO9ylith"}, "outputs": []}, {"cell_type": "code", "source": ["for lib in [np,tf,torch]:\n", "    A=[]\n", "    for i in range(5):\n", "        A.append( i*lib.ones([2]))\n", "    A=lib.stack(A)#par d\u00e9faut dim ou axis=0\n", "    print(A)"], "metadata": {"id": "CFmxAsn1ld2I", "executionInfo": {"status": "ok", "timestamp": 1730761092052, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "2b4a8f78-0301-48df-f743-250ec1a4c8c4"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "EJdgXtmUUTGA"}, "source": ["On peut aussi faire la m\u00eame chose avec les fonctions de concat\u00e9nation. Mais attention:\n", "\n", "    tf.concat = np.concatenate = torch.cat = torch.concat\n", "\n", "On s'\u00e9tonne que les gens ne se comprennent pas  \ud83d\ude44"], "outputs": []}, {"cell_type": "code", "source": ["A=[]\n", "for i in range(5):\n", "    A.append(i*np.ones([1,2]))\n", "A=np.concatenate(A,axis=0)\n", "print(A)"], "metadata": {"id": "ATcrG6mJ-nVY", "executionInfo": {"status": "ok", "timestamp": 1730761092052, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "9caea56d-8a29-4dc0-aebc-53931a58c35e"}, "execution_count": null, "outputs": []}]}