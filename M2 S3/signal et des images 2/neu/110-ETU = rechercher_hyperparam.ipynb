{"cells": [{"cell_type": "markdown", "metadata": {"id": "jCTqLacMJkE0"}, "source": ["# Rechercher les meilleurs hyper-param\u00e8tres"], "outputs": []}, {"cell_type": "code", "execution_count": 8, "metadata": {"id": "sWCSV3zE_Hjp", "executionInfo": {"status": "ok", "timestamp": 1763048536095, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["import hashlib\n", "import os\n", "import shutil\n", "import time\n", "from typing import Callable\n", "from matplotlib import pyplot as plt\n", "import numpy as np\n", "\n", "import jax\n", "import jax.numpy as jnp\n", "import jax.random as jr\n", "import optax\n", "import pickle\n", "from datetime import datetime\n", "\n", "from dataclasses import dataclass"]}, {"cell_type": "markdown", "metadata": {"id": "4zBVJ9hGl8ft"}, "source": ["## Data"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "B46wgZVTJqzx"}, "source": ["### Un probl\u00e8me de regression\n", "\n", "On veut faire coller un mod\u00e8le \u00e0 une fonction toute simple."], "outputs": []}, {"cell_type": "code", "execution_count": 9, "metadata": {"executionInfo": {"elapsed": 18, "status": "ok", "timestamp": 1763048536123, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "baJBjQruLIX8"}, "outputs": [], "source": ["n_data=20_000\n", "X = jnp.linspace(0, 1, n_data)[:, None]\n", "Y = jnp.sin(10 * X)\n", "nb_data_train = int(n_data * 0.8)\n", "idx=np.random.permutation(n_data)\n", "X_=X[idx]\n", "Y_=Y[idx]\n", "X_train = X_[:nb_data_train]\n", "Y_train = Y_[:nb_data_train]\n", "X_val = X_[nb_data_train:]\n", "Y_val = Y_[nb_data_train:]"]}, {"cell_type": "code", "execution_count": 10, "metadata": {"executionInfo": {"elapsed": 544, "status": "ok", "timestamp": 1763048536666, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "Nm-6PGevMv33", "colab": {"base_uri": "https://localhost:8080/", "height": 430}, "outputId": "5ec12e19-d878-4941-c354-c6481f289f78"}, "outputs": [], "source": ["fig,ax=plt.subplots()\n", "ax.plot(X,Y);"]}, {"cell_type": "markdown", "metadata": {"id": "ijcfgElBmHzV"}, "source": ["### Distributeur de batch"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "AaIJXdM6mMaM"}, "source": ["On va distribuer les donn\u00e9es avec une double boucle. Une boucle sur les \u00e9poques. A chaque \u00e9poque les donn\u00e9es sont r\u00e9parties dans les batchs."], "outputs": []}, {"cell_type": "code", "execution_count": 11, "metadata": {"executionInfo": {"elapsed": 3, "status": "ok", "timestamp": 1763048536667, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "4LJ4bJr1i5jt"}, "outputs": [], "source": ["def batchs_for_one_epoch(X_all,Y_all,batch_size):\n", "    nb_batches=len(X_all)//batch_size\n", "    shuffle_index=np.random.permutation(len(X_all))\n", "    X_all_shuffle=X_all[shuffle_index]\n", "    Y_all_shuffle=Y_all[shuffle_index]\n", "    for i in range(nb_batches):\n", "        yield X_all_shuffle[i*batch_size:(i+1)*batch_size],Y_all_shuffle[i*batch_size:(i+1)*batch_size]"]}, {"cell_type": "code", "execution_count": 12, "metadata": {"executionInfo": {"elapsed": 255, "status": "ok", "timestamp": 1763048536920, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "OZw1yWV7Zzh3", "colab": {"base_uri": "https://localhost:8080/"}, "outputId": "3762d1bb-f41c-4ec0-8f85-2b7dabdcf70c"}, "outputs": [], "source": ["X_all=jnp.zeros([1003,2])\n", "Y_all=jnp.ones([1003,1])\n", "\n", "iterator_for_one_epoch=batchs_for_one_epoch(X_all,Y_all,100)\n", "\n", "for x,y in iterator_for_one_epoch:\n", "    print(x.shape,y.shape)"]}, {"cell_type": "markdown", "metadata": {"id": "XSUtrXOxaZZ1"}, "source": ["Remarque: les 3 donn\u00e9es de la fin ne sont pas distribu\u00e9e. C'est pas grave, car le shuffle change l'ordre \u00e0 chaque \u00e9poque."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "_M42CBHvmd6w"}, "source": ["## Mod\u00e8le et fonctions d'entrainement"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "0x6Gma3VJ5gU"}, "source": ["Un r\u00e9seau neuronal est une fonction param\u00e9trique $f(\\theta,x)$. En jax, on l'impl\u00e9mente tr\u00e8s explicitement: en se donnant\n", "* la fonction `model_init(rkey)` qui renvoie un jeu initial de param\u00e8tre not\u00e9 `params`, ou `model_params` ou $\\theta$  \n", "* et la fonction `model_call(params,x)` =$f(\\theta,x)$."], "outputs": []}, {"cell_type": "code", "execution_count": 13, "metadata": {"executionInfo": {"elapsed": 1, "status": "ok", "timestamp": 1763048536925, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "9lAEcvsniKqJ"}, "outputs": [], "source": ["def model_fnm(layer_widths,activation_fn):\n", "\n", "    def model_init(rkey):\n", "        params = []\n", "        for n_in, n_out in zip(layer_widths[:-1], layer_widths[1:]):\n", "            rk,rkey=jr.split(rkey)\n", "            params.append(\n", "                {\"weight\":jr.normal(rk,shape=(n_in, n_out))*jnp.sqrt(2/n_in),\n", "                \"bias\":jnp.zeros([n_out])})\n", "        return params\n", "\n", "    def model_apply(params, inp):\n", "        *hidden, last = params\n", "        for layer in hidden:\n", "            inp = activation_fn(inp @ layer['weight'] + layer['bias'])\n", "        return inp @ last['weight'] + last['bias']\n", "\n", "    return model_init,model_apply"]}, {"cell_type": "markdown", "metadata": {"id": "IrdRVD3cnkbA"}, "source": ["### De l'Hyper-param\u00e8tre au mod\u00e8le"], "outputs": []}, {"cell_type": "code", "execution_count": 14, "metadata": {"executionInfo": {"elapsed": 24, "status": "ok", "timestamp": 1763048536949, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "ja35P7BimObO"}, "outputs": [], "source": ["def make_model(hyper_param):\n", "\n", "    dim_in=1\n", "    dim_out=1\n", "\n", "    dim_hidden=hyper_param['dim_hidden']\n", "    n_layer=hyper_param['n_layer']\n", "    activation_name=hyper_param['activation_name']\n", "\n", "\n", "    layer_widths=[dim_in]+[dim_hidden]*(n_layer-1)+[dim_out]\n", "\n", "\n", "    if activation_name==\"relu\":\n", "        activation_fn=jax.nn.relu\n", "    else:\n", "        activation_fn=jax.nn.tanh\n", "    #on pourrait mettre plein d'autre choix de fonctions d'activation\n", "\n", "    return model_fnm(layer_widths,activation_fn)"]}, {"cell_type": "markdown", "metadata": {"id": "O3Cj9qCpJ-tA"}, "source": ["Ensuite, il faut trouver le bon param\u00e8tre $\\theta$ pour que le r\u00e9seau neuronal colle aux donn\u00e9es. Cette recherche se fait \u00e0 l'aide d'une descente de gradient.\n", "\n", "Mais pour r\u00e9ussir au mieux, il faut aussi bien calibrer l'architecture du r\u00e9seau de neurone (`n_layer`, `dim_hidden`, `activation_name`) param\u00e8tres de l'optimisation (`learning_rate`, `batch_size`, etc.). On nommera tous ces param\u00e8tres \"hyper-param\u00e8tres\" pour les diff\u00e9rencier des param\u00e8tres du mod\u00e8les.\n", "\n", "\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "yTS_d5CwKNmW"}, "source": ["Nous cherchons \u00e0 organiser notre code pour pouvoir tester diff\u00e9rents mod\u00e8les et diff\u00e9rents modes d'apprentissages. On aimerait trouver le bon \u00e9quilibre entre \"tout automatiser\" et  \"tout faire \u00e0 la main\".\n", "\n", "On aimerait aussi que les param\u00e8tres des mod\u00e8les entrain\u00e9s soient sauvegard\u00e9s pour pouvoir prolonger un entrainement. Et on veut aussi se souvenir de tous les hyper-param\u00e8tres qui ont \u00e9t\u00e9 test\u00e9."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qVCevl3mLTFx"}, "source": ["### fonction loss et update"], "outputs": []}, {"cell_type": "code", "execution_count": 15, "metadata": {"executionInfo": {"elapsed": 0, "status": "ok", "timestamp": 1763048536950, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "7m_cTlMPLVTL"}, "outputs": [], "source": ["def jit_creator(model_apply,optimizer):\n", "    @jax.jit\n", "    def loss_compute(params, X,Y):\n", "        Y_pred=model_apply(params,X)\n", "        return jnp.mean((Y_pred-Y)**2)\n", "\n", "    @jax.jit\n", "    def update_model_param(optimizer_state, model_param, X,Y):\n", "        grads = jax.grad(loss_compute)(model_param, X,Y)\n", "        updates, optimizer_state = optimizer.update(grads, optimizer_state)\n", "        #here the model_param is modified\n", "        model_param = optax.apply_updates(model_param, updates)\n", "        #c'est idem que faire la somme des feuilles des pytrees model_param et updates comme ceci:\n", "        #model_param = jax.tree.map(lambda x,y:x+y, model_param, updates)\n", "        return optimizer_state, model_param\n", "\n", "    return loss_compute,update_model_param"]}, {"cell_type": "markdown", "metadata": {"id": "2PXqHF0jK4pr"}, "source": ["## L'Agent\n", "\n", "J'utilise le mot 'Agent' pour un objet qui permet l'entrainement.\n", "\n", "J'ai l'impression que maintenant la plupart des gens utilisent le mot 'Trainer'.\n", "\n", "\n", "Appelons la technique que l'on va utiliser 'ful-folder'. Tout ce qui est produit durant l'entrainement est sauv\u00e9 dans un folder."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Mb1GOjcmK-sB"}, "source": ["### Fonctions de sauvegarde"], "outputs": []}, {"cell_type": "code", "execution_count": 16, "metadata": {"executionInfo": {"elapsed": 13, "status": "ok", "timestamp": 1763048536964, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "xRl3y94NK9Sr"}, "outputs": [], "source": ["def save_as_pickle(file_name,serializable):\n", "    pickle.dump(serializable,open(file_name,\"wb\"))\n", "def load_from_pickle(file_name):\n", "    return pickle.load(open(file_name,\"rb\"))\n", "def save_as_str(file_name,serializable):\n", "    with open(file_name, \"wt\") as f:\n", "        f.write(str(serializable))\n", "def load_from_str(file_name):\n", "    with open(file_name, \"rt\") as f:\n", "        res = eval(f.read())\n", "    return res"]}, {"cell_type": "markdown", "metadata": {"id": "rjNptirZLaH7"}, "source": ["### L'Agent en personne"], "outputs": []}, {"cell_type": "code", "execution_count": 17, "metadata": {"executionInfo": {"elapsed": 39, "status": "ok", "timestamp": 1763048537004, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}, "user_tz": -60}, "id": "vcg52BBsLfNt"}, "outputs": [], "source": ["@dataclass\n", "class AgentMiniResult:\n", "    hyper_param:dict\n", "    best_loss:float\n", "    model_param:dict\n", "    model_call:Callable\n", "\n", "\n", "class AgentMini:\n", "\n", "    @staticmethod\n", "    def load(folder):\n", "        assert os.path.exists(folder),f\"folder:{folder} does not exist\"\n", "        model_param = load_from_pickle(f\"{folder}/model_param\")\n", "        best_loss = load_from_str(f\"{folder}/best_loss\")\n", "        model_param=load_from_pickle(f\"{folder}/model_param\")\n", "        hyper_param=load_from_str(f\"{folder}/hyper_param\")\n", "        _, model_call = make_model(hyper_param)\n", "        return AgentMiniResult(hyper_param,best_loss,model_param,model_call)\n", "\n", "    @staticmethod\n", "    def train(folder,hyper_param,n_epoch,verbose):\n", "\n", "        model_init, model_call = make_model(hyper_param)\n", "        optimizer = optax.adam(hyper_param[\"learning_rate\"])\n", "        batch_size = hyper_param[\"batch_size\"]\n", "\n", "        if os.path.exists(folder):\n", "            if verbose:\n", "                print(f\"Existing folder:{folder}, we load model_param and best_loss from if\")\n", "            model_param = load_from_pickle(f\"{folder}/model_param\")\n", "            best_loss =load_from_str(f\"{folder}/best_loss\")\n", "\n", "        else:#c'est la premi\u00e8re fois qu'on teste cet hyper_param\u00e8tre.\n", "            os.makedirs(folder, exist_ok=True)\n", "            if verbose:\n", "                print(f\"New folder:{folder}, model_param are randomly initialized\")\n", "            model_param=model_init(jr.key(0))\n", "            best_loss=1e10#l'infini ou presque\n", "            save_as_pickle(f\"{folder}/model_param\", model_param)\n", "            save_as_str(f\"{folder}/best_loss\", best_loss)\n", "\n", "        save_as_str(f\"{folder}/hyper_param\", hyper_param)\n", "        optimizer_state=optimizer.init(model_param)\n", "        loss_compute, update_model_param=jit_creator(model_call,optimizer)\n", "\n", "        for _ in range(n_epoch):\n", "            for x,y in batchs_for_one_epoch(X_train,Y_train,batch_size):\n", "                optimizer_state, model_param = update_model_param(optimizer_state, model_param, x,y)\n", "\n", "            val_loss=float(loss_compute(model_param, X_val, Y_val))\n", "            if val_loss <= best_loss:\n", "                best_loss=val_loss\n", "                if verbose:\n", "                    print(f\"\u2b0a{val_loss:.3g}\", end=\"\")\n", "                save_as_pickle(f\"{folder}/model_param\",model_param)\n", "                save_as_str(f\"{folder}/best_loss\",best_loss)\n", "            else:\n", "                if verbose:\n", "                    print(\".\",end=\"\")\n", "        if verbose:\n", "            print(\"| end of the optimization loop.\")\n", "        return best_loss"]}, {"cell_type": "markdown", "metadata": {"id": "AmtCHdzXoLDg"}, "source": ["## Les entrainements"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "bqzpIzvZkArI"}, "source": ["### Entrainement pour 1 hyper-param\u00e8tre\n", "\n"], "outputs": []}, {"cell_type": "code", "execution_count": 18, "metadata": {"id": "-EnE4NaqkP6z", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1763048543122, "user_tz": -60, "elapsed": 6118, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bcf4c45c-591f-4d7c-8c7e-a09af3444aec"}, "outputs": [], "source": ["folder=\"data/mon_premier_test\"\n", "#Pour que ce ne soit pas un r\u00e9-entrainement.\n", "shutil.rmtree(folder,ignore_errors=True)\n", "hyper_param = {\"n_layer\": 2, \"dim_hidden\": 32,\"batch_size\":512,\"learning_rate\":1e-3,\"activation_name\":\"relu\"}\n", "AgentMini.train(folder,hyper_param,20,verbose=True)"]}, {"cell_type": "code", "execution_count": 19, "metadata": {"id": "RzWKWJ8bkOQu", "executionInfo": {"status": "ok", "timestamp": 1763048543143, "user_tz": -60, "elapsed": 21, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["def eval_training(folder):\n", "    result=AgentMini.load(folder)\n", "    fig, axs = plt.subplots(1, 1, sharex=\"all\")\n", "    Y_pred=result.model_call(result.model_param,X)\n", "    axs.plot(X,Y_pred)\n", "    axs.plot(X,Y)\n", "    fig.tight_layout()\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": 20, "metadata": {"id": "fePMH150kjTs", "colab": {"base_uri": "https://localhost:8080/", "height": 487}, "executionInfo": {"status": "ok", "timestamp": 1763048544027, "user_tz": -60, "elapsed": 867, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "e9e7a53c-b62e-4479-b38f-98352d2c440b"}, "outputs": [], "source": ["eval_training(folder)"]}, {"cell_type": "markdown", "metadata": {"id": "plEOl9ERn1jl"}, "source": ["\u21d1 pas terrible"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "1IABalR0Li0d"}, "source": ["### Une rechercher en grille"], "outputs": []}, {"cell_type": "code", "execution_count": 29, "metadata": {"id": "Bdb8XWc6Lm3S", "executionInfo": {"status": "ok", "timestamp": 1763048882715, "user_tz": -60, "elapsed": 41, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["def manual_loop(mother_folder):\n", "    # noinspection PyDictCreation\n", "    hyper_params = [\n", "        {\"n_layer\": 2, \"dim_hidden\": 32},\n", "        {\"n_layer\": 3, \"dim_hidden\": 32},\n", "        {\"n_layer\": 4, \"dim_hidden\": 32},\n", "        {\"n_layer\": 2, \"dim_hidden\": 64},\n", "        {\"n_layer\": 3, \"dim_hidden\": 64},\n", "        {\"n_layer\": 4, \"dim_hidden\": 64}\n", "    ]\n", "    for hyper_param in hyper_params:\n", "        hyper_param[\"batch_size\"] = 512\n", "        # noinspection PyTypeChecker\n", "        hyper_param[\"learning_rate\"] = 1e-3\n", "        # noinspection PyTypeChecker\n", "        hyper_param[\"activation_name\"] = \"relu\"\n", "\n", "    for i,hyper_param in enumerate(hyper_params):\n", "        folder=f\"{mother_folder}/test_{i}\"\n", "        shutil.rmtree(folder,ignore_errors=True)\n", "        AgentMini.train(folder,hyper_param,40,verbose=True)"]}, {"cell_type": "code", "execution_count": 30, "metadata": {"id": "JoiYUnCUL1BA", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1763048904318, "user_tz": -60, "elapsed": 13856, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "8f925a67-628d-4ef8-aa0a-037bcb334298"}, "outputs": [], "source": ["manual_loop(\"data/manual_loop\")"]}, {"cell_type": "code", "execution_count": 23, "metadata": {"id": "ggt7XHk_k2OH", "executionInfo": {"status": "ok", "timestamp": 1763048560012, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["def hyper_param_to_str(hyper_param):\n", "    return f\"bs:{hyper_param['batch_size']},n_lay:{hyper_param['n_layer']},lay_size:{hyper_param['dim_hidden']},lr:{hyper_param['learning_rate']:.3g}\"\n"]}, {"cell_type": "code", "execution_count": 31, "metadata": {"id": "dgiMgdvDk61c", "executionInfo": {"status": "ok", "timestamp": 1763048910995, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["def eval_trainings(mother_folder):\n", "    folders=list(os.listdir(mother_folder))\n", "    loss_results=[]\n", "    for i,_folder in enumerate(folders):\n", "        folder=f\"{mother_folder}/{_folder}\"\n", "        result=AgentMini.load(folder)\n", "        loss_results.append((result.best_loss,result))\n", "    loss_results=sorted(loss_results,key=lambda a:a[0])\n", "    results=[a[1] for a in loss_results]\n", "    ni = 3\n", "    some_results=[results[0],results[len(results)//2],results[-1]]\n", "    fig, axs = plt.subplots(ni, 1, sharex=\"all\", figsize=(6, ni * 4))\n", "    titles=[\"best\",\"intermediate\",\"worst\"]\n", "\n", "    for i,result in enumerate(some_results):\n", "        Y_pred=result.model_call(result.model_param,X)\n", "        axs[i].plot(X,Y_pred)\n", "        axs[i].plot(X,Y)\n", "        axs[i].set_title(titles[i]+':'+hyper_param_to_str(result.hyper_param))\n", "    fig.tight_layout()\n", "    plt.show()"]}, {"cell_type": "code", "execution_count": 32, "metadata": {"id": "c4r18Lnuk-wR", "colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "executionInfo": {"status": "ok", "timestamp": 1763048920958, "user_tz": -60, "elapsed": 891, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "cf01a9bb-1243-445f-bfa9-9d2a512b95db"}, "outputs": [], "source": ["eval_trainings(\"data/manual_loop\")"]}, {"cell_type": "markdown", "metadata": {"id": "Ow7TGeOzpSyU"}, "source": ["***A vous:*** Refaite ces entrainements avec le fonction d'activation sigmoid pour voir la diff\u00e9rence."], "outputs": []}, {"cell_type": "markdown", "source": ["### Une recherche al\u00e9atoire"], "metadata": {"id": "AoEh8qHJ6Mcs"}, "outputs": []}, {"cell_type": "code", "source": ["def random_loop(mother_folder):\n", "    # noinspection PyDictCreation\n", "\n", "\n", "    i=0\n", "    for activation_name in [\"relu\",\"tanh\"]:\n", "        for _ in range(10):\n", "            i+=1\n", "            hyper_param = {}\n", "            hyper_param[\"dim_hidden\"]=np.random.choice(a=[32,64,128])\n", "            hyper_param[\"n_layer\"]=np.random.choice(a=[2,3,4,5])\n", "            hyper_param[\"batch_size\"] = 512\n", "            hyper_param[\"learning_rate\"] = np.random.choice(a=[1e-2,1e-3,1e-4])\n", "            hyper_param[\"activation_name\"] = activation_name\n", "\n", "            folder=f\"{mother_folder}/random_test_{i}\"\n", "            shutil.rmtree(folder,ignore_errors=True)\n", "\n", "            AgentMini.train(folder,hyper_param,40,verbose=True)"], "metadata": {"id": "tv1n06G56bcN", "executionInfo": {"status": "ok", "timestamp": 1763049381526, "user_tz": -60, "elapsed": 34, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 35, "outputs": []}, {"cell_type": "code", "source": ["random_loop(\"data/random_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "OVQpEo5D7dZ9", "executionInfo": {"status": "ok", "timestamp": 1763049432822, "user_tz": -60, "elapsed": 51157, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "5bcf27d1-9615-49f6-867f-b134186b9ba4"}, "execution_count": 36, "outputs": []}, {"cell_type": "code", "source": ["eval_trainings(\"data/random_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "ML1MCp977vAI", "executionInfo": {"status": "ok", "timestamp": 1763049504366, "user_tz": -60, "elapsed": 47625, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9a4a2cc1-865b-4fa5-80f1-d36bd47190af"}, "execution_count": 37, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "4d6Uzm8MLoqT"}, "source": ["### Utilisation d'une libraire d'optimisation"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "by0A5qPKn9IH"}, "source": ["Hyper-op est une librairie d'optimisation bayesienne. Ce genre d'optimisation est utile lorsque vous essayez de trouver le minimum (ou le maximum) d'une fonction dont l'\u00e9valuation prend du temps et dont vous ne connaissez pas la forme exacte (la \"bo\u00eete noire\").\n", "\n", "Ici on cherche le minimum de la fonction qui \u00e0 un hyper-param\u00e8tre associe la 'best-loss' obtenue pendant l'entrainement."], "outputs": []}, {"cell_type": "code", "execution_count": 26, "metadata": {"id": "ByUpcI1nLsG7", "executionInfo": {"status": "ok", "timestamp": 1763048560941, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["def hyperop_loop(mother_folder):\n", "    n_epoch=20\n", "    def objective(hyper_param):\n", "        #un nome de fichier par rapport au temps\n", "        #attention,il faut que les trainings durent plus d'une seconde\n", "        n_second=str(time.time()).split(\".\")[0][5:]\n", "        folder=f\"{mother_folder}/test_{n_second}\"\n", "        return AgentMini.train(folder,hyper_param,n_epoch,False)\n", "\n", "    from hyperopt import hp,fmin, tpe, space_eval\n", "    space = {\n", "        'batch_size': hp.choice('batch_size', [128,256,512]),\n", "        'n_layer': hp.choice('n_layer', [2,3,4]),\n", "        'dim_hidden': hp.choice('layer_size', [64,128,256]),\n", "        'activation_name':hp.choice('activation_name',['relu','tanh']),\n", "        'learning_rate':hp.loguniform('learning_rate',np.log(5e-4),np.log(1e-2))\n", "    }\n", "    best = fmin(objective, space, algo=tpe.suggest, max_evals=10)\n", "    print(\"best hyper_parameter found:\")\n", "    print(space_eval(space, best))"]}, {"cell_type": "code", "execution_count": 27, "metadata": {"id": "a-5ndD8YMJ9M", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1763048586390, "user_tz": -60, "elapsed": 25448, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "e7cea2fa-98b5-48ea-c98d-5df298566394"}, "outputs": [], "source": ["hyperop_loop(\"data/hyperop_loop\")"]}, {"cell_type": "code", "execution_count": 28, "metadata": {"id": "rsV3Z21SlzAs", "colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "executionInfo": {"status": "ok", "timestamp": 1763048587221, "user_tz": -60, "elapsed": 830, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9ab6a3de-73db-46ed-8670-0b0f455c6c02"}, "outputs": [], "source": ["eval_trainings(\"data/hyperop_loop\")"]}, {"cell_type": "markdown", "metadata": {"id": "LxqYLSGCq25y"}, "source": ["### Optimisation Bay\u00e9sienne (explication br\u00e8ve)\n", "\n", "\n", "L'optimisation bay\u00e9sienne est une technique pour trouver le minimum $x$ une fonction inconnue $f(x)$ qui est prend beaucoup de temps \u00e0 \u00e9valuer.\n", "\n", "Dans notre cas $x$ est l'ensemble des hyper-param\u00e8tres, et $f(x)$ est le score d'un entrainement complet (la best-loss).\n", "\n", "\n", "L'id\u00e9e est d'avoir un mod\u00e8le de fonction $\\hat f$. Ajuster ce mod\u00e8le \u00e0 partir de quelques points $x_i,y_i=f(x_i)$. Puis tirer de nouveaux points $x_i,y_i=f(x_i)$ dans la zone o\u00f9 la fonction $\\hat f$ est assez petite. Ajuster mieux la fonction $\\hat f$ avec ces nouveaux points puis recommencer.\n", "\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "dyU9WWxfr6yE"}, "source": ["##Le d\u00e9fi prog\n", "\n", "\n", "* Modifiez agent-mini pour faire des entrainements au 'chrono': chaque hyper-param\u00e8tre doit b\u00e9n\u00e9ficier approximativement du m\u00eame temps d'entrainement.\n", "\n", "\n", "* Une am\u00e9lioration possible dans l'agent est de stocker aussi l'optimisateur-state. Ainsi si l'on red\u00e9marre l'entrainement, l'optimiseur sera d\u00e9j\u00e0 \u00e9chauff\u00e9.\n", "\n", "\n", "\n", "\n", "* Cette agent 'Mini' est fait pour \u00eatre copi\u00e9-coller dans vos diff\u00e9rents projets et am\u00e9lir\u00e9. Par exemple, il pourrait aussi stock\u00e9 le temps pris par l'entrainement. Et on pourrait alors ajouter un score 'loss*temps-d'entrainement' qui serait plus honn\u00e8te pour les petits mod\u00e8les. Ou alors on peut faire les entrainements au chrono (ex: 1 minute chacun).\n", "\n", "\n", "Choisissez l'item ci-dessus qui vous inspire le plus, et codez-le.\n", "\n", "\n", "\n"], "outputs": []}], "metadata": {"accelerator": "GPU", "colab": {"gpuType": "T4", "provenance": [], "authorship_tag": "ABX9TyNA7HEuiKZSuS/d6nahFEir"}, "kernelspec": {"display_name": "Python 3", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 0}