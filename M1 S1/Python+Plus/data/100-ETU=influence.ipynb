{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "toc_visible": true}, "kernelspec": {"name": "python3", "language": "python", "display_name": "Python 3 (ipykernel)"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "markdown", "source": ["# Influence d'une variable al\u00e9atoire sur une autre"], "metadata": {"id": "HW5BQyVj28i5"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["%reset -f"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:08.290523Z", "start_time": "2024-10-25T08:26:08.005358Z"}, "id": "CVwuU1KJ8c3_"}, "execution_count": null}, {"cell_type": "code", "source": ["import numpy as np\n", "import matplotlib.pyplot as plt\n", "import scipy\n", "np.set_printoptions(precision=2,suppress=True, linewidth=100)"], "metadata": {"id": "8YXejcVsHRZW", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.313071Z", "start_time": "2024-10-25T08:26:08.285432Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Introduction"], "metadata": {"id": "Dqf-JwPSGJWu"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Variable al\u00e9atoire et data"], "metadata": {"id": "tmUIqT-0GPRj"}, "outputs": []}, {"cell_type": "markdown", "source": ["Les h\u00e9ros de ce cours sont deux variables al\u00e9atoires $X$ et $Y$. Elles prennent leurs valeurs dans $\\mathbb R$.  Cependant, de nombreuses notions se g\u00e9n\u00e9ralisent si  $X$ et $Y$ prennent leurs valeurs dans $\\mathbb R^n$.\n", "\n", "Habituellement une v.a \u00e0 valeur dans $\\mathbb R^n$ est appel\u00e9e vecteur al\u00e9atoire.  On utilisera souvent le vecteur al\u00e9atoire $Z=(X,Y)$ qui est \u00e0 valeur dans $\\mathbb R^2$.\n", "\n", "\n", "\n", "Pour le traitement de donn\u00e9e, nous allons simplement avoir besoin de data $\\mathtt X=(\\mathtt X_i)$ et $\\mathtt Y=(\\mathtt Y_i)$ qui sont des tirages al\u00e9atoires ind\u00e9pendants de $X$ et $Y$.  Nous les notons avec une police qui rappelle celle des programmes informatiques, car en pratiques, c'est avec des data que l'on fait les calculs.\n", "\n", "Remarque: Les statisticiens appellent \"\u00e9chantillon\" une suite de copies ind\u00e9pendantes des v.a. $X,Y$. Les data-scientists (comme nous) ont surtout besoin de data: qui sont donc la \"r\u00e9alisation\" d'un \u00e9chantillon.\n"], "metadata": {"id": "VlWYEM6HGQw1"}, "outputs": []}, {"cell_type": "markdown", "source": ["### L'exemple concret 1"], "metadata": {"id": "BbggVCG7Q6rF"}, "outputs": []}, {"cell_type": "code", "source": ["def simulate_concrete_1(size):\n", "    X=np.random.normal(size=size)\n", "    Y=X*np.random.exponential(size=size)\n", "    return X,Y"], "metadata": {"id": "usSSzLv9uCV2", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.337573Z", "start_time": "2024-10-25T08:26:08.309548Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X,Y=simulate_concrete_1(5000)\n", "#voici nos r\u00e9alisations:\n", "X,Y"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "MWGXgeW3HPQS", "executionInfo": {"status": "ok", "timestamp": 1731403929065, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "783cf051-6f7e-4466-b3a3-1ab25175f179", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.358840Z", "start_time": "2024-10-25T08:26:08.340013Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "Un 'pairplot' ou un histogramme de $\\mathtt X,\\mathtt Y$ permet d'avoir une id\u00e9e de la loi de $X,Y$."], "metadata": {"id": "ZDTIsj9xDnj6"}, "outputs": []}, {"cell_type": "code", "source": ["def plot_simu(X,Y):\n", "    fig,(ax0,ax1)=plt.subplots(1,2,sharey=\"all\",figsize=(10,5))\n", "    ax0.set_xlabel(\"X\")\n", "    ax1.set_xlabel(\"X\")\n", "    ax0.set_ylabel(\"Y\")\n", "    ax0.scatter(X,Y,s=3,alpha=0.2,linewidths=0)\n", "    ax1.hist2d(X,Y,bins=30)\n", "plot_simu(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 456}, "id": "IpBz_nlsH1M9", "executionInfo": {"status": "ok", "timestamp": 1731403929065, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9f4d9bed-3adc-477d-cdf0-8e088c2b7888", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.467899Z", "start_time": "2024-10-25T08:26:08.358077Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Sur cet exemple,  on voit que $X,Y$ \"s'influencent\" mutuellement sans pour autant qu'il existe un lien de causalit\u00e9 entre eux: il n'y a pas de fonction $f$ telle que $Y=f(X)$ ou $X=f(X)$.\n", "\n", "Le but de ce cours est de quantifier cette notion d'influence, notamment \u00e0 l'aide de la notion de corr\u00e9lation."], "metadata": {"id": "rPIyFpdyKNSd"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Corr\u00e9lation dans le langage de tous les jours\n", "\n", "Dans le langage courant, deux ph\u00e9nom\u00e8nes sont \"corr\u00e9l\u00e9es\" quand ils ont tendance \u00e0 se produire simultan\u00e9ment. Par exemple la pluie est corr\u00e9l\u00e9e \u00e0 la crue des rivi\u00e8res.\n", "\n", "\n", "Quand on peut quantifier les ph\u00e9nom\u00e8nes par deux scores, alors le mot corr\u00e9l\u00e9 signifie que les deux scores ont tendance \u00e0 \u00eatre simultan\u00e9ment grand, ou bien simultan\u00e9ment petit: Par exemple: La quantit\u00e9 de pluie est corr\u00e9l\u00e9e avec le niveau des rivi\u00e8res.\n", "\n", "On parle parfois d'anti-corr\u00e9lation: Le nombre de jours de s\u00e9cheresse est anti-corr\u00e9l\u00e9 avec le niveau des rivi\u00e8res.\n", "\n", "Les math\u00e9maticiens parlent plut\u00f4t de corr\u00e9lation positive, et de corr\u00e9lation n\u00e9gative, car ils ont invent\u00e9 un co\u00e9fficient qui est positif pour les ph\u00e9nom\u00e8nes corr\u00e9l\u00e9s et n\u00e9gatif pour les ph\u00e9nom\u00e8nes anti-corr\u00e9l\u00e9s.\n", "\n", "\n", "### Ne pas confondre\n", "\n", "\n", "Attention \u00e0 ne pas confondre 'corr\u00e9lation' et 'causalit\u00e9'. Voici une petite histoire que vous pouvez raconter autour de vous:\n", "\n", "\"On a fait passer un test de math\u00e9matique \u00e0 tous les enfants d'une \u00e9cole primaire, du CP au CM2. En observant les r\u00e9sultats du test, le directeur d'\u00e9cole en d\u00e9duit que plus les enfants ont de grands pieds, et plus ils sont forts en math.\"\n", "\n", "\n", "\n"], "metadata": {"id": "CUhvb07IoTz-"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\n", "\n", "\n", "***\u00c0 vous:*** Le directeur n'est pas idiot, il confond simplement causalit\u00e9 et corr\u00e9lation. Expliquez.\n"], "metadata": {"id": "gMn0HJao3I_C"}, "outputs": []}, {"cell_type": "markdown", "source": [""], "metadata": {"id": "2-7JMg_i3GGo"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Loi jointe et loi conditionnelle"], "metadata": {"id": "yV15rWUw32JJ"}, "outputs": []}, {"cell_type": "markdown", "source": ["### D\u00e9finition de la loi jointe\n", "\n", "Les lois de $X$ et de $Y$ sont les mesures sur $\\mathbb R$ d\u00e9finies par:\n", "\\begin{align}\n", "Loi_X[A] &= \\mathbf P[X\\in A]\\\\\n", "Loi_Y[B] &= \\mathbf P[Y\\in B]\n", "\\end{align}\n", "Mais ces deux lois ne contiennent pas d'information sur l'interaction entre $X$ et $Y$. C'est la loi jointe qui contient cette information:    \n", "$$\n", "\\forall C\\subset \\mathbb R^2\\qquad Loi_{X,Y}[C] = \\mathbf P[(X,Y) \\in C]\n", "$$\n", "En particulier quand $C=A\\times B$:\n", "$$\n", "Loi_{X,Y}[A\\times B] = \\mathbf P[X\\in A , Y\\in B]\n", "$$\n", "(la virgule dans les proba doit se traduire par \"et\"). Remarquons que la loi jointe permet de retrouver les lois individuelles (aussi appel\u00e9es lois marginales):\n", "\\begin{align}\n", "Loi_X[A] &= Loi_{X,Y}[A\\times \\mathbb R]\\\\\n", "Loi_Y[B] &= Loi_{X,Y}[\\mathbb R \\times B]\n", "\\end{align}\n", "\n", "### Notations infinit\u00e9simales\n", "\n", "Il est  pratique de consid\u00e9rer un \u00e9l\u00e9ment infinit\u00e9simal $dx\\times dy \\subset \\mathbb R^2$, qu'on note aussi $dx\\,dy$, et d'\u00e9crire:\n", "$$\n", "Loi_{X,Y}(dx\\,dy) = \\mathbf P[X\\in dx, Y \\in dy]\n", "$$\n", "La loi jointe  permet de calculer des esp\u00e9rances: pour toute fonction $\\phi:\\mathbb R^2\\to \\mathbb R$:\n", "$$\n", "\\mathbf E[\\phi(X,Y)] = \\int_{\\mathbb R^2} \\phi(x,y) Loi_{X,Y}(dx\\,dy)\n", "$$\n", "\n", "Cette loi jointe admet une densit\u00e9 $f_{X,Y}$ quand on peut \u00e9crire\n", "$$\n", "Loi_{X,Y}(dx\\,dy) = f_{X,Y}(x,y) \\, dx  dy\n", "$$\n", "et donc\n", "$$\n", "\\mathbf E[\\phi(X,Y)]= \\int_{\\mathbb R^2} \\phi(x,y) f_{X,Y}(x,y) \\, dx dy\n", "$$\n", "\n", "\n", "\n"], "metadata": {"id": "49ZRXr233-E3"}, "outputs": []}, {"cell_type": "markdown", "source": ["### D\u00e9finition de la loi conditionnelle\n", "\n", "Pour mieux d\u00e9crire l'influence de $X$ sur $Y$, il est  pratique de consid\u00e9rer la loi de $Y$ sachant $X=x$.\n", "$$\n", "Loi_{Y|X=x}(dy)\n", "$$\n", "Comme la notation l'indique, c'est une mesure en son argument $dy$ et une fonction en son argument $x$. Elle permet de retrouver la loi jointe gr\u00e2ce \u00e0 l'\u00e9quation  de \"reconstruction\":\n", "$$\n", "Loi_{X,Y}(dx\\,dy) = Loi_{Y|X=x}(dy)\\ Loi_{X}(dx)\n", "$$\n", "\n", "\n", "Autre notation:\n", "$$\n", "\\mathbf P[X\\in dx, Y\\in dy] = \\mathbf P[Y\\in dy / X=x] \\ \\mathbf P[X\\in dx]\n", "$$\n", "Mais attention, on ne peut pas \u00e9crire brutalement:\n", "$$\n", "\\mathbf P[Y\\in dy / X=x] = {\\mathbf P[X\\in dx, Y\\in dy]  \\over \\mathbf P[X\\in dx] }\n", "$$\n", "car \u00e7a n'a pas  de sens de diviser des mesures (ou alors, il faut pr\u00e9ciser le sens de cette division).\n", "\n", "\n", "Mais dans le cas particulier o\u00f9 la loi jointe admet une densit\u00e9 $f_{X,Y}$ alors les lois marginales  admettent une densit\u00e9, notamment celle de $X$:\n", "$$\n", "f_X(x)= \\int f_{X,Y}(x,y) dy\n", "$$\n", "et la loi conditionnelle admet la densit\u00e9 suivante:\n", "$$\n", "Loi_{Y|X=x}(dy) = {f_{X,Y}(x,y) \\over f_{X}(x) } dy\n", "$$\n", "(diviser des fonctions cela a du sens. Et de plus, dans cette \u00e9quation, la convention $\\frac 00=0$ a du sens, et r\u00e9gle le probl\u00e8me de la division par $0$).\n"], "metadata": {"id": "TANourc57B3q"}, "outputs": []}, {"cell_type": "markdown", "source": ["*Point technique:*  La loi conditionnelle n'est pas tout \u00e0 fait unique: En effet, si on consid\u00e8re une variante  $Loi2_{Y|X=x}$ qui diff\u00e8re de $Loi_{Y|X=x}$ uniquement sur un ensemble de $x$ qui est n\u00e9gligeable pour $Loi_{X}$, alors l'\u00e9quation de reconstruction est toujours valide, et donc $Loi2_{Y|X=x}$ est aussi l\u00e9gitime que $Loi_{Y|X=x}$."], "metadata": {"id": "sciU5Yq_9Nb0"}, "outputs": []}, {"cell_type": "markdown", "source": ["###  Exemple concret 2"], "metadata": {"id": "dQjwZQXlAqVO"}, "outputs": []}, {"cell_type": "markdown", "source": ["Nous simulons un couple de variable al\u00e9atoire $X,Y$ comme ceci"], "metadata": {"id": "PAROxRY9A4Th"}, "outputs": []}, {"cell_type": "code", "source": ["def simulate_concrete_2(size):\n", "    X=np.random.uniform(0,1,size=size)\n", "    Y=np.random.normal(loc=X,scale=np.sqrt(X))\n", "    return X,Y\n", "\n", "X,Y=simulate_concrete_2(50_000)\n", "plot_simu(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 461}, "id": "BanmG78mA20J", "executionInfo": {"status": "ok", "timestamp": 1731403930191, "user_tz": -60, "elapsed": 1128, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "42144166-855e-478a-ed93-6d92c73e7645", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.605264Z", "start_time": "2024-10-25T08:26:08.464360Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "* $X$ suit une loi uniforme sur $[0,1]$\n", "* Sachant $X=x$, la v.a $Y$ suit une loi normale de moyenne $x$ et d'\u00e9cart type $\\sqrt x$.\n", "\n", "R\u00e9\u00e9crivons cela en notation math\u00e9matique:\n", "$$\n", "Loi_X(dx) = 1_{[0,1]}(x) \\, dx\n", "$$\n", "$$\n", "Loi_{Y|X=x}(dy)  = {1\\over \\sqrt{2\\pi x}}\\exp(-\\frac 12 { (y-x)^2 \\over x }) dy\n", "$$\n", "Par cons\u00e9quent:\n", "$$\n", "Loi_{X,Y}(dx\\,dy)={1\\over \\sqrt{2\\pi x}}\\exp(-\\frac 12 { (y-x)^2 \\over x })1_{[0,1]}(x) \\, dx dy\n", "$$\n"], "metadata": {"id": "ey3-Iu4D_osZ"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\n", "\n", "", "\n", "Pour l'exemple concret 1 on a:\n", "\n", "    X=np.random.normal(size=size)\n", "    Y=X*np.random.exponential(size=size)\n", "\n", "Donc en notation math\u00e9matique:\n", "$$\n", "Loi_X(dx) = {1\\over \\sqrt{2\\pi}}\\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "Si $x>0$:\n", "$$\n", "Loi_{Y|X=x}(dy)  = {1\\over x} \\color{red}{\\square \\square \\square} 1_{y>0}\n", "$$\n", "Si $x < 0$:\n", "$$\n", "Loi_{Y|X=x}(dy)  = {1\\over |x|} \\color{red}{\\square \\square \\square} 1_{y < 0}\n", "$$\n", "\n", "Pas besoin de traiter le cas $x=0$ car il est n\u00e9gligeable au regard de $Loi_X$."], "metadata": {"id": "Qn86v3Zl0QbK"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Conditionnements en cascade\n", "\n", "Notez que dans l'exemple concret 2, on construit la loi jointe de $(X,Y)$ \u00e0 partir de la loi conditionnelle.  C'est une situation tr\u00e8s fr\u00e9quente en mod\u00e9lisation. Et m\u00eame tr\u00e8s souvent on a plusieurs \u00e9tages de conditionnements.\n", "\n", "* Voici un exemple \u00e0 2 \u00e9tages:  On veut mod\u00e9liser la taille d'une esp\u00e8ce de poissons: On note $X$ la temp\u00e9rature de l'eau. On suppose que cette temp\u00e9rature suit une loi exponentielle de param\u00e8tre 1. Puis sachant $X=x$, la taille du poisson suit une loi normale d'esp\u00e9rance $(x+10)^2$ et d'\u00e9cart type $\\sqrt x$.\n", "\n", "* Voici un exemple \u00e0 3 \u00e9tages:  Toujours pour des tailles de poissons: On note $P$ une v.a. qui repr\u00e9sente la profondeur de l'endroit o\u00f9 vit le poisson. $P$ suit une loi Gamma de param\u00e8tre 1. Puis sachant $P=p$, la temp\u00e9rature de l'eau suit une loi exponentielle de param\u00e8tres $p$. Ensuite, sachant $X=x$, la taille du Poisson suit une loi normale d'esp\u00e9rance $(x+10)^2$ et d'\u00e9cart type $\\sqrt x$.\n", "\n", "* Voici un exemple \u00e0 4 \u00e9tages: On note $O$ une v.a discr\u00e8te qui d\u00e9crit l'oc\u00e9an o\u00f9 vit le poisson: $O=1$ si s'il vit dans l'oc\u00e9an atlantique,  $O=2$ s'il vit dans l'oc\u00e9an pacifique, etc. On suppose la proba que $O=k$ est proportionnelle \u00e0 la taille de l'oc\u00e9an.  Puis sachant $O=k$, la profondeur de l'eau $P$ suit une loi gamma dont le param\u00e8tre d\u00e9pend de $k$. Ensuite, on d\u00e9crit la loi conditionnelle de la temp\u00e9rature de l'eau, et pour finir celle de la taille du poisson.\n", "\n", "\n", "\n", "\n", "\n", "\n"], "metadata": {"id": "fQOkxLA6EuZ6"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Ind\u00e9pendance\n"], "metadata": {"id": "gfkbSLxLDKtj"}, "outputs": []}, {"cell_type": "markdown", "source": ["### D\u00e9finition et premi\u00e8res caract\u00e9risations"], "metadata": {"id": "A6MNRkUETZxn"}, "outputs": []}, {"cell_type": "markdown", "source": ["> ***D\u00e9finition:*** On dit que $X$ et $Y$ sont ind\u00e9pendantes quand\n", "$$\n", "\\forall A,B \\qquad \\mathbf P[X\\in A,Y\\in B]= \\mathbf P[X\\in A]\\, \\mathbf P[Y\\in B]\n", "$$\n", "\n", "\n", "Remarque: quand on parle avec des non-probabilistes, il est pr\u00e9f\u00e9rable de dire \"statistiquement ind\u00e9pendant\", car le mot \"ind\u00e9pendant\" \u00e0 plein de sens, y compris en math. Par exemple \"lin\u00e9airement ind\u00e9pendant\".\n", "\n"], "metadata": {"id": "uJ6KwJqtRYXP"}, "outputs": []}, {"cell_type": "markdown", "source": ["L'\u00e9quation ci-dessus s'\u00e9crit aussi:\n", "$$\n", "Loi_{X,Y}(dx\\,dy) = Loi_X(dx) Loi_Y(dy)\n", "$$\n", "Et quand cette loi jointe admet une densit\u00e9 $f_{X,Y}$, cela \u00e9quivaut \u00e0 dire que celle fonction peut s'\u00e9crire\n", "$$\n", "f_{X,Y}(x,y) = g(x)h(y)\n", "$$\n", "Et en normalisant:\n", "* ${g\\over \\int g}$ est n\u00e9cessairement la densit\u00e9 de $X$\n", "* ${h\\over \\int h}$ est n\u00e9cessairement la densit\u00e9 de $Y$"], "metadata": {"id": "YHYwWWchSVx0"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "Voici la caract\u00e9risation la plus classique de l'ind\u00e9pendance: le fait de pouvoir 'spliter' les esp\u00e9rances:\n", "\n", "> ***Proposition:*** $X$ et $Y$ sont ind\u00e9pendantes ssi\n", "$$\n", "\\forall \\phi,\\psi\\qquad \\mathbf E[\\phi(X)\\psi(Y)]=\\mathbf E[\\phi(X)]\\mathbf E[\\psi(Y)]\n", "$$\n"], "metadata": {"id": "EaIbx4oBDRda"}, "outputs": []}, {"cell_type": "markdown", "source": ["###  Caract\u00e9risation par la loi conditionnelle"], "metadata": {"id": "xdLFDiL0TfZI"}, "outputs": []}, {"cell_type": "markdown", "source": ["Je pense que vous connaissiez bien les caract\u00e9risations de l'ind\u00e9pendance de la section pr\u00e9c\u00e9dente. Mais la suite est moins connue:\n", "\n", "\n", "> ***Proposition:*** Les trois points suivants sont \u00e9quivalents:\n", "* $X$ et $Y$ sont ind\u00e9pendantes\n", "* $Loi_{Y|X=x}(dy)$ ne d\u00e9pend pas de $x$ (c'est toujours la m\u00eame mesure).\n", "* $Loi_{X|Y=y}(dx)$ ne d\u00e9pend pas de $y$ (c'est toujours la m\u00eame mesure).\n", "\n", "\n", "\u00c0 mon avis, c'est la bonne mani\u00e8re de comprendre d'ind\u00e9pendance probabiliste: Le fait que $X$ prennent la valeur $x$ ou $x'$  n'influe pas sur la proba que $Y$ soit dans $dy$ ou $dy'$. Et c'est idem en inversant $X$ et $Y$ dans la phrase pr\u00e9c\u00e9dent.\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"], "metadata": {"id": "Rt1EWYurU6YN"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\n", "\n", "***\u00c0 vous:*** D\u00e9montrez cette proposition dans le cas particulier o\u00f9 $X,Y$ admet une densit\u00e9 $f_{X,Y}$.  "], "metadata": {"id": "RvLxsSBTOh5_"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\n", "\n", "***\u00c0 vous:*** Dans les exemples concrets 1 et 2, comment peut-on voir imm\u00e9diatement qu'il n'y a pas ind\u00e9pendances entre $X$ et $Y$ ?"], "metadata": {"id": "woDQMNXG1uzH"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Lien avec la causalit\u00e9\n", "\n", "On dit qu'il y a un lien causal de $X$ vers $Y$ quand il existe une fonction $f$ telle que $Y=f(X)$. On comprend intuitivement que cela emp\u00eache l'ind\u00e9pendance entre $X$ et $Y$."], "metadata": {"id": "9hlfEW96_vrd"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "> ***Proposition:*** Prenons deux v.a $X,Y$ non-constantes. S'il y a un lien causal de $X$ vers $Y$ ou bien de $Y$ vers  et si $X$  alors, elles ne sont pas ind\u00e9pendantes.\n", "\n", "\n", "*D\u00e9mo:*  Supposons par exemple que $Y=f(X)$ alors\n", "$$\n", "Loi_{Y|X=x}(dy) = \\delta_{f(x)}(dy)\n", "$$\n", "o\u00f9 le delta est la mesure de Dirac. Cette quantit\u00e9 varie avec $x$ donc on est en situation de non-ind\u00e9pendance. Et la d\u00e9mo est la m\u00eame si on a $X=f(Y)$. $\\square$\n", "\n", "\n", "*Remarque:* Un v.a constante est ind\u00e9pendante avec n'importe quelle autre v.a. Dans la d\u00e9mo pr\u00e9c\u00e9dente, on utilise bien le fait que $X$ et $Y$ ne sont pas constantes.\n", "\n", "\n", "### Non-causal et non-ind\u00e9pendant\n", "\n", "Mais attention: ce n'est pas parce qu'il n'y a pas de lien causal qu'il y a forc\u00e9ment ind\u00e9pendance.\n", "\n", "Un contre-exemple peut facilement se construire en observant les supports de loi jointe: Le fait d'avoir un lien causal de $X$ vers $Y$ \u00e9quivaut \u00e0 dire que le support de $Loi_{X,Y}$ est le graphe d'une fonction. Situation oppos\u00e9e: Si $X$ et $Y$ sont ind\u00e9pendantes, alors le support de la loi jointe est un rectangle (\u00e9ventuellement non born\u00e9). Ainsi, dans toutes les situations o\u00f9 le support de la loi jointe n'est ni un graph, ni un rectangle il y a non-causalit\u00e9 et non-ind\u00e9pendance.  \n", "\n", "\n", "\n"], "metadata": {"id": "kun5c_rZ2eyd"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Covariance\n", "\n", "\n"], "metadata": {"id": "iSSKMb86ksOU"}, "outputs": []}, {"cell_type": "markdown", "source": ["### D\u00e9finition"], "metadata": {"id": "E68xPJHhp6lc"}, "outputs": []}, {"cell_type": "markdown", "source": ["> ***D\u00e9finition:*** Soit $X$ et $Y$ deux variables al\u00e9atoires. Leur covariance est d\u00e9finie par:\n", "$$\n", "cov(X,Y)= \\mathbf E [ (X-\\mathbf E(X))(Y-\\mathbf E(Y)) ]\n", "$$\n", "\n", "\n", "***\u00c0 vous:*** Il y a une seconde formule bien pratique pour calculer la covariance, que l'on obtient simplement en d\u00e9veloppant le produit dans l'esp\u00e9rance ci-dessus:"], "metadata": {"id": "LY7mjm2flLwz"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661"], "metadata": {"id": "d_9logTa2AuU"}, "outputs": []}, {"cell_type": "markdown", "source": ["", "$$\n", "cov(X,Y)=  \\mathbf E [XY] -\\color{red}{\\square \\square \\square}\n", "$$"], "metadata": {"id": "fasTm10x2AFP"}, "outputs": []}, {"cell_type": "markdown", "source": ["###  Ind\u00e9pendante \u21d2 non-corr\u00e9l\u00e9e\n"], "metadata": {"id": "tVtx3NffE1YU"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661"], "metadata": {"id": "aoMgpxXb18iV"}, "outputs": []}, {"cell_type": "markdown", "source": ["", "\n", "> ***Proposition:*** Si $X$ et $Y$ sont ind\u00e9pendantes, on a:\n", "$$\n", "cov(X,Y) =\\color{red}{\\square \\square \\square}\n", "$$"], "metadata": {"id": "Y6tboYrp10hN"}, "outputs": []}, {"cell_type": "markdown", "source": ["###   Non-corr\u00e9l\u00e9e $\\not \\Rightarrow$ ind\u00e9pendante\n"], "metadata": {"id": "TnLa6-ETpX9j"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "Contre-exemple pour la r\u00e9ciproque: Consid\u00e9rons n'importe quelle figure $F\\subset \\mathbb R^2$ avec une sym\u00e9trie selon l'axe des abscisses. Consid\u00e9rons $X,Y$ un point tir\u00e9 uniform\u00e9ment sur cette figure. Alors $cov(X,Y)=0$.\n", "\n", "En effet, la sym\u00e9trie implique que la loi de $(X,Y)$ est \u00e9gale \u00e0 la loi de $(-X,Y)$. En utilisant la bilin\u00e9arit\u00e9 de la covariance:\n", "$$\n", "cov(X,Y)= cov(-X,Y) = -cov(X,Y) = 0\n", "$$\n", "Or en prenant $F$ qui n'est pas un rectangle, il n'y a pas ind\u00e9pendance entre $X$ et $Y$.\n"], "metadata": {"id": "Ek77MrMG2OBK"}, "outputs": []}, {"cell_type": "code", "source": ["def simulate_one_unif_in_F():\n", "    go_on=True\n", "    while go_on:\n", "        X=np.random.uniform(-1.5,1.5)\n", "        Y=np.random.uniform(-2.5,2.5)\n", "        go_on = -1<X<1 and -1<Y<1\n", "    return X,Y\n", "\n", "def simulate_several_unif_in_F(size):\n", "    Xs,Ys=[],[]\n", "    for _ in range(size):\n", "        X,Y=simulate_one_unif_in_F()\n", "        Xs.append(X)\n", "        Ys.append(Y)\n", "    return np.array(Xs),np.array(Ys)\n", "\n", "X,Y=simulate_several_unif_in_F(10)\n", "X,Y"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "iEPkqKVzeiMJ", "executionInfo": {"status": "ok", "timestamp": 1731403930191, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "dc1137b0-0c2b-4f3d-9e49-d200842a818f", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.606723Z", "start_time": "2024-10-25T08:26:08.583173Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#version vectoris\u00e9e, plus rapide, mais la taille de l'\u00e9chantillon est al\u00e9atoire\n", "def simulate_unif_in_F(n):\n", "    X=np.random.uniform(-1.5,1.5,size=n)\n", "    Y=np.random.uniform(-2.5,2.5,size=n)\n", "    in_center =  (-1<X) & (X<1) & (-1<Y) & (Y<1)\n", "    not_in_center=~in_center\n", "\n", "    return X[not_in_center],Y[not_in_center]\n", "\n", "X,Y=simulate_unif_in_F(20_000)\n", "plot_simu(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 461}, "id": "lQe8wANFiltH", "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 1728, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2935ff12-e007-4086-85d6-68c8a90d3c46", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.726390Z", "start_time": "2024-10-25T08:26:08.587062Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\u2661\n", "\n", "\n", "***\u00c0 vous:*** Qu'en est-il si la figure $F$ est sym\u00e9trique selon l'axe des ordonn\u00e9es? ou selon une sym\u00e9trie centrale?"], "metadata": {"id": "m9hZ0lBE2Oiq"}, "outputs": []}, {"cell_type": "markdown", "source": [""], "metadata": {"id": "ccf1Ig5MlMgt"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Matrice de covariance"], "metadata": {"id": "mS39QfSwlD6C"}, "outputs": []}, {"cell_type": "markdown", "source": ["***D\u00e9finition:*** Consid\u00e9rons $Z$ un vecteur al\u00e9atoire \u00e0 valeur dans $\\mathbb R^n$. La matrice de covariance de $Z=(Z_i)$ c'est la matrice\n", "$$\n", "cov(Z)_{i,j} = cov (Z_i,Z_j)\n", "$$\n", "En particulier sur la diagonale\n", "$$\n", "cov(Z)_{i,i} = var (Z_i)\n", "$$\n"], "metadata": {"id": "5zOsfUb-lQHD"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Estimation de la covariance\n"], "metadata": {"id": "LBF9Q8Jvl6iM"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Codons \u00e0 la main"], "metadata": {"id": "QrA1AafUl7YJ"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "* $\\mathbf E[X]$ est estim\u00e9 par `mean(X)` (la moyenne des data `X`).\n", "* $\\mathbf E[Y]$ est estim\u00e9 par `mean(Y)` (la moyenne des data `Y`).\n", "\n", "\n", "\n", "La covariance $cov(X,Y)$ peut aussi \u00eatre estim\u00e9e avec les data:\n", "\n", "    cov(X,Y) = 1/(n-1) sum_i (X[i]-mean(X))(Y[i]-mean(Y))\n", "\n", "En particulier `cov(X,X)=std2(X)` est l'estimateur classique de la variance.\n", "\n", "S'il vous plait, faites toujours la distinction entre les quantit\u00e9s que l'on estime \u00e0 partir d'observations et les quantit\u00e9s th\u00e9oriques. Si, quand vous r\u00e9digez, vous ne disposez pas de plusieurs polices, vous pouvez noter les estimateurs avec des tildes ou des chapeaux: $c\\tilde ov$,  $c\\hat ov$ pour les distinguer de la vraie covariance $cov$."], "metadata": {"id": "5bLfWuPM-q2D"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "Impl\u00e9mentons la fonction qui renvoie l'estimation de la covariance:\n", "    "], "metadata": {"id": "S9S9TnLmFSyi"}, "outputs": []}, {"cell_type": "code", "source": ["def cov(X,Y):\n", "    n=len(X)\n", "    assert n==len(Y)\n", "    X=X-np.mean(X)\n", "    Y=Y-np.mean(Y)\n", "    return X@Y/(n-1)\n", "\n", "def test():\n", "    np.random.seed(1234)#pour avoir toujours le m\u00eame r\u00e9sultat\n", "    X,Y=simulate_unif_in_F(100_000)\n", "    print(cov(X,Y))\n", "\n", "\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "4D7_4BbenCPc", "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ac0ed4ff-dcf6-4c86-8e30-1fcf8c6d26ea", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.737204Z", "start_time": "2024-10-25T08:26:08.699495Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Dans le test, on obtient une valeur proche de z\u00e9ro... Et pas z\u00e9ro exactement: il ne s'agit que d'une estimation!"], "metadata": {"id": "V2G9CIiGnt12"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### $\\heartsuit$"], "metadata": {"collapsed": false, "id": "19kxwXrL8c4H"}, "outputs": []}, {"cell_type": "markdown", "source": ["***\u00c0 vous:*** Pourquoi est-ce que la variante suivante serait une tr\u00e8s mauvaise id\u00e9e:\n", "\n", "    def cov(X,Y):\n", "        n=len(X)\n", "        assert n==len(Y)\n", "        X-=np.mean(X)\n", "        Y-=np.mean(Y)\n", "        return X@Y/(n-1)\n", "\n", "", "R\u00e9ponse: Car l'op\u00e9ration `-=` est une op\u00e9ration <font color=\"red\"> \u25a1 \u25a1 \u25a1 </font>. Notre fonction `cov` <font color=\"red\"> \u25a1 \u25a1 \u25a1 </font>  les donn\u00e9es de l'utilisateur."], "metadata": {"collapsed": false, "id": "rum8d7Qp8c4H"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Sur l'exemple concret 2"], "metadata": {"id": "yO-SQ8q6p-Zz"}, "outputs": []}, {"cell_type": "code", "source": ["X,Y=simulate_concrete_2(10_000)\n", "plot_simu(X,Y)"], "metadata": {"id": "Ba2KiXeUmVFS", "colab": {"base_uri": "https://localhost:8080/", "height": 461}, "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 6, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "15bdb437-56b8-48ea-9e24-b474dbb54c67", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.944433Z", "start_time": "2024-10-25T08:26:08.705572Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On a l'impression que $X$ et $Y$ sont l\u00e9g\u00e8rement corr\u00e9l\u00e9es positivement. V\u00e9rifions-le par notre estimation:"], "metadata": {"id": "KuQiFL3pwLfs"}, "outputs": []}, {"cell_type": "code", "source": ["cov(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "RtmBnyJpokqD", "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "5c7a1ac7-eafb-4f79-f8fa-db21bffa917b", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.954157Z", "start_time": "2024-10-25T08:26:08.909519Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Autre fa\u00e7on de calculer: on consid\u00e8re le vecteur al\u00e9atoire $Z=(X,Y)$, on calcule sa matrice de covariance avec numpy, puis on prend un des deux coefficients non-diagonal."], "metadata": {"id": "7gDg807Fp_cY"}, "outputs": []}, {"cell_type": "code", "source": ["def cov_np(X,Y):\n", "    XY=np.stack([X,Y],axis=0)\n", "    return np.cov(XY,ddof=1)[0,1]\n", "cov_np(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "G2G5dN_7nsA-", "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "7cabb501-f185-4650-9cf3-107a78492f1a", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.955734Z", "start_time": "2024-10-25T08:26:08.912885Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Un calcul exacte la matrice de covariance"], "metadata": {"id": "6LsR4MWY0Yss"}, "outputs": []}, {"cell_type": "markdown", "source": ["Quand on travaille \u00e0 des data r\u00e9colt\u00e9es dans la vraie vie, on n'a pas acc\u00e8s \u00e0 leur loi, donc on n'a que des estimations de covariances, variances, esp\u00e9rances.\n", "\n", "\n", " Mais dans nos deux exemples concrets, le couple $(X,Y)$ a une loi jointe simple et explicite. On va pouvoir effectuer les calculs th\u00e9oriques. On se concentrera sur l'exemple concert 2:\n", "\n", "* $X$ suit une loi uniforme sur $[0,1]$\n", "* Sachant $X=x$, la v.a $Y$ suit une loi normale de moyenne $x$ et d'\u00e9cart type $\\sqrt x$."], "metadata": {"id": "hSwKcp9B0cma"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Calcul de la co-variance"], "metadata": {"id": "MkcqSLjfaYEv"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\u2661"], "metadata": {"id": "5lAVk8-X4utm"}, "outputs": []}, {"cell_type": "markdown", "source": ["", "\n", "*  Calculons $\\mathbf E[Y]$. Sachant $X=x$, la v.a $Y$ suit une loi normale de moyenne $x$, donc:\n", "$$\n", "\\mathbf E[Y/X=x]= \\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "---\n", "\n", "En int\u00e9grant:\n", "$$\n", "\\mathbf E[Y] =\\int \\mathbf E[Y/X=x] \\mathbf P[X\\in dx]  =\n", " \\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "---\n", "\n", "* Calculons $cov(X,Y)$.\n", "$$\n", "\\mathbf E[XY/X=x] = \\mathbf E[xY/X=x]= \\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "---\n", "\n", "En int\u00e9grant:\n", "$$\n", "\\mathbf E[XY]= \\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "---\n", "\n", "Et pour conclure:\n", "$$\n", "cov(X,Y) =\n", "\\mathbf E[XY]-\\mathbf E[X]\\mathbf E[Y] = \\color{red}{\\square \\square \\square}\n", "$$\n", "\n", "\u00c0 la fin, il faut pr\u00e9senter le r\u00e9sultat sous la forme d'une fraction irr\u00e9ductible.  \n"], "metadata": {"id": "QxViU9Kn000d"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Une erreur classique\n", "\n", "Attention erreur classique: la variance d'une v.a ne s'obtient par en int\u00e9grant la variance conditionnelle. En particulier pour notre exemple:\n", "$$\n", "var(Y) \\neq \\int \\mathbf E[ (Y-\\mathbf E[Y/X=x])^2 /X=x ] \\ \\mathbf P[X\\in dx]\n", "=\\int_0^1 x dx\n", "$$\n", "Pour comprendre pourquoi cela ne fonctionne pas, en d\u00e9veloppant le terme de droite, on tombe sur\n", "$$\n", "\\int (\\mathbf E[ Y^2/X=x ] - E[ Y/X=x ]^2)  \\ \\mathbf P[X\\in dx]\n", "=\n", "\\mathbf E[ Y^2] - \\int  E[ Y/X=x ]^2 \\mathbf P[X\\in dx]\n", "$$\n", "L'\u00e9quation de reconstruction ne permet pas de simplifier le dernier terme."], "metadata": {"collapsed": false, "id": "TydBpd128c4I"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Calcul des variances"], "metadata": {"id": "NF0USaHrab8A"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\u2661"], "metadata": {"id": "poeCcN4nrq9z"}, "outputs": []}, {"cell_type": "markdown", "source": ["", "\n", "\n", "* La variance de $X$ vaut $1/12$ car la variance d'une loi uniforme sur un intervalle [a,b] c'est $\\color{red}{\\square \\square \\square}$.\n", "\n", "---\n", "\n", "* Calculons la variance de $Y$: Pour une v.a $K$ de loi $N(a,\\sigma^2)$ on a\n", "$$\n", "\\mathbf E[K^2]=\\sigma^2+a^2\n", "$$\n", "Dans notre cas, sachant $X=x$,  $Y$ suit une loi normale d'\u00e9cart-type $\\sqrt{x}$ et d'esp\u00e9rance $x$ donc:  \n", "$$\n", "\\mathbf E[Y^2/X=x] = \\color{red}{\\square \\square \\square}\n", "$$\n", "En int\u00e9grant\n", "$$\n", "\\mathbf E[Y^2] = \\color{red}{\\square \\square \\square}\n", "$$\n", "donc:\n", "$$\n", "var(Y) = \\color{red}{\\square \\square \\square}\n", "$$\n"], "metadata": {"id": "TGhznAmK3YpO"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "...\n"], "metadata": {"id": "F8r4nkhC6hAn"}, "outputs": []}, {"cell_type": "markdown", "source": ["Comparons la vraie matrice de covariance et son estimation:"], "metadata": {"id": "4kxV5iLYa82h"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": [" true_cov=np.array([[...\n", "true_cov"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:08.957659Z", "start_time": "2024-10-25T08:26:08.917539Z"}, "id": "e6DuG_7k8c4I", "outputId": "137c4455-f92f-4138-c6ef-2d9b6a246387", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "code", "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["array([[0.08, 0.08],\n", "       [0.08, 0.58]])"]}, "metadata": {}, "execution_count": 13}], "source": ["#--- To keep following outputs, do not run this cell! ---"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:08.957659Z", "start_time": "2024-10-25T08:26:08.917539Z"}, "id": "e6DuG_7k8c4I", "outputId": "137c4455-f92f-4138-c6ef-2d9b6a246387", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["Comparons avec l'estimation:"], "metadata": {"id": "oRhxFphx__v0"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["np.random.seed(134)\n", "#On tire beaucoup de donn\u00e9e pour avoir une bonne estimation\n", "X,Y=simulate_concrete_2(100_000)\n", "estimate_cov=np.cov(np.stack([X,Y],axis=0),ddof=1)\n", "estimate_cov"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:08.962122Z", "start_time": "2024-10-25T08:26:08.923326Z"}, "id": "A1HX5p7a8c4I", "outputId": "258a57f0-c038-4427-b6ff-9db08066fc81", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["## Correlations  de Pearson et spearman"], "metadata": {"id": "0DiDNMyiAdKx"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Pearson"], "metadata": {"id": "Y5rkKSbjr8h5"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "> ***D\u00e9finition:*** Le coefficient de corr\u00e9lation de Pearson  est d\u00e9fini par:\n", "$$\n", "cor(X,Y) = { cov(X,Y)\\over \\sqrt{var(X)}\\sqrt{var(Y)} }\n", "$$\n", "\n", "Remarquons que c'est une simple renormalisation de la covariance.  Cette correlation permet d'indiquer la relation entre $X$ et $Y$ ind\u00e9pendamment de leur magnitude. En particulier:\n", "\n", "\n", "> ***Proposition:*** Pour toutes constantes $a,b$ on a:\n", "$$\n", "cor(a X, b Y) = cor(X,Y)\n", "$$"], "metadata": {"id": "HsJkVaKfArTL"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\u2661\n", "\n", "***\u00c0 vous:*** D\u00e9montrez cette proposition et, chemin faisant, vous allez voir qu'il manque une hypoth\u00e8se tr\u00e8s importante pour qu'elle soit vraie. Corriger l'\u00e9nonc\u00e9.\n", "\n", ""], "metadata": {"id": "hLSQ546ys5IT"}, "outputs": []}, {"cell_type": "markdown", "source": ["> ***Proposition:*** Le coefficient de corr\u00e9lation est toujours dans l'intervalle $[-1,1]$."], "metadata": {"id": "UNb3cCDLs7IT"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\n", "\n", "", "*D\u00e9monstration:* C'est une cons\u00e9quence imm\u00e9diate de l'in\u00e9galit\u00e9 de <font color=\"red\"> \u25a1 \u25a1 \u25a1 </font> $\\square$"], "metadata": {"id": "thz9WkwFtOZG"}, "outputs": []}, {"cell_type": "code", "source": ["#reprenons l'exemple l'exemple, calculons la corr\u00e9lation\n", "X,Y=simulate_concrete_2(50000)\n", "Z=np.stack([X,Y],axis=0)"], "metadata": {"id": "o0tTUvouB8Uz", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.963423Z", "start_time": "2024-10-25T08:26:08.929366Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["np.corrcoef(Z)#Dans cette fonction, pas d'argument ddof. Tant pis."], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ruC_4MXwB9PT", "executionInfo": {"status": "ok", "timestamp": 1731403931917, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "984c023a-c253-4077-d9fb-9bbebdea2e3f", "ExecuteTime": {"end_time": "2024-10-25T08:26:08.964705Z", "start_time": "2024-10-25T08:26:08.932778Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\n", "\n", "La corr\u00e9lation se trouve sur la non-diagonale. Pourquoi d'apr\u00e8s vous n'y a-t-il pas d'argument `ddof` dans la fonction `np.corrcoef`? Alors que cet argument est pr\u00e9sent dans `np.cov`.  \n", "\n", ""], "metadata": {"id": "9bqivKTCJHgy"}, "outputs": []}, {"cell_type": "markdown", "source": ["On peut aussi utiliser `scipy` pour calculer ce coefficient:"], "metadata": {"id": "vbPLxb0gDYxP"}, "outputs": []}, {"cell_type": "code", "source": ["scipy.stats.pearsonr(X, Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UISzmtL4Ddx4", "executionInfo": {"status": "ok", "timestamp": 1731403932477, "user_tz": -60, "elapsed": 563, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0b6052a1-9bd4-4e95-aa8f-379aa60e1abc", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.039880Z", "start_time": "2024-10-25T08:26:08.935969Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": [" `scipy` donne aussi une p-value: la p-value du test de student sur la nullit\u00e9 de ce coefficient. Quand cette p-value  est  petite (inf\u00e9rieure `1e-3`),  cela indique que ce coefficient est significativement diff\u00e9rent de z\u00e9ro."], "metadata": {"id": "-VwreNy2Dkm-"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\n", "\n", "En utilisons nos calculs th\u00e9oriques pr\u00e9c\u00e9dents pour calculer le vrai coefficient de corr\u00e9lation de l'exemple concret 2."], "metadata": {"id": "_k_HhnMsC_YH"}, "outputs": []}, {"cell_type": "code", "source": [" Faites un petit calcul qui donne une valeur num\u00e9rique de la vrai valeur de la corr\u00e9lation.\n"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "j3M0koWpCJIO", "executionInfo": {"status": "ok", "timestamp": 1731403932477, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6d00075c-3ca2-4034-fea0-3c3ecd86985e", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.041337Z", "start_time": "2024-10-25T08:26:08.940205Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#--- To keep following outputs, do not run this cell! ---"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "j3M0koWpCJIO", "executionInfo": {"status": "ok", "timestamp": 1731403932477, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6d00075c-3ca2-4034-fea0-3c3ecd86985e", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.041337Z", "start_time": "2024-10-25T08:26:08.940205Z"}}, "execution_count": null, "outputs": [{"output_type": "execute_result", "data": {"text/plain": ["0.3779644730092272"]}, "metadata": {}, "execution_count": 18}]}, {"cell_type": "markdown", "source": ["Une corr\u00e9lation \u00e0 37%: c'est pas mal.  $X,Y$ sont fortement corr\u00e9l\u00e9e; ce qui ne se voyait pas bien avec la covariance qui \u00e9tait de l'ordre de 0.08"], "metadata": {"id": "KbdIgqq32nWt"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "L93HpHWNh2Bv"}, "source": ["\n", "###  Corr\u00e9lations extr\u00e8mes"], "outputs": []}, {"cell_type": "markdown", "source": ["Le coefficient de corr\u00e9lation (de Pearson) entre deux variables $X$ et $Y$ mesurent \u00e0 quel point $Y$ est proche d'une fonction affine de $X$. Les valeurs extr\u00e8mes $+1$ et $-1$ de ces corr\u00e9lations indiquent des relations purement affines:\n", "\n", "> ***Proposition:***\n", "* $cor(X,Y) = 1$  ssi $Y = aX+b$ avec $a > 0$.\n", "* $cor(X,Y) = -1$ ssi $Y = aX+b$ avec $a < 0$\n", "\n", "*D\u00e9monstration dans un sens:* On fait seulement le sens facile: Montrons que si $Y = aX+b$ avec $a > 0$ alors  $cor(X,Y) = 1$:\n", "\n", "Supposons donc que $Y = aX+b$ avec $a>0$.   On a:\n", "$$\n", "cov(X,Y) = cov(X,aX+b)= cov(X,aX) =  a \\,\n", " cov(X,X) = a \\, var(X)\n", "$$\n", "Tandis que\n", "\n", "<font color='red'> Finir</font>\n"], "metadata": {"id": "pJuAgkTEbb-x"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "DjAacD0W2G9I"}, "source": ["\n", "Cette proposition a un \u00e9quivalent pour les estimateurs: Notons maintenant $\\mathtt X,\\mathtt Y$ des \u00e9chantillons:\n", "* $\\mathtt{cov (X,Y)} = 1$ ssi $\\forall i: \\mathtt Y_i = a \\mathtt X_i+b$ avec $a>0$.\n", "* $\\mathtt{cov (X,Y)} = 1$ ssi $\\forall i: \\mathtt Y_i = a \\mathtt X_i+b$ avec $a < 0$."], "outputs": []}, {"cell_type": "markdown", "source": ["### Spearman\n", "\n", "Introduisons maintenant le coefficient de corr\u00e9lation de Spearman $spear(X,Y)$ et son estimateur $\\mathtt {spear(X,Y)}$. Elles v\u00e9rifient:\n", "\n", "\n", "* ${spear (X,Y)} = 1$ ssi $ Y = f(X)$ pour une fonction $f$ croissante.\n", "* ${spear (X,Y)} = -1$ ssi $ Y = f(X)$ pour une fonction $f$ d\u00e9croissante.\n", "\n", "* $\\mathtt{spear (X,Y)} = 1$ ssi $\\forall i: \\mathtt Y_i = f( \\mathtt X_i)$ pour une fonction $f$ croissante.\n", "* $\\mathtt{spear (X,Y)} = -1$ ssi $\\forall i: \\mathtt Y_i = f( \\mathtt X_i)$ pour une fonction $f$ d\u00e9croissante.\n", "\n", "\n", "Comment est-ce possible? Tr\u00e8s simplement: Spearman c'est Pearson que l'on calcule \u00e0 partir du rang des observations (= leur ordre quand on les classe par ordre croissant).  \n", "\n", "Observons ce calcul.  "], "metadata": {"id": "It8jKZxU3Se3"}, "outputs": []}, {"cell_type": "code", "source": ["size=30"], "metadata": {"id": "M5dPBDA-gTfr", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.043595Z", "start_time": "2024-10-25T08:26:08.942774Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["X=np.random.uniform(0,10,size=100)\n", "Y=np.random.normal(loc=np.exp(X),scale=X)"], "metadata": {"id": "RsX5G1lCdc34", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.054400Z", "start_time": "2024-10-25T08:26:08.945439Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plt.plot(X,Y,\".\");"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "41jg2udagehN", "executionInfo": {"status": "ok", "timestamp": 1731403932974, "user_tz": -60, "elapsed": 498, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0f228be6-1955-4e88-c573-2d0a05209e17", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.087621Z", "start_time": "2024-10-25T08:26:08.948590Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Calculons Pearson:"], "metadata": {"id": "-XMcVhgEme-w"}, "outputs": []}, {"cell_type": "code", "source": ["#m\u00e9thode 1\n", "XY=np.stack([X,Y],axis=0)\n", "print(np.corrcoef(XY)[0,1])"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "R9_evtRNin70", "executionInfo": {"status": "ok", "timestamp": 1731403932974, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "84c12beb-49db-4efe-c112-601e4ac002ce", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.088944Z", "start_time": "2024-10-25T08:26:09.006317Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#m\u00e9thode 2:\n", "scipy.stats.pearsonr(X, Y)[0]"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "WumiDsxaj9c0", "executionInfo": {"status": "ok", "timestamp": 1731403932974, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6e7036c0-7912-4723-9598-ad7d714859e2", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.090173Z", "start_time": "2024-10-25T08:26:09.009228Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On voit que ces deux variables sont extr\u00eamement corr\u00e9l\u00e9es au sens fran\u00e7ais du terme. Le coefficient de Pearson est assez grand (70% environ) mais au vu de la d\u00e9pendance observ\u00e9e, on aimerait un coefficient encore plus proche de sa valeur maximale: 1. \u00c7a sera le cas du coefficient de corr\u00e9lation de Spearman."], "metadata": {"id": "fmG-wx2lmBfc"}, "outputs": []}, {"cell_type": "markdown", "source": ["Observons les rangs des observations"], "metadata": {"id": "nuntkxZ6hxEr"}, "outputs": []}, {"cell_type": "code", "metadata": {"id": "jYeIFZEynvXa", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.091295Z", "start_time": "2024-10-25T08:26:09.011847Z"}}, "source": ["# rank of x's\n", "X_ranks = scipy.stats.rankdata(X)\n", "# rank of y's\n", "Y_ranks = scipy.stats.rankdata(Y)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["La fonction `np.argsort` renvoie aussi les rangs; mais c'est bien `scipy.stats.rankdata` qu'il faut utiliser pour Spearman."], "metadata": {"id": "6cFpnHlfZGDt"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "rSkcD2BlqJZ_"}, "source": ["#### \u2661\u2661\u2661\u2661\n", "\n", "*** \u00c0 vous:***   Faites des petits tests pour expliquer quelle sont les 2 diff\u00e9rences entre `np.argsort` et `scipy.stats.rankdata`. Aide: regarder notamment quand il y a des \u00e9galit\u00e9s."], "outputs": []}, {"cell_type": "code", "source": ["plt.plot(X_ranks,Y_ranks,\".\");"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "WiV6YH2PiJ8H", "executionInfo": {"status": "ok", "timestamp": 1731403933463, "user_tz": -60, "elapsed": 492, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bb870913-fb0c-4dd1-a804-e7e0e65842e0", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.174344Z", "start_time": "2024-10-25T08:26:09.013673Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On voit qu'ils sont tr\u00e8s corr\u00e9l\u00e9s lin\u00e9airement. Le coef de Pearson des rangs (=le coef de Spearman) va renvoyer un nombre tr\u00e8s proche de 1.\n"], "metadata": {"id": "cXwNROB4h82H"}, "outputs": []}, {"cell_type": "code", "source": ["def compute_spearman(X,Y):\n", "    X_ranks = scipy.stats.rankdata(X)\n", "    Y_ranks = scipy.stats.rankdata(Y)\n", "    XY_ranks=np.stack([X_ranks,Y_ranks],axis=0)\n", "    return np.corrcoef(XY_ranks)[0,1]"], "metadata": {"id": "zxbv70mKgi8A", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.189613Z", "start_time": "2024-10-25T08:26:09.069941Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["my_speareman=compute_spearman(X,Y)\n", "my_speareman"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UZnGBCysg6Kc", "executionInfo": {"status": "ok", "timestamp": 1731403933463, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4ae27374-90ca-4b88-e95b-3453130dedd5", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.190854Z", "start_time": "2024-10-25T08:26:09.071581Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#comparons avec ce que renvoie scipy directement:\n", "scipy.stats.spearmanr(X, Y)[0]"], "metadata": {"id": "Msb7GsjZhMAF", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1731403933464, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "18a1e55e-1b33-4518-8cda-e3704cec9d3c", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.215142Z", "start_time": "2024-10-25T08:26:09.183695Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Si on remplace `[0]` par `[1]` dans le code ci-dessus, on trouve la p-value du test de Student sur la nullit\u00e9 du coefficient de Spearman."], "metadata": {"id": "SQmoguQp3mmB"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Droite de r\u00e9gression et ACP.\n"], "metadata": {"id": "u_pxyYL5Peke"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Droite affine de r\u00e9gression"], "metadata": {"id": "LlMU_yQk69yl"}, "outputs": []}, {"cell_type": "markdown", "source": ["On cherche la droite affine qui approxime au mieux nos donn\u00e9es, on cherche donc:\n", "$$\n", " \\hat a,\\hat b= \\text{argmin}_{a,b}\\   \\sum_i (\\mathtt Y_i - a \\mathtt X_i -b)^2\n", "$$\n", "\n", "> ***Proposition:*** On a:\n", "> \\begin{align}\n", "\\hat a&=\\mathtt{ {cov(X,Y)\\over var (X)} }\\\\\n", "\\hat b&= \\mathtt{mean}(\\mathtt Y) + \\hat a \\, \\mathtt{mean}(\\mathtt X)\n", "\\end{align}\n"], "metadata": {"collapsed": false, "id": "a2Ry7aTK8c4K"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "*D\u00e9monstration:* Il est tr\u00e8s clair que si l'on translate les donn\u00e9es alors, on translate la droite de r\u00e9gression (c'est simplement un changement d'origine). En particulier: notons\n", "$$\n", "loss(\\mathtt  X,\\mathtt Y) = \\sum_i (\\mathtt Y_i - a \\mathtt X_i -b)^2\n", "$$\n", "la fonction objective. Si $\\hat a,\\hat b$ sont les minimiseurs cette loss, alors, pour une constante $k$, les minimiseurs de $loss(\\mathtt  X - k,\\mathtt Y)$ sont $\\hat a,\\hat b - \\hat a k$ (ce sont les param\u00e8tres de la droite quand on fait une translation de l'origine).\n", "\n", "En notant $k=\\text{mean}(\\mathtt{X})$, et en soustrayant cette quantit\u00e9 \u00e0 $\\mathtt{X}$, on peut supposer que $\\sum_i \\mathtt{X}_i=0$ ce qui va grandement simplifier les calculs."], "metadata": {"collapsed": false, "id": "Kjo9WAjn8c4K"}, "outputs": []}, {"cell_type": "markdown", "source": ["Notons $n$ la taille de nos data. Notons $\\mathbf X$ la matrice dont la premi\u00e8re colonne est compos\u00e9e de 1, et la seconde contient les $\\mathtt{X}_i$. Notons $\\mathbf Y$ la matrice colonne qui contient les  $\\mathtt{Y}_i$. \"L'\u00e9quation normale\" donne:\n", "$$\n", " \\begin{pmatrix}\n", " \\hat b \\\\\n", " \\hat a\n", " \\end{pmatrix}\n", "=(\\mathbf X^T  \\mathbf X)^{-1}\\mathbf X^T\\mathbf Y\n", "$$\n", "La matrice $\\mathbf X^T  \\mathbf X$ est donn\u00e9e par\n", "$$\n", "\\begin{pmatrix}\n", "n &\\sum_i \\mathtt{X}_i\\\\\n", "\\sum_i \\mathtt{X}_i&\\sum_i \\mathtt{X}^2_i\n", "\\end{pmatrix}\n", "=\n", "\\begin{pmatrix}\n", "n &0\\\\\n", "0&\\sum_i \\mathtt{X}^2_i\n", "\\end{pmatrix}\n", "$$\n", "Dont l'inverse est facile \u00e0 calculer. Et on trouve\n", "$$\n", "\\begin{pmatrix}\n", " \\hat b \\\\\n", " \\hat a\n", " \\end{pmatrix}\n", " =\n", "\\begin{pmatrix}\n", "\\frac 1n \\sum_i \\mathtt{Y}_i \\\\\n", "{\\sum_i \\mathtt{X}_i\\mathtt{Y}_i  \\over \\sum_i \\mathtt{X}^2_i}\n", "\\end{pmatrix}\n", "=\n", "\\begin{pmatrix}\n", "\\mathtt{mean} (\\mathtt Y) \\\\\n", "{ \\mathtt{cov(X) } \\over  \\mathtt{var(X)}}\n", "\\end{pmatrix}.\n", "$$\n", "Nous avons fini la preuve dans le cas o\u00f9 $\\sum_i \\mathtt{X}_i=0$. Le cas g\u00e9n\u00e9ral d\u00e9coule de la discussion en d\u00e9but de preuve. $\\square$"], "metadata": {"id": "2TkWJAqx6pfR"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Droite vectorielle de r\u00e9gression\n", "\n", "Tr\u00e8s souvent, on a envie d'expliquer l'effet de $X$ sur $Y$ de la mani\u00e8re la plus simple possible: par exemple pour des appartements, on parle de \"prix au m\u00e8tre carr\u00e9\" ($X$=surface, $Y$=prix). On cherche donc le coefficient:\n", "$$\n", " \\hat c = \\text{argmin}_{c}\\  \\sum_i (\\mathtt Y_i - c \\mathtt X_i)^2\n", "$$\n", "\n", "> ***Proposition:*** On a:\n", "> \\begin{align}\n", "\\hat c&=\\mathtt{ {\\sum_i \\mathtt X_i \\mathtt Y_i \\over \\sum_i \\mathtt X^2_i } }\n", "\\end{align}\n", "\n", "Remarque: Quand les donn\u00e9es sont centr\u00e9e, on a $\\hat b=0$ et $\\hat a=\\hat c$: les droites de regression affine et  vectorielle co\u00efncident."], "metadata": {"collapsed": false, "id": "vpfxPrKQ8c4K"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### $\\heartsuit\\heartsuit\\heartsuit$\n", "\n", "D\u00e9montrez cette proposition en utilisant l'\u00e9quation normale. Mais cette fois-ci, la matrice $\\mathbf X^T  \\mathbf X$ est de taille 1*1. Tr\u00e8s simple!"], "metadata": {"collapsed": false, "id": "-mn9BxKq8c4L"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Droites de r\u00e9gression: le programme\n", "\n"], "metadata": {"id": "0Mus2jtG7Acu"}, "outputs": []}, {"cell_type": "code", "source": ["def plot_regression_lines(X,Y):\n", "    fig,ax=plt.subplots()\n", "    ax.scatter(X,Y,s=3,label=\"point\")\n", "\n", "    a=cov(X,Y) / np.std(X)**2\n", "    b=np.mean(Y)  - a*np.mean(X)\n", "    c=sum(X*Y)/sum(X**2)\n", "\n", "    left,right=min(X),max(X)\n", "    xx=np.linspace(left,right,2)\n", "    ax.plot(xx,a*xx+b,\"r\",label=\"regression affine\")\n", "    ax.plot(xx,c*xx,\"b\",label=\"regression vectorielle\")\n", "    ax.legend()"], "metadata": {"id": "zJt-CrAL7I6S", "ExecuteTime": {"end_time": "2024-10-25T08:26:09.269018Z", "start_time": "2024-10-25T08:26:09.215345Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["X,Y=simulate_concrete_2(500)\n", "plot_regression_lines(X,Y)"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:09.354985Z", "start_time": "2024-10-25T08:26:09.261780Z"}, "id": "Zh3wIyQC8c4L", "outputId": "174f4ef2-f0ff-4fe2-ffbf-da07eec2178e", "colab": {"base_uri": "https://localhost:8080/", "height": 430}, "executionInfo": {"status": "ok", "timestamp": 1731403934032, "user_tz": -60, "elapsed": 570, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["Les deux droites ont l'air tr\u00e8s proches. Mais modifions un peu les donn\u00e9es:"], "metadata": {"collapsed": false, "id": "XA8UC1sY8c4L"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["X,Y=simulate_concrete_2(500)\n", "X=X-1\n", "Y=Y+2\n", "plot_regression_lines(X,Y)"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T08:26:09.427692Z", "start_time": "2024-10-25T08:26:09.343381Z"}, "id": "aiFg6Mhg8c4L", "outputId": "2c7742ef-ad1e-4e12-9c8d-e00ef6648075", "colab": {"base_uri": "https://localhost:8080/", "height": 430}, "executionInfo": {"status": "ok", "timestamp": 1731403934679, "user_tz": -60, "elapsed": 648, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["Pour ces data, la droite vectorielle semble \u00eatre dans les choux."], "metadata": {"collapsed": false, "id": "mRI-Ehe28c4L"}, "outputs": []}, {"cell_type": "markdown", "source": ["### La droite d'ACP"], "metadata": {"id": "A-tRagNl8maC"}, "outputs": []}, {"cell_type": "markdown", "source": ["Voici toute ce qu'il faut savoir sur l'ACP (Analyse en composante principale) pour un ensemble de points $\\mathtt Z$. On utilisera ce r\u00e9sultat en 2D pour nos point $\\mathtt{Z=(X,Y)}$, mais ce qui suit est vrai en toute dimension.\n", "\n", "* La matrice de covariance $\\mathtt{cov(Z)}$ est sym\u00e9trique d\u00e9finie positive, donc diagonalisable dans une base orthonormale.\n", "* Ses valeurs propres sont positives. On les ordonne les valeurs propres par ordre d\u00e9croissant: $\\lambda_0$ est la plus grande. Notons $U_0$ le vecteur propre correspondant.\n", "* La droite passant par le barycentre de $\\mathtt Z$  et engendr\u00e9e par $U_0$ donne la \"direction principale\" du nuage de point: parmi toutes les droites, c'est la droite qui minimise la distance avec les points.\n", "* Cons\u00e9quence logique: Quand on projette les points sur cette droite, on obtient la projection qui a la plus grande variance (compar\u00e9e aux autres projections possibles sur des droites).\n", "* La variance des points projet\u00e9s, c'est $\\lambda_0$.  \n", "\n", "Techniquement, la proc\u00e9dure `svd` permet de faire la diagonalisation avec la matrice de passage bien ordonn\u00e9e."], "metadata": {"id": "HUfbt-y98quG"}, "outputs": []}, {"cell_type": "code", "source": ["X,Y=simulate_concrete_1(5000)\n", "cov_mat=np.cov(np.stack([X,Y],axis=0),ddof=1)\n", "cov_mat"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "VzjB2Eiq8rZY", "executionInfo": {"status": "ok", "timestamp": 1731403934679, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9f446d9d-28e2-47c0-df72-68a029dd27cf", "ExecuteTime": {"end_time": "2024-10-25T09:00:20.434341Z", "start_time": "2024-10-25T09:00:20.393742Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def compute_m_with_svd(X,Y):\n", "    cov_mat=np.cov(np.stack([X,Y],axis=0),ddof=1)\n", "\n", "    #Le vecteur S contient les valeurs propres ordonn\u00e9es de la plus grande \u00e0 la plus petite.\n", "    #U est la matrice de passage. Les colonnes de U sont ordonn\u00e9es pour que la premi\u00e8re colonne corresponde \u00e0 la plus grande valeur propre.\n", "    U,S,_=np.linalg.svd(cov_mat)\n", "    U0=U[:,0]\n", "    m=U0[1]/U0[0]\n", "    return m"], "metadata": {"id": "taIzd4lh82eC", "ExecuteTime": {"end_time": "2024-10-25T09:00:21.333254Z", "start_time": "2024-10-25T09:00:21.324838Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["compute_m_with_svd(X,Y)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "khh05zgk4dYn", "executionInfo": {"status": "ok", "timestamp": 1731403934679, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "943b480a-d7f0-45d7-c04a-81d5a5599067"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["def plot_both_line(X,Y):\n", "    mean_X=np.mean(X)\n", "    mean_Y=np.mean(Y)\n", "\n", "    a=cov(X,Y) / np.std(X)**2\n", "    b=np.mean(Y)  - a*np.mean(X)\n", "\n", "    m=compute_m_with_svd(X,Y)\n", "\n", "    fig,ax=plt.subplots()\n", "    ax.scatter(X,Y,s=3,label=\"point\")\n", "    left,right=min(X),max(X)\n", "    xx=np.linspace(left,right,100)\n", "\n", "    ax.plot(xx,a*xx+b,\"r\",label=\"regression line\")\n", "    ax.plot(xx,m*(xx-mean_X)+mean_Y,\"g\",label=\"ACP line\")\n", "\n", "    ax.scatter(mean_X,mean_Y,s=20,c=\"k\",label=\"mean\")\n", "    #ax.scatter(0,0,label=\"origin\")\n", "    ax.legend()"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T09:02:44.248320Z", "start_time": "2024-10-25T09:02:44.169884Z"}, "id": "B0y7LtMD8c4L"}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["X,Y=simulate_concrete_1(500)\n", "X+=2\n", "Y-=-3\n", "plot_both_line(X,Y)"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T09:02:45.662916Z", "start_time": "2024-10-25T09:02:45.578344Z"}, "id": "0X2z6-7f8c4L", "outputId": "56027001-1ead-4646-d712-fb53189d0020", "colab": {"base_uri": "https://localhost:8080/", "height": 430}, "executionInfo": {"status": "ok", "timestamp": 1731403935361, "user_tz": -60, "elapsed": 686, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "code", "outputs": [], "source": ["X,Y=simulate_concrete_2(500)\n", "X+=4\n", "Y-=6\n", "plot_both_line(X,Y)"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T09:02:48.874590Z", "start_time": "2024-10-25T09:02:48.783051Z"}, "id": "M3UvIbr98c4L", "outputId": "ba286a9b-b65b-4e4f-f7e5-0342c3f6289e", "colab": {"base_uri": "https://localhost:8080/", "height": 430}, "executionInfo": {"status": "ok", "timestamp": 1731403936070, "user_tz": -60, "elapsed": 710, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["### Quelle droite choisir ?\n", "\n", "La droite d'ACP (verte) est \"au plus proche\" des points: Si vous projetez tous les points orthogonalement sur la droite ACP, vous obtenez une distance bien plus petite que si vous faites cette m\u00eame op\u00e9ration avec la droite de regression (rouge).\n", "\n", "\n", "Par contre la droite de regression permet d'approcher une relation de causalit\u00e9 bruit\u00e9 $Y=f(X)+bruit$. Dans le dernier exemple trac\u00e9, on aurait plut\u00f4t envi d'utiliser la droite de regression: graphiquement on imagine une relation $Y=f(X)+bruit$ avec le bruit qui augmente quand $x$ grandit.\n"], "metadata": {"id": "QmDygu5cVc-D"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Exemple de mauvaise interpr\u00e9tation"], "metadata": {"id": "MC19Esdiagwm"}, "outputs": []}, {"cell_type": "code", "source": ["loi=scipy.stats.multivariate_normal([0., 0.], [[2.0, 0.3], [0.3, 1.5]])"], "metadata": {"id": "dCWPsupGaj4-", "ExecuteTime": {"end_time": "2024-10-25T09:02:52.280858Z", "start_time": "2024-10-25T09:02:52.253571Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["Z=abs(loi.rvs(size=1000)+3)\n", "Z.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "RbCfuX4fcpvZ", "executionInfo": {"status": "ok", "timestamp": 1731403936070, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0b82c395-5762-422d-839a-5ecb751b786a", "ExecuteTime": {"end_time": "2024-10-25T09:02:53.017458Z", "start_time": "2024-10-25T09:02:52.977864Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["`Z` est une matrice contenant des scores repr\u00e9sentant le niveau math\u00e9matique d'une personne.\n", "\n", "Chaque ligne de `Z` correspond \u00e0 un couple. La premi\u00e8re colonne repr\u00e9sente le score de l'homme, la seconde le score de la femme."], "metadata": {"id": "1Ro_oJJEhjHB"}, "outputs": []}, {"cell_type": "markdown", "source": ["on va mettre les hommes en abscisse et les femmes en ordonn\u00e9es."], "metadata": {"id": "r4TUlfYZiUqP"}, "outputs": []}, {"cell_type": "code", "source": ["plot_simu(Z[:,0],Z[:,1])"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 469}, "id": "MqviWlO7fKTK", "executionInfo": {"status": "ok", "timestamp": 1731403936647, "user_tz": -60, "elapsed": 579, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ab45ae11-323e-40bc-ae99-68759afb9cff", "ExecuteTime": {"end_time": "2024-10-25T09:02:54.832725Z", "start_time": "2024-10-25T09:02:54.731777Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Notons $\\Delta$ la droite $y=x$ (=la premi\u00e8re bissectrice).\n", "\n", "* Les points sur $\\Delta$ correspondent aux couples o\u00f9 les deux conjoints ont le m\u00eame niveau en math.\n", "* Les points au-dessus de $\\Delta$ correspondent au couple o\u00f9 la femme est la plus forte.\n", "* Les points en-dessous de $\\Delta$ correspondent au couple o\u00f9 l'homme est le plus fort.\n", "\n", "Il semble donc pertinent le tracer la droite de regression vectorielle de nos points, puis de la comparer avec $\\Delta$."], "metadata": {"id": "xaRHZCaJiacO"}, "outputs": []}, {"cell_type": "code", "source": ["def plot_delta_and_regression(X,Y,xlabel,ylabel):\n", "    fig,ax=plt.subplots()\n", "    ax.scatter(X,Y,s=3)\n", "    c=np.sum(X*Y)/np.sum(X**2)\n", "    xx=np.linspace(min(X),max(X),10)\n", "    ax.plot(xx,c*xx,\"r\",label=\"regression vectorielle\")\n", "    ax.plot(xx,xx,\"k:\",label=\"delta\")\n", "    ax.set_xlabel(xlabel)\n", "    ax.set_ylabel(ylabel)\n", "    ax.legend()\n", "    ax.set_aspect(\"equal\")\n", "plot_delta_and_regression(Z[:,0],Z[:,1],\"homme\",\"femme\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 449}, "id": "li_PhxazffmL", "executionInfo": {"status": "ok", "timestamp": 1731403937316, "user_tz": -60, "elapsed": 671, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9be55063-e955-4f71-d171-b52ae891a69c", "ExecuteTime": {"end_time": "2024-10-25T09:02:56.670517Z", "start_time": "2024-10-25T09:02:56.578973Z"}}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Le graphique parle de lui-m\u00eame: la droite rouge est sous $\\Delta$, donc les hommes sont en majorit\u00e9 plus fort que les femmes en math."], "metadata": {"id": "WTlc1jHHihJd"}, "outputs": []}, {"cell_type": "markdown", "source": ["Mais que ce passe-t-il si on met les femmes en abscisse et les hommes en ordonn\u00e9e:"], "metadata": {"id": "ES-NvOpAivaS"}, "outputs": []}, {"cell_type": "code", "outputs": [], "source": ["plot_delta_and_regression(Z[:,1],Z[:,0],\"femme\",\"homme\")"], "metadata": {"ExecuteTime": {"end_time": "2024-10-25T09:02:59.325735Z", "start_time": "2024-10-25T09:02:59.236347Z"}, "id": "dLFGH5kf8c4M", "outputId": "9fb9984c-b227-4dc7-fc10-f17abf74d569", "colab": {"base_uri": "https://localhost:8080/", "height": 449}, "executionInfo": {"status": "ok", "timestamp": 1731403938822, "user_tz": -60, "elapsed": 1507, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": null}, {"cell_type": "markdown", "source": ["Mince, finalement, ce sont les femmes les plus fortes!"], "metadata": {"id": "Jj-rY9vSjH6M"}, "outputs": []}, {"cell_type": "markdown", "source": ["Cet apparent paradoxe vient du fait que la droite de regression minimise les projections verticales. Et ce n'est pas du tout sym\u00e9trique si on \u00e9change $X$ et $Y$. Par contre, la droite d'ACP n'a pas ce probl\u00e8me:"], "metadata": {"id": "E0Se4sOMjcNG"}, "outputs": []}, {"cell_type": "markdown", "source": ["### La bonne droite\n", "\n", "On force la droite d'ACP \u00e0 passer par z\u00e9ro avec une astuce que vous pouvez lire dans le code ci-dessous."], "metadata": {"id": "86W78KFFVFE-"}, "outputs": []}, {"cell_type": "code", "source": ["def plot_delta_and_acp_from_0(X,Y,xlabel,ylabel):\n", "    fig,ax=plt.subplots()\n", "    XX=np.append(X,-X)\n", "    YY=np.append(Y,-Y)\n", "    mm=compute_m_with_svd(XX,YY)\n", "\n", "\n", "    ax.scatter(X,Y,s=3)\n", "\n", "\n", "    xx=np.linspace(min(X),max(X),10)\n", "    ax.plot(xx,mm*xx,\"r\",label=\"regression vectorielle\")\n", "    ax.plot(xx,xx,\"k:\",label=\"delta\")\n", "    ax.set_xlabel(xlabel)\n", "    ax.set_ylabel(ylabel)\n", "    ax.legend()\n", "    ax.set_aspect(\"equal\")\n", "\n", "plot_delta_and_acp_from_0(Z[:,0],Z[:,1],\"homme\",\"femme\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 449}, "id": "v2qcIEEDVlPz", "executionInfo": {"status": "ok", "timestamp": 1731403938822, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "fb5321ee-8120-4a69-b1df-827bfc382f80"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plot_delta_and_acp_from_0(Z[:,1],Z[:,0],\"femme\",\"homme\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 449}, "id": "3_7Y4NnhV2iE", "executionInfo": {"status": "ok", "timestamp": 1731403939655, "user_tz": -60, "elapsed": 835, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "61edf6b5-9a82-4082-b987-1fa7d3ae7352"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["La droite rouge est proche de $\\Delta$. Pas de diff\u00e9rence notable.\n", "\n", "Notons aussi qu'il est dangereux de r\u00e9sumer \u00e0 une droite une discribution de point qui ne ressemble pas \u00e0 une droite."], "metadata": {"id": "_LJWB91Btx8m"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Des p'tits calculs sympas"], "metadata": {"id": "L-7n9ilz58J6"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Deux variables binaires\n"], "metadata": {"id": "7QRsDksr6EEH"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "Supposons que $X$ et $Y$ prennent leurs valeurs dans $\\{0,1\\}$, ainsi $X=1_{X=1}$ et donc\n", "$$\n", "\\mathbf E[X] = \\mathbf P[X=1]:=p_X\n", "$$\n", "$$\n", "var(X)= p_X(1-p_X)\n", "$$\n", "Idem pour $Y$.\n", "\n", "\n", "Pour comprendre l'influence de $X$ sur $Y$ il est naturel de comparer $\\mathbf P[Y=1/X=1]$ avec $\\mathbf P[Y=1]$. Il est donc naturel de calculer le ratio:\n", "$$\n", "{\\mathbf P[Y=1/X=1]\\over \\mathbf P[Y=1]}\n", "$$\n", "\n", "> ***Proposition***\n", "$$\n", " {\\mathbf P[Y=1/X=1]\\over \\mathbf P[Y=1]}\n", "={cov(X,Y) \\over p_Xp_Y} +1\n", "=cor(X,Y){ \\sqrt{(1-p_X)(1-p_Y)}\\over \\sqrt{p_Xp_Y}} +1\n", "$$\n", "\n", "\n", "La formule est naturelle.\n", "\n", "\n"], "metadata": {"id": "jtPiYQG98xUM"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661"], "metadata": {"id": "1eXQ4lUC2Syj"}, "outputs": []}, {"cell_type": "markdown", "source": ["D\u00e9monstration:\n", "\n", "C'est \u00e0 vous de la faire\n"], "metadata": {"id": "-kjjcnku2Ps_"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Retours math\u00e9matiques sur les pieds et les notes\n", "\n", "\n", "\n", "\n"], "metadata": {"id": "p1RrTXy-6HDl"}, "outputs": []}, {"cell_type": "markdown", "source": ["On mod\u00e9lise l'\u00e2ge des enfant du primaire par une v.a $A$ \u00e0 valeur dans $6,7,8,9,10,11$.\n", "\n", "\n", "On mod\u00e8lise la note en math par\n", "$$\n", "X = f(A) + \\epsilon\n", "$$\n", "o\u00f9 $f$ et une fonction croissante et $\\epsilon$ un bruit centr\u00e9.\n", "\n", "\n", "On mod\u00e8lise la taille du pied par\n", "$$\n", "Y = g(A) + \\epsilon'\n", "$$\n", "o\u00f9 $g$ et une fonction croissante et $\\epsilon'$ un bruit centr\u00e9.\n", "\n", "\n", "On a bien un lien de causalit\u00e9 (bruit\u00e9) de $A$ vers $X$ et de $A$ vers $Y$. Mais pas de $Y$ vers $X$ comme la phrase du directeur laiss\u00e9e entendre. Mais on a bien une corr\u00e9lation, et m\u00eame:\n", "\n", "\n", "\n"], "metadata": {"id": "yIEPWud46SxK"}, "outputs": []}, {"cell_type": "markdown", "source": ["***Proposition:*** La note $X$ et la taille du pied $Y$ sont corr\u00e9l\u00e9s positivement.\n", "\n", "\n", "*D\u00e9monstration:* On va simplement montrer que la covariance et positive. Les bruits \u00e9tant centr\u00e9s et ind\u00e9pendants de toute le monde on v\u00e9rifie facilement que\n", "$$\n", "cov(X,Y) = cov(f(A),g(A))\n", "$$\n", "Consid\u00e9rons $A'$ une copie ind\u00e9pendante de $A$. Consid\u00e9rons la quantit\u00e9\n", "$$\n", "e=\\mathbf E[(f(A)-f(A'))(g(A)-g(A'))]\n", "$$\n", "\n", "* D'une part nous avons que $e\\geq 0$. En effet, il suffit de s\u00e9parer cette esp\u00e9rence en deux bouts:\n", "$$\n", "e=\\mathbf E[1_{A>A'} ... ] + \\mathbf E[1_{A\\leq A'} ... ]\n", "$$\n", "en utlisant la croissante de $f$ et $g$, les deux bouts sont positifs.\n", "\n", "\n", "* D'autres part, en d\u00e9veloppant le produit, on voit que $e = 2 cov(f(A),g(A)) $\n", "\n"], "metadata": {"id": "-FK5YI2o7pZ8"}, "outputs": []}, {"cell_type": "markdown", "source": ["#### \u2661\u2661\u2661\n", "\n", "***A vous:*** Rajouter des d\u00e9tails dans cette preuve pour bien la comprendre, notamment, faite le d\u00e9veloppement de $e$ pour le second points."], "metadata": {"id": "sCnKtbj0EfOL"}, "outputs": []}]}