{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89862c83",
   "metadata": {},
   "source": [
    "\n",
    "# M2 ROM — Tiny RBM Lab (1D Reaction–Diffusion)\n",
    "\n",
    "**Goal**: get a hands-on feel for Reduced Basis Methods (RBM) on a tiny 1D problem with an affine parameter dependence.\n",
    "You will:\n",
    "\n",
    "generate snapshots and build a POD basis (Exercise 1),\n",
    "implement a residual-based a posteriori error estimator (Exercise 2),\n",
    "implement a greedy basis selection (Exercise 3).\n",
    "**Model problem (finite-difference)**: find $u(x;\\mu)$ on $x\\in(0,1)$ s.t.\n",
    "$$\n",
    "-\\mu,u''(x) + u(x) = 1,\\quad u(0)=u(1)=0,\\quad \\mu\\in[0.1,10].\n",
    "$$\n",
    "\n",
    "Discretization with $N$ interior points gives the linear system\n",
    "$$\n",
    "(\\mu K + I),\\mathbf{u} = \\mathbf{f},\n",
    "$$\n",
    "where $K$ is the 1D Laplacian (Dirichlet) stiffness matrix and $I$ is the identity.\n",
    "This affine form $A(\\mu)=\\mu K + I$ enables a clean offline/online split.\n",
    "\n",
    "Residual-based estimator (Euclidean norm):\n",
    "Let $\\mathbf{r}(\\mu) = \\mathbf{f} - A(\\mu)\\mathbf{u}N(\\mu)$. For SPD problems,\n",
    "$$\n",
    "|\\mathbf{u}(\\mu)-\\mathbf{u}N(\\mu)|2 \\le \\frac{|\\mathbf{r}(\\mu)|2}{\\alpha_{LB}(\\mu)}.\n",
    "$$\n",
    "For our choice $A(\\mu)=\\mu K + I$, a valid coercivity lower bound is\n",
    "$$\n",
    "\\alpha_{LB}(\\mu) = \\mu,\\lambda{\\min}(K) + 1,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\lambda{\\min}(K) = \\frac{4}{h^2}\\sin^2!\\Big(\\frac{\\pi}{2(N+1)}\\Big),\\qquad h=\\frac{1}{N+1}.\n",
    "$$\n",
    "\n",
    "**What you'll see**: Error vs. basis size for POD and for Greedy; effectivity ($\\Delta/|e|$) of the estimator; and a simple offline/online timing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdbde4",
   "metadata": {},
   "source": [
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7527f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem size: N=32\n",
      "Training parameters: 20\n",
      "Test parameters: 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Problem size and parameter range\n",
    "N = 32                    # interior points\n",
    "MU_TRAIN = np.logspace(np.log10(0.1), np.log10(10), 20)   # 20 training params\n",
    "MU_TEST  = np.logspace(np.log10(0.1), np.log10(10), 50)   # 50 test params\n",
    "\n",
    "print(f\"Problem size: N={N}\")\n",
    "print(f\"Training parameters: {len(MU_TRAIN)}\")\n",
    "print(f\"Test parameters: {len(MU_TEST)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2df4d84",
   "metadata": {},
   "source": [
    "\n",
    "## Core Functions\n",
    "\n",
    "Here are the core functions you'll need for the exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58da4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def assemble_system(N):\n",
    "    \"\"\"\n",
    "    Build 1D matrices for -mu u'' + u = 1 with Dirichlet BCs on (0,1).\n",
    "    Returns:\n",
    "        K  : (N,N) Laplacian stiffness (finite-difference) with scaling 1/h^2\n",
    "        I  : (N,N) identity\n",
    "        f  : (N,)   RHS vector of ones\n",
    "        h  : grid spacing\n",
    "        lminK : smallest eigenvalue of K (analytical formula)\n",
    "    \"\"\"\n",
    "    h = 1.0/(N+1)\n",
    "    main = 2.0*np.ones(N)\n",
    "    off  = -1.0*np.ones(N-1)\n",
    "    K = (1.0/h**2)*(np.diag(main) + np.diag(off, 1) + np.diag(off, -1))\n",
    "    I = np.eye(N)\n",
    "    f = np.ones(N)\n",
    "\n",
    "    # Exact smallest eigenvalue of 1D Dirichlet Laplacian matrix\n",
    "    lminK = (4.0/(h**2))*(np.sin(np.pi/(2.0*(N+1)))**2)\n",
    "    return K, I, f, h, lminK\n",
    "\n",
    "\n",
    "def solve_full(mu, K, I, f):\n",
    "    \"\"\"Solve the full-order system (mu*K + I)*u = f.\"\"\"\n",
    "    A = mu*K + I\n",
    "    u = np.linalg.solve(A, f)\n",
    "    return u\n",
    "\n",
    "\n",
    "def rb_solve(mu, U, K, I, f):\n",
    "    \"\"\"\n",
    "    Reduced-basis solve: project onto span(U) and solve reduced system.\n",
    "    Returns u_rb (in full space) and coefficients a.\n",
    "    \"\"\"\n",
    "    # Reduced matrices/vectors\n",
    "    A_r = U.T @ (mu*K + I) @ U\n",
    "    f_r = U.T @ f\n",
    "    \n",
    "    # Solve reduced system\n",
    "    a = np.linalg.solve(A_r, f_r)\n",
    "    u_rb = U @ a\n",
    "    return u_rb, a\n",
    "\n",
    "\n",
    "def pod_basis(S, r):\n",
    "    \"\"\"\n",
    "    Extract POD basis of size r from snapshot matrix S.\n",
    "    Returns U (POD basis) and s (singular values).\n",
    "    \"\"\"\n",
    "    U_full, s, Vt = np.linalg.svd(S, full_matrices=False)\n",
    "    U = U_full[:, :r]\n",
    "    return U, s\n",
    "\n",
    "\n",
    "def project_error(u_full, u_rb):\n",
    "    \"\"\"\n",
    "    Compute projection error ||u_full - u_rb||_2 and relative error.\n",
    "    \"\"\"\n",
    "    err = np.linalg.norm(u_full - u_rb, 2)\n",
    "    rel = err / np.linalg.norm(u_full, 2)\n",
    "    return err, rel\n",
    "\n",
    "\n",
    "def alpha_LB(mu, lminK):\n",
    "    \"\"\"Coercivity lower bound for our problem A(mu) = mu*K + I.\"\"\"\n",
    "    return mu * lminK + 1.0\n",
    "\n",
    "\n",
    "def estimator(u_rb, mu, K, I, f, lminK):\n",
    "    \"\"\"\n",
    "    Residual-based a posteriori error estimator.\n",
    "    Returns ||r||_2 / alpha_LB(mu).\n",
    "    \"\"\"\n",
    "    r = f - (mu*K + I) @ u_rb\n",
    "    residual_norm = np.linalg.norm(r, 2)\n",
    "    alpha_lb = alpha_LB(mu, lminK)\n",
    "    return residual_norm / alpha_lb\n",
    "\n",
    "\n",
    "def orthonormalize(v, U=None, tol=1e-12):\n",
    "    \"\"\"\n",
    "    Gram-Schmidt orthonormalization of v against columns of U.\n",
    "    Returns orthonormalized vector or None if linearly dependent.\n",
    "    \"\"\"\n",
    "    w = v.copy()\n",
    "    if U is not None:\n",
    "        for j in range(U.shape[1]):\n",
    "            w -= (U[:, j].T @ w) * U[:, j]\n",
    "    nrm = np.linalg.norm(w, 2)\n",
    "    if nrm < tol:\n",
    "        return None  # dependent vector\n",
    "    return w / nrm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e880ceea",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1 — POD basis construction (10 min)\n",
    "\n",
    "Build a snapshot matrix and compute its POD (SVD). Plot the singular values and cumulative energy.\n",
    "\n",
    "**Tasks:**\n",
    "1. Build snapshot matrix `S` by computing full solutions for all training parameters\n",
    "2. Compute POD basis using SVD\n",
    "3. Plot singular values (semilogy) and cumulative energy\n",
    "4. Find how many modes capture 99% and 99.9% of energy\n",
    "\n",
    "> *Hint:* Use `solve_full`, `pod_basis`. Cumulative energy = `np.cumsum(s**2) / np.sum(s**2)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8423457e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exercise 1 Results ===\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Your turn (student cell) ===\n",
    "# Build snapshot matrix, compute POD, and analyze singular values\n",
    "\n",
    "# Set up problem matrices\n",
    "K, I, f, h, lminK = assemble_system(N)\n",
    "\n",
    "# TODO: Build snapshot matrix S\n",
    "# Hint: S should be (N, len(MU_TRAIN)) where each column is solve_full(mu, K, I, f)\n",
    "\n",
    "# TODO: Compute POD basis\n",
    "# Hint: U_full, s, Vt = np.linalg.svd(S, full_matrices=False)\n",
    "\n",
    "# TODO: Plot singular values and cumulative energy\n",
    "# Create subplots and plot:\n",
    "# 1) semilogy plot of singular values\n",
    "# 2) cumulative energy plot with 99% and 99.9% lines\n",
    "\n",
    "# TODO: Find modes for 99% and 99.9% energy\n",
    "# Hint: Use np.argmax(cumulative_energy >= 0.99) + 1\n",
    "\n",
    "print(\"=== Exercise 1 Results ===\")\n",
    "# Print your results here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569acfc",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 2 — Residual-based estimator & effectivity (10–15 min)\n",
    "\n",
    "Using the POD basis of size $r=10$:\n",
    "1. For each $\\mu\\in$ `MU_TEST`, compute the reduced solution and the **estimator**\n",
    "   $\\Delta(\\mu) = \\|\\mathbf{r}\\|_2/\\alpha_{LB}(\\mu)$.\n",
    "2. Compute the **true error** $ \\|e(\\mu)\\|_2 $ and the **effectivity** $ \\eta(\\mu) = \\Delta(\\mu)/\\|e(\\mu)\\|_2 $.\n",
    "3. Plot $\\eta(\\mu)$ versus $\\mu$. You should get $\\eta(\\mu)\\gtrsim 1$.\n",
    "\n",
    "> *Hint:* see `alpha_LB`, `estimator`, and `project_error`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bd6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Your turn (student cell) ===\n",
    "# Compute estimator effectivity for POD basis of size r=10\n",
    "\n",
    "# TODO: Build POD basis of size r=10\n",
    "r = 10\n",
    "# Hint: U_r, s = pod_basis(S, r)\n",
    "\n",
    "# TODO: Compute effectivity for each test parameter\n",
    "effectivities = []\n",
    "# Hint: For each mu in MU_TEST:\n",
    "#   1) Compute full solution: u_full = solve_full(mu, K, I, f)\n",
    "#   2) Compute reduced solution: u_rb, a = rb_solve(mu, U_r, K, I, f)\n",
    "#   3) Compute estimator: Delta = estimator(u_rb, mu, K, I, f, lminK)\n",
    "#   4) Compute true error: err, _ = project_error(u_full, u_rb)\n",
    "#   5) Compute effectivity: Delta/err\n",
    "\n",
    "# TODO: Plot effectivity vs mu\n",
    "# plt.figure()\n",
    "# plt.plot(MU_TEST, effectivities, marker='o')\n",
    "# plt.xlabel(\"mu\")\n",
    "# plt.ylabel(\"Effectivity (Delta / ||e||_2)\")\n",
    "# plt.title(\"Estimator effectivity vs mu (r=10)\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"=== Exercise 2 Results ===\")\n",
    "# Print statistics about effectivity (min, max, mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3408d9c",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 3 — Greedy basis construction (15–20 min)\n",
    "\n",
    "Implement a greedy that selects $\\mu_k$ by **maximizing** the estimator over the training set,\n",
    "and enriches the basis with the **full-order** solution at $\\mu_k$. Stop when the max estimator\n",
    "falls below a tolerance or when you reach a max size.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Initialize with one parameter (middle of training set)\n",
    "2. **Loop:** Compute estimator for all training parameters, select max\n",
    "3. **Enrich:** Add full solution at selected parameter to basis\n",
    "4. **Orthonormalize:** Use Gram-Schmidt\n",
    "5. **Check:** Stop if estimator < tol or max basis size reached\n",
    "\n",
    "> *Hint:* Use `estimator`, `solve_full`, `orthonormalize`, `rb_solve`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Your turn (student cell) ===\n",
    "# Implement greedy basis construction\n",
    "\n",
    "def greedy_algorithm(mu_train, K, I, f, lminK, tol=1e-6, max_basis=15, verbose=True):\n",
    "    \"\"\"\n",
    "    Greedy algorithm for basis construction.\n",
    "    \n",
    "    Returns:\n",
    "        U: basis matrix\n",
    "        selected_params: list of selected parameters\n",
    "        estimator_history: list of max estimators per iteration\n",
    "    \"\"\"\n",
    "    # TODO: Initialize with middle parameter\n",
    "    # Hint: mu0 = mu_train[len(mu_train)//2]\n",
    "    # Hint: u0 = solve_full(mu0, K, I, f)\n",
    "    # Hint: U = orthonormalize(u0, None)[:, None]\n",
    "    \n",
    "    selected_params = []  # TODO: Initialize with mu0\n",
    "    estimator_history = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[Greedy] Starting with mu={mu0:.3f}\")\n",
    "    \n",
    "    # TODO: Main greedy loop\n",
    "    for iteration in range(1, max_basis + 1):\n",
    "        # TODO: Compute estimator for all training parameters\n",
    "        estimators = []\n",
    "        # for mu in mu_train:\n",
    "        #     u_rb, _ = rb_solve(mu, U, K, I, f)\n",
    "        #     est = estimator(u_rb, mu, K, I, f, lminK)\n",
    "        #     estimators.append(est)\n",
    "        \n",
    "        # TODO: Find parameter with maximum estimator\n",
    "        # Hint: idx = np.argmax(estimators)\n",
    "        # Hint: mu_star = mu_train[idx]\n",
    "        # Hint: max_estimator = estimators[idx]\n",
    "        \n",
    "        estimator_history.append(max_estimator)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"[Greedy] Iteration {iteration}: max estimator = {max_estimator:.3e} at mu = {mu_star:.3f}\")\n",
    "        \n",
    "        # TODO: Check stopping criterion\n",
    "        # if max_estimator < tol:\n",
    "        #     break\n",
    "        \n",
    "        # TODO: Enrich basis with solution at mu_star\n",
    "        # Hint: u_star = solve_full(mu_star, K, I, f)\n",
    "        # Hint: v_new = orthonormalize(u_star, U)\n",
    "        # if v_new is None:  # linearly dependent\n",
    "        #     break\n",
    "        # Hint: U = np.column_stack([U, v_new])\n",
    "        \n",
    "        selected_params.append(mu_star)\n",
    "    \n",
    "    return U, np.array(selected_params), np.array(estimator_history)\n",
    "\n",
    "# TODO: Run the greedy algorithm\n",
    "# U_greedy, selected, history = greedy_algorithm(MU_TRAIN, K, I, f, lminK, tol=1e-6, max_basis=15)\n",
    "\n",
    "# TODO: Plot greedy convergence\n",
    "# plt.figure()\n",
    "# plt.semilogy(range(1, len(history)+1), history, 'o-')\n",
    "# plt.xlabel('Greedy iteration')\n",
    "# plt.ylabel('Maximum estimator')\n",
    "# plt.title('Greedy convergence')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"=== Exercise 3 Results ===\")\n",
    "# Print final basis size and selected parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea2db2",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 4 — POD vs Greedy comparison (10 min)\n",
    "\n",
    "Compare POD and Greedy methods by computing the mean relative error on the test set for different basis sizes.\n",
    "\n",
    "> *Hint:* For fair comparison, use same range of basis sizes (1 to min(POD_size, Greedy_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2485a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Your turn (student cell) ===\n",
    "# Compare POD vs Greedy methods\n",
    "\n",
    "# TODO: Test both methods for different basis sizes\n",
    "basis_sizes = range(1, min(U_greedy.shape[1], 15) + 1)\n",
    "pod_errors = []\n",
    "greedy_errors = []\n",
    "\n",
    "# for r in basis_sizes:\n",
    "    # TODO: Extract basis of size r for both methods\n",
    "    # U_pod_r = ...\n",
    "    # U_greedy_r = ...\n",
    "    \n",
    "    # TODO: Compute mean relative error on test set\n",
    "    # pod_test_errors = []\n",
    "    # greedy_test_errors = []\n",
    "    # for mu in MU_TEST:\n",
    "    #     # Compute errors for both methods\n",
    "    #     pass\n",
    "    \n",
    "    # pod_errors.append(np.mean(pod_test_errors))\n",
    "    # greedy_errors.append(np.mean(greedy_test_errors))\n",
    "\n",
    "# TODO: Plot comparison\n",
    "# plt.figure()\n",
    "# plt.semilogy(basis_sizes, pod_errors, 'b-o', label='POD')\n",
    "# plt.semilogy(basis_sizes, greedy_errors, 'r-s', label='Greedy')\n",
    "# plt.xlabel('Basis size')\n",
    "# plt.ylabel('Mean relative error')\n",
    "# plt.title('POD vs Greedy: Error vs basis size')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"=== Exercise 4 Results ===\")\n",
    "# Print comparison summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80863c",
   "metadata": {},
   "source": [
    "\n",
    "## Summary and Reflection\n",
    "\n",
    "**Key Takeaways:**\n",
    "1. **POD**: Optimal in terms of energy, but requires all snapshots upfront\n",
    "2. **Greedy**: Adaptive selection, can be more efficient for sparse parameter exploration\n",
    "3. **Estimators**: Provide computable error bounds for certification\n",
    "4. **Offline/Online**: ROM enables fast parameter sweeps after offline preprocessing\n",
    "\n",
    "**Questions to consider:**\n",
    "- Which method converges faster for your problem?\n",
    "- How tight are the error estimator bounds?\n",
    "- What happens with different parameter ranges or problem sizes?\n",
    "- How do computational costs compare?\n",
    "- Can we accelerate the offline/online procedure ?\n",
    "\n",
    "**Extensions you could try:**\n",
    "- Different parameter distributions (uniform vs logarithmic)\n",
    "- Multiple parameters (2D, 3D parameter spaces)\n",
    "- Different PDEs or boundary conditions\n",
    "- Advanced greedy variants (POD-Greedy, hp-adaptation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdeac5f",
   "metadata": {},
   "source": [
    "## Extended Problem with Oscillating Source Term\n",
    "\n",
    "Let's extend the PDE to include an oscillating source term:\n",
    "\n",
    "$$-\\mu u'' + u = 1 + \\nu \\sin(\\omega \\pi x)$$\n",
    "\n",
    "where:\n",
    "- $\\mu$ is the diffusion parameter (as before)\n",
    "- $\\nu$ is the amplitude of the oscillating source  \n",
    "- $\\omega$ is the frequency of the oscillation\n",
    "\n",
    "This creates a 2-parameter problem $(\\mu, \\nu)$ with the frequency $\\omega$ potentially being a third parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6c122b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extended multi-parameter functions defined!\n"
     ]
    }
   ],
   "source": [
    "def assemble_system_extended(N, omega=2.0):\n",
    "    \"\"\"\n",
    "    Build 1D matrices for -mu u'' + u = 1 + nu*sin(omega*pi*x) with Dirichlet BCs on (0,1).\n",
    "    \n",
    "    This uses affine decomposition:\n",
    "    (mu*K + I) u = f_base + nu*f_osc\n",
    "    \n",
    "    Parameters:\n",
    "        N: number of interior grid points\n",
    "        omega: frequency parameter for oscillating source\n",
    "    \n",
    "    Returns:\n",
    "        K  : (N,N) Laplacian stiffness matrix\n",
    "        I  : (N,N) identity matrix  \n",
    "        f_base : (N,) base RHS vector (constant source)\n",
    "        f_osc  : (N,) oscillating RHS vector (sin source)\n",
    "        h  : grid spacing\n",
    "        lminK : smallest eigenvalue of K\n",
    "    \"\"\"\n",
    "    h = 1.0/(N+1)\n",
    "    main = 2.0*np.ones(N)\n",
    "    off  = -1.0*np.ones(N-1)\n",
    "    K = (1.0/h**2)*(np.diag(main) + np.diag(off, 1) + np.diag(off, -1))\n",
    "    I = np.eye(N)\n",
    "    \n",
    "    # Base RHS (constant source)\n",
    "    f_base = np.ones(N)\n",
    "    \n",
    "    # Oscillating RHS: sin(omega*pi*x) at interior grid points\n",
    "    x_interior = np.linspace(h, 1-h, N)  # x_i = i*h for i=1,...,N\n",
    "    f_osc = np.sin(omega * np.pi * x_interior)\n",
    "    \n",
    "    # Exact smallest eigenvalue of 1D Dirichlet Laplacian matrix  \n",
    "    lminK = (4.0/(h**2))*(np.sin(np.pi/(2.0*(N+1)))**2)\n",
    "    \n",
    "    return K, I, f_base, f_osc, h, lminK\n",
    "\n",
    "\n",
    "def solve_full_extended(mu, nu, K, I, f_base, f_osc):\n",
    "    \"\"\"\n",
    "    Solve (mu*K + I) u = f_base + nu*f_osc.\n",
    "    \n",
    "    Parameters:\n",
    "        mu: diffusion parameter\n",
    "        nu: oscillating source amplitude\n",
    "        K, I: system matrices\n",
    "        f_base, f_osc: RHS vectors\n",
    "    \"\"\"\n",
    "    A = mu*K + I\n",
    "    f_total = f_base + nu*f_osc\n",
    "    return np.linalg.solve(A, f_total)\n",
    "\n",
    "\n",
    "def build_snapshots_extended(mu_vals, nu_vals, K, I, f_base, f_osc):\n",
    "    \"\"\"\n",
    "    Build snapshot matrix for 2-parameter problem.\n",
    "    Creates snapshots for all combinations of (mu, nu) values.\n",
    "    \n",
    "    Returns:\n",
    "        S: (N, num_snapshots) matrix where num_snapshots = len(mu_vals) * len(nu_vals)\n",
    "        param_combinations: list of (mu, nu) tuples corresponding to columns of S\n",
    "    \"\"\"\n",
    "    snapshots = []\n",
    "    param_combinations = []\n",
    "    \n",
    "    for mu in mu_vals:\n",
    "        for nu in nu_vals:\n",
    "            u = solve_full_extended(mu, nu, K, I, f_base, f_osc)\n",
    "            snapshots.append(u)\n",
    "            param_combinations.append((mu, nu))\n",
    "    \n",
    "    S = np.column_stack(snapshots)\n",
    "    return S, param_combinations\n",
    "\n",
    "\n",
    "def rb_solve_extended(mu, nu, U, K, I, f_base, f_osc):\n",
    "    \"\"\"\n",
    "    Reduced solve for extended problem: (mu*U^T K U + U^T I U) a = U^T (f_base + nu*f_osc)\n",
    "    \"\"\"\n",
    "    Kr = U.T @ K @ U\n",
    "    Mr = U.T @ I @ U  # should be close to identity if U orthonormal\n",
    "    fr_base = U.T @ f_base\n",
    "    fr_osc = U.T @ f_osc\n",
    "    \n",
    "    Ar = mu*Kr + Mr\n",
    "    fr_total = fr_base + nu*fr_osc\n",
    "    a = np.linalg.solve(Ar, fr_total)\n",
    "    return U @ a, a\n",
    "\n",
    "\n",
    "print(\"✓ Extended multi-parameter functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ecc617",
   "metadata": {},
   "source": [
    "## Extended Exercises — Multi-Parameter Problem\n",
    "\n",
    "Now that you have the extended problem setup, let's explore the 2-parameter space $(\\mu, \\nu)$ where:\n",
    "- $\\mu \\in [0.1, 10]$ controls diffusion\n",
    "- $\\nu \\in [-2, 2]$ controls oscillating source amplitude\n",
    "- $\\omega = 2$ is the fixed frequency\n",
    "\n",
    "**Goal**: Apply ROM methods to this richer problem and see how the parameter space affects the basis construction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba6549",
   "metadata": {},
   "source": [
    "### Exercise 5 — Parameter Space Exploration (10 min)\n",
    "\n",
    "Explore the 2-parameter problem by visualizing solutions and understanding the parameter space structure.\n",
    "\n",
    "**Tasks:**\n",
    "1. Set up parameter ranges for $(\\mu, \\nu)$\n",
    "2. Visualize a few solutions for different parameter combinations\n",
    "3. Build snapshots for the 2-parameter problem\n",
    "4. Analyze how solutions vary with both parameters\n",
    "\n",
    "> *Hint:* Use `assemble_system_extended`, `solve_full_extended`, `build_snapshots_extended`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cab39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Your turn (student cell) ===\n",
    "# Explore the 2-parameter problem space\n",
    "\n",
    "# TODO: Set up the extended system\n",
    "omega_freq = 2.0  # Fixed frequency\n",
    "K_ext, I_ext, f_base_ext, f_osc_ext, h_ext, lminK_ext = assemble_system_extended(N, omega_freq)\n",
    "\n",
    "# TODO: Define parameter ranges\n",
    "# Hint: mu_ext = np.logspace(np.log10(0.1), np.log10(10), 8)    # 8 mu values\n",
    "# Hint: nu_ext = np.linspace(-2, 2, 6)                          # 6 nu values\n",
    "\n",
    "print(f\"Extended problem setup:\")\n",
    "print(f\"  - Grid size: N = {N}\")\n",
    "print(f\"  - Frequency: ω = {omega_freq}\")\n",
    "print(f\"  - μ range: {len(mu_ext)} values from {mu_ext[0]:.1f} to {mu_ext[-1]:.1f}\")\n",
    "print(f\"  - ν range: {len(nu_ext)} values from {nu_ext[0]:.1f} to {nu_ext[-1]:.1f}\")\n",
    "print(f\"  - Total parameter combinations: {len(mu_ext) * len(nu_ext)}\")\n",
    "\n",
    "# TODO: Visualize a few solutions for different parameter combinations\n",
    "# Create a grid for visualization\n",
    "x_ext = np.linspace(0, 1, N+2)[1:-1]  # Interior points\n",
    "\n",
    "# Pick some interesting parameter combinations to visualize\n",
    "param_demo = [(0.1, -2), (0.1, 2), (10, -2), (10, 2), (1.0, 0)]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (mu_demo, nu_demo) in enumerate(param_demo):\n",
    "    # TODO: Solve for this parameter combination\n",
    "    # u_demo = solve_full_extended(mu_demo, nu_demo, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "    \n",
    "    plt.subplot(2, 3, i+1)\n",
    "    # TODO: Plot the solution\n",
    "    # plt.plot(x_ext, u_demo, 'b-', linewidth=2)\n",
    "    # plt.title(f'μ={mu_demo}, ν={nu_demo}')\n",
    "    # plt.xlabel('x')\n",
    "    # plt.ylabel('u(x)')\n",
    "    # plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Build snapshot matrix for the 2-parameter problem\n",
    "# S_ext, param_combinations_ext = build_snapshots_extended(mu_ext, nu_ext, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "\n",
    "print(f\"\\n=== Exercise 5 Results ===\")\n",
    "print(f\"Snapshot matrix shape: {S_ext.shape}\")\n",
    "print(f\"Total snapshots: {len(param_combinations_ext)}\")\n",
    "# Print some statistics about the solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee8e0e",
   "metadata": {},
   "source": [
    "### Exercise 6 — POD for Multi-Parameter Problem (15 min)\n",
    "\n",
    "Apply POD to the 2-parameter snapshot matrix and analyze the singular value decay.\n",
    "\n",
    "**Tasks:**\n",
    "1. Compute POD decomposition of the extended snapshot matrix\n",
    "2. Plot singular values and analyze the decay rate\n",
    "3. Compare energy content with the 1-parameter case\n",
    "4. Visualize the first few POD modes\n",
    "5. Test POD basis performance on the extended problem\n",
    "\n",
    "**Questions to consider:**\n",
    "- How does the singular value decay compare to the 1-parameter case?\n",
    "- How many modes are needed for 99% energy capture?\n",
    "- Do the POD modes reveal the structure of the oscillating source?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0cdb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Your turn (student cell) ===\n",
    "# Apply POD to the extended 2-parameter problem\n",
    "\n",
    "# TODO: Compute POD decomposition\n",
    "# U_ext, s_ext = pod_basis(S_ext, S_ext.shape[1])  # Full decomposition first\n",
    "\n",
    "# TODO: Analyze singular values\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Singular values comparison\n",
    "plt.subplot(1, 3, 1)\n",
    "# TODO: Plot singular values for both 1-param and 2-param cases\n",
    "# plt.semilogy(s, 'b-o', label='1-parameter', markersize=4)\n",
    "# plt.semilogy(s_ext, 'r-s', label='2-parameter', markersize=4)\n",
    "# plt.xlabel('Mode number')\n",
    "# plt.ylabel('Singular value')\n",
    "# plt.title('Singular values comparison')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# Plot 2: Cumulative energy\n",
    "plt.subplot(1, 3, 2)\n",
    "# TODO: Compute and plot cumulative energy for extended problem\n",
    "# cumulative_energy_ext = np.cumsum(s_ext**2) / np.sum(s_ext**2)\n",
    "# plt.plot(cumulative_energy_ext, 'r-', linewidth=2, label='2-parameter')\n",
    "# plt.plot(cumulative_energy, 'b--', linewidth=2, label='1-parameter')\n",
    "# plt.axhline(y=0.99, color='k', linestyle=':', alpha=0.7, label='99%')\n",
    "# plt.axhline(y=0.999, color='k', linestyle=':', alpha=0.5, label='99.9%')\n",
    "# plt.xlabel('Mode number')\n",
    "# plt.ylabel('Cumulative energy')\n",
    "# plt.title('Energy content')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# Plot 3: First few POD modes\n",
    "plt.subplot(1, 3, 3)\n",
    "# TODO: Visualize first 4 POD modes\n",
    "# for i in range(4):\n",
    "#     plt.plot(x_ext, U_ext[:, i], label=f'Mode {i+1}', linewidth=2)\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('POD mode value')\n",
    "# plt.title('First 4 POD modes')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Find modes needed for different energy levels\n",
    "modes_99_ext = None   # TODO: np.argmax(cumulative_energy_ext >= 0.99) + 1\n",
    "modes_999_ext = None  # TODO: np.argmax(cumulative_energy_ext >= 0.999) + 1\n",
    "\n",
    "# TODO: Test POD performance on extended problem\n",
    "# Choose a test parameter combination not in training set\n",
    "mu_test_ext = 2.5\n",
    "nu_test_ext = 1.5\n",
    "\n",
    "# Test different POD basis sizes\n",
    "test_ranks = [1, 2, 5, 10, min(15, len(s_ext))]\n",
    "pod_errors_ext = []\n",
    "\n",
    "# for r_test in test_ranks:\n",
    "    # TODO: Build POD basis of size r_test\n",
    "    # U_pod_ext = U_ext[:, :r_test]\n",
    "    \n",
    "    # TODO: Compute full and reduced solutions\n",
    "    # u_full_test = solve_full_extended(mu_test_ext, nu_test_ext, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "    # u_rb_test, _ = rb_solve_extended(mu_test_ext, nu_test_ext, U_pod_ext, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "    \n",
    "    # TODO: Compute relative error\n",
    "    # _, rel_error_test = project_error(u_full_test, u_rb_test)\n",
    "    # pod_errors_ext.append(rel_error_test)\n",
    "\n",
    "# TODO: Plot POD convergence for extended problem\n",
    "plt.figure(figsize=(8, 6))\n",
    "# plt.semilogy(test_ranks, pod_errors_ext, 'ro-', linewidth=2, markersize=8)\n",
    "# plt.xlabel('POD basis size')\n",
    "# plt.ylabel('Relative error')\n",
    "# plt.title(f'POD convergence (μ={mu_test_ext}, ν={nu_test_ext})')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "print(\"=== Exercise 6 Results ===\")\n",
    "print(f\"Extended problem singular values: {len(s_ext)} total\")\n",
    "# print(f\"Modes for 99% energy (1-param): {modes_99}\")\n",
    "# print(f\"Modes for 99% energy (2-param): {modes_99_ext}\")\n",
    "# print(f\"Modes for 99.9% energy (1-param): {modes_999}\")\n",
    "# print(f\"Modes for 99.9% energy (2-param): {modes_999_ext}\")\n",
    "print(f\"Test parameter: μ={mu_test_ext}, ν={nu_test_ext}\")\n",
    "# print(f\"POD errors for different ranks: {pod_errors_ext}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48264f02",
   "metadata": {},
   "source": [
    "### Exercise 7 — Greedy for Multi-Parameter Problem (20 min)\n",
    "\n",
    "Implement a greedy algorithm for the 2-parameter problem. This is more challenging because you need to search over the 2D parameter space!\n",
    "\n",
    "**Tasks:**\n",
    "1. Adapt the greedy algorithm for 2-parameter space $(\\mu, \\nu)$\n",
    "2. Define an appropriate error estimator for the extended problem\n",
    "3. Run the greedy algorithm and compare with POD\n",
    "4. Visualize the selected parameters in the 2D parameter space\n",
    "5. Compare computational efficiency\n",
    "\n",
    "**Algorithm adaptation:**\n",
    "- **Training set**: All combinations of $(\\mu, \\nu)$ from your parameter ranges\n",
    "- **Error estimator**: Extend the residual-based estimator for the new RHS structure\n",
    "- **Selection criterion**: Find $(\\mu^*, \\nu^*)$ that maximizes the estimator\n",
    "- **Basis enrichment**: Add solution $u(\\mu^*, \\nu^*)$ to the basis\n",
    "\n",
    "**Challenges:**\n",
    "- Larger parameter space means more combinations to evaluate\n",
    "- Error estimator needs to handle the new affine structure\n",
    "- Visualization of selected parameters in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Your turn (student cell) ===\n",
    "# Implement greedy algorithm for 2-parameter problem\n",
    "\n",
    "def estimator_extended(u_rb, mu, nu, K, I, f_base, f_osc, lminK):\n",
    "    \"\"\"\n",
    "    Error estimator for extended problem with affine RHS structure.\n",
    "    \n",
    "    For the extended problem: (mu*K + I) u = f_base + nu*f_osc\n",
    "    Residual: r = f_base + nu*f_osc - (mu*K + I) @ u_rb\n",
    "    \"\"\"\n",
    "    # TODO: Implement extended error estimator\n",
    "    # Hint: r = f_base + nu*f_osc - (mu*K + I) @ u_rb\n",
    "    # Hint: residual_norm = np.linalg.norm(r, 2)\n",
    "    # Hint: alpha_lb = alpha_LB(mu, lminK)  # Same coercivity bound\n",
    "    # return residual_norm / alpha_lb\n",
    "    pass\n",
    "\n",
    "\n",
    "def greedy_extended(param_combinations, K, I, f_base, f_osc, lminK, tol=1e-6, max_basis=20, verbose=True):\n",
    "    \"\"\"\n",
    "    Greedy algorithm for 2-parameter problem.\n",
    "    \n",
    "    Parameters:\n",
    "        param_combinations: list of (mu, nu) tuples for training\n",
    "        Other parameters: system matrices and tolerances\n",
    "    \n",
    "    Returns:\n",
    "        U: greedy basis matrix\n",
    "        selected_params: list of selected (mu, nu) parameters\n",
    "        estimator_history: convergence history\n",
    "    \"\"\"\n",
    "    # TODO: Initialize with a parameter from the middle of the ranges\n",
    "    # Find middle indices for mu and nu ranges\n",
    "    n_mu = len(mu_ext)\n",
    "    n_nu = len(nu_ext)\n",
    "    mid_idx = (n_mu // 2) * n_nu + (n_nu // 2)  # Middle combination\n",
    "    mu0, nu0 = param_combinations[mid_idx]\n",
    "    \n",
    "    # TODO: Compute initial solution and basis\n",
    "    # u0 = solve_full_extended(mu0, nu0, K, I, f_base, f_osc)\n",
    "    # U = orthonormalize(u0, None)[:, None]\n",
    "    \n",
    "    selected_params = [(mu0, nu0)]\n",
    "    estimator_history = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"[Greedy Extended] Starting with μ={mu0:.3f}, ν={nu0:.3f}\")\n",
    "    \n",
    "    # TODO: Main greedy loop\n",
    "    for iteration in range(1, max_basis + 1):\n",
    "        # TODO: Compute estimator for all parameter combinations\n",
    "        estimators = []\n",
    "        # for mu, nu in param_combinations:\n",
    "        #     u_rb, _ = rb_solve_extended(mu, nu, U, K, I, f_base, f_osc)\n",
    "        #     est = estimator_extended(u_rb, mu, nu, K, I, f_base, f_osc, lminK)\n",
    "        #     estimators.append(est)\n",
    "        \n",
    "        # TODO: Find parameter combination with maximum estimator\n",
    "        # idx_max = np.argmax(estimators)\n",
    "        # mu_star, nu_star = param_combinations[idx_max]\n",
    "        # max_estimator = estimators[idx_max]\n",
    "        \n",
    "        estimator_history.append(max_estimator)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"[Greedy Extended] Iteration {iteration}: max est = {max_estimator:.3e} at μ={mu_star:.3f}, ν={nu_star:.3f}\")\n",
    "        \n",
    "        # TODO: Check stopping criterion\n",
    "        # if max_estimator < tol:\n",
    "        #     if verbose:\n",
    "        #         print(f\"[Greedy Extended] Converged at iteration {iteration}\")\n",
    "        #     break\n",
    "        \n",
    "        # TODO: Enrich basis\n",
    "        # u_star = solve_full_extended(mu_star, nu_star, K, I, f_base, f_osc)\n",
    "        # v_new = orthonormalize(u_star, U)\n",
    "        # if v_new is None:\n",
    "        #     if verbose:\n",
    "        #         print(f\"[Greedy Extended] Linear dependence at iteration {iteration}\")\n",
    "        #     break\n",
    "        # U = np.column_stack([U, v_new])\n",
    "        \n",
    "        selected_params.append((mu_star, nu_star))\n",
    "    \n",
    "    return U, selected_params, np.array(estimator_history)\n",
    "\n",
    "\n",
    "# TODO: Run the extended greedy algorithm\n",
    "print(\"Running greedy algorithm for 2-parameter problem...\")\n",
    "# U_greedy_ext, selected_ext, history_ext = greedy_extended(\n",
    "#     param_combinations_ext, K_ext, I_ext, f_base_ext, f_osc_ext, lminK_ext, \n",
    "#     tol=1e-6, max_basis=20, verbose=True\n",
    "# )\n",
    "\n",
    "# TODO: Visualize results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Greedy convergence\n",
    "plt.subplot(1, 3, 1)\n",
    "# plt.semilogy(range(1, len(history_ext)+1), history_ext, 'go-', linewidth=2, markersize=6)\n",
    "# plt.xlabel('Greedy iteration')\n",
    "# plt.ylabel('Maximum estimator')\n",
    "# plt.title('Greedy convergence (2-param)')\n",
    "# plt.grid(True)\n",
    "\n",
    "# Plot 2: Selected parameters in 2D space\n",
    "plt.subplot(1, 3, 2)\n",
    "# mu_selected = [p[0] for p in selected_ext]\n",
    "# nu_selected = [p[1] for p in selected_ext]\n",
    "# \n",
    "# # Plot all training parameters as background\n",
    "# mu_all = [p[0] for p in param_combinations_ext]\n",
    "# nu_all = [p[1] for p in param_combinations_ext]\n",
    "# plt.scatter(mu_all, nu_all, c='lightgray', alpha=0.5, s=20, label='Training set')\n",
    "# \n",
    "# # Plot selected parameters\n",
    "# plt.scatter(mu_selected, nu_selected, c=range(len(mu_selected)), \n",
    "#             cmap='viridis', s=100, edgecolor='black', linewidth=1, label='Selected')\n",
    "# for i, (mu_s, nu_s) in enumerate(selected_ext):\n",
    "#     plt.annotate(f'{i+1}', (mu_s, nu_s), xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "# \n",
    "# plt.xlabel('μ (diffusion)')\n",
    "# plt.ylabel('ν (oscillating amplitude)')\n",
    "# plt.title('Selected parameters')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# Plot 3: POD vs Greedy comparison for extended problem\n",
    "plt.subplot(1, 3, 3)\n",
    "# Compare performance on a test parameter\n",
    "# mu_test2, nu_test2 = 5.0, -1.0\n",
    "# test_ranks_ext = range(1, min(U_greedy_ext.shape[1], U_ext.shape[1]) + 1)\n",
    "# \n",
    "# pod_errors_comp = []\n",
    "# greedy_errors_comp = []\n",
    "# \n",
    "# for r in test_ranks_ext:\n",
    "#     # POD error\n",
    "#     U_pod_r = U_ext[:, :r]\n",
    "#     u_full_comp = solve_full_extended(mu_test2, nu_test2, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "#     u_pod_comp, _ = rb_solve_extended(mu_test2, nu_test2, U_pod_r, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "#     _, rel_pod = project_error(u_full_comp, u_pod_comp)\n",
    "#     pod_errors_comp.append(rel_pod)\n",
    "#     \n",
    "#     # Greedy error\n",
    "#     if r <= U_greedy_ext.shape[1]:\n",
    "#         U_greedy_r = U_greedy_ext[:, :r]\n",
    "#         u_greedy_comp, _ = rb_solve_extended(mu_test2, nu_test2, U_greedy_r, K_ext, I_ext, f_base_ext, f_osc_ext)\n",
    "#         _, rel_greedy = project_error(u_full_comp, u_greedy_comp)\n",
    "#         greedy_errors_comp.append(rel_greedy)\n",
    "#     else:\n",
    "#         greedy_errors_comp.append(np.nan)\n",
    "# \n",
    "# plt.semilogy(test_ranks_ext, pod_errors_comp, 'b-o', label='POD', linewidth=2)\n",
    "# valid_greedy = [e for e in greedy_errors_comp if not np.isnan(e)]\n",
    "# plt.semilogy(range(1, len(valid_greedy)+1), valid_greedy, 'r-s', label='Greedy', linewidth=2)\n",
    "# plt.xlabel('Basis size')\n",
    "# plt.ylabel('Relative error')\n",
    "# plt.title(f'POD vs Greedy\\n(μ={mu_test2}, ν={nu_test2})')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=== Exercise 7 Results ===\")\n",
    "# print(f\"Greedy basis size: {U_greedy_ext.shape[1]}\")\n",
    "# print(f\"Selected parameters: {len(selected_ext)}\")\n",
    "# print(f\"Final estimator: {history_ext[-1]:.3e}\")\n",
    "# print(f\"Training set size: {len(param_combinations_ext)}\")\n",
    "print(\"Extended greedy algorithm implementation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
