{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBSSULReUITm"
   },
   "source": [
    "# Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QmaoIBF9PTCk"
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Fjjt2Z_LI9rf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 14:26:30.703187: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sQsfkGue81m"
   },
   "source": [
    "## Backward et Foreward\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biOeIVOkzWiQ"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "Mais comment calcule-t-on des d√©riv√©es d√©j√† ? Ok, on sait le faire sur papier, mais avec un ordinateur ? Curieusement, la bonne r√©ponse est venue tardivement (1985 environ). Cela s'appelle \"la r√©tro-propagation du gradient\" (=back-propagation). Et cette avanc√©e algorithmique a permie de d√©velopper le deep learning.\n",
    "\n",
    "Imaginons que nous voulons effectuer le calcul $y=3x*(x^2+ 4)$ et d√©terminer son gradient $\\frac{dy}{dx}=3(x^2+ 4)+3x*2x$ en un point pr√©cis: $x=3$. On agit alors en deux √©tapes:\n",
    "\n",
    "* Passage forward: On effectue le calcul voulu  tout en enregistrant chaque √©tape de calcul, ici: $x^2$, puis $x^2+4$, ensuite $3x$, ensuite $y$.  Techniquement en tensorflow, l'enregistrement se fait sur une \"bande\" (imaginez une bande magn√©tique) via l'objet `tf.GradientTape`.\n",
    "* Passage *backward*:  On parcourt cette bande dans l'ordre inverse pour calculer et composer les gradients des op√©rations √©l√©mentaires (on verra un exemple plus loin).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4440,
     "status": "ok",
     "timestamp": 1730760458168,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Xq9GgTCP7a4A",
    "outputId": "a37eac39-917a-48c8-c574-ee8e2b9a4ba3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(3.0)\n",
    "\n",
    "# Passage forward\n",
    "with tf.GradientTape() as tape:\n",
    "  y = 3*x*(x**2 + x)\n",
    "\n",
    "# Passage backward\n",
    "dy_dx = tape.gradient(y, x)\n",
    "dy_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPXqvl3yfH7Y"
   },
   "source": [
    "### D√©rivation compos√©e (Chain rule)\n",
    "\n",
    "D√©taillons les maths sur un exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw6RWnrRe-Nr"
   },
   "source": [
    "Analysons la d√©riv√©e de la fonction $  h \\circ g \\circ f (x)  $.  Voici son graphe de calcul:\n",
    "\n",
    "$$\n",
    "x \\xrightarrow  f   y   \\xrightarrow g z   \\xrightarrow h  t\n",
    "$$\n",
    "  Les accroissements infinit√©simaux se multiplient (c'est la chain rule) :\n",
    "\n",
    "\\begin{alignat}{1}\n",
    "\\frac {\\partial  t  }{\\partial x}      &=        \\frac{ \\partial y }{ \\partial x}   \\frac{ \\partial z }{ \\partial y}   \\frac{ \\partial t }{ \\partial z } \\\\\n",
    "&=  f'(x) g'(y) h'(z)    \n",
    "\\end{alignat}\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Rmy4pcOgATn"
   },
   "source": [
    "Nous allons d√©cortiquer le calcul de cette d√©riv√©e en un point pr√©cis. Pour fixer les id√©es:\n",
    "\n",
    "* $f(a) = \\sin(a)$, donc $f'(a) = \\cos(a)$\n",
    "* $g(a) =  4 a^2$, donc $g'(a) = 8 a$\n",
    "* $h(a)=  \\tanh(a)$ donc $h'(a)= 1-\\tanh^2(a)$\n",
    "\n",
    "Notons que l'ordinateur sait calculer ces fonctions et leur d√©riv√©e de mani√®re tr√®s pr√©cise.\n",
    "\n",
    "Nous voulons calculer\n",
    "$$\n",
    "   \\frac{\\partial (h \\circ g \\circ f )(x)} {\\partial x}  \n",
    "$$\n",
    "en $x=7$.\n",
    "\n",
    "Forward pass:\n",
    "1. Calcul et stockage de $y=f(x)$\n",
    "2. Calcul et stockage de $z=g(y)$\n",
    "3. Calcul et stockage de $t=h(z)$\n",
    "\n",
    "Backward pass:\n",
    "1. Calcul de $\\frac{\\partial t}{\\partial z} = h'(z)$\n",
    "2. Calcul de $\\frac{\\partial t}{\\partial y} = g'(y) h'(z)$.\n",
    "3. Calcul de $\\frac{\\partial t}{\\partial x} = f'(x) g'(y) h'(z)$.\n",
    "\n",
    "Faisons cela en tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730760458168,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "aZ8Ee04hnBhB",
    "outputId": "8294190c-1ecc-4857-84e8-3ebf77c1c34e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041513324\n",
      "0.2503759\n",
      "-0.1644936\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(7.)\n",
    "\n",
    "#forward\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y = tf.cos(x)\n",
    "    z = 4*y**2\n",
    "    t = tf.tanh(z)\n",
    "\n",
    "#backward\n",
    "print(tape.gradient(t,z).numpy())\n",
    "print(tape.gradient(t,y).numpy())\n",
    "print(tape.gradient(t,x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQd1sR1PoNaO"
   },
   "source": [
    "Bien entendu, on n'est pas oblig√© d'indiquer toutes les √©tapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730760458168,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "BGoYC3_QoDFK",
    "outputId": "f48666d6-2104-4192-973c-0f19394632ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1644936\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(7.)\n",
    "with tf.GradientTape(persistent=False) as tape:\n",
    "    t = tf.tanh(4*tf.cos(x)**2)\n",
    "\n",
    "print(tape.gradient(t,x).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T3_tb5VBOLE"
   },
   "source": [
    "Remarque: comme je ne calcule qu'un seul gradient avec ma tape, je peux mettre `persistent=False`. La m√©moire prise par la tape sera lib√©r√©e plus vite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qU9Rvv38f_mG"
   },
   "source": [
    "***√Ä vous:***  Consid√©rons des scalaires $a,b,c,d$ et les fonctions affines\n",
    "\n",
    "* $f(x) = ax+b $ et\n",
    "* $g(x) = cx + d $.\n",
    "\n",
    "\n",
    "Calculez explicitement $g\\circ f(x+\\epsilon) - g\\circ f(x)$.    \n",
    "\n",
    "\n",
    "En comparant cet exo et la 'chain rule', vous comprendrez que : les accroissements infinit√©simaux des fonctions lisses, se composent de la m√™me mani√®re que les accroissements des fonctions affines.  En bref : toute fonction lisse est localement une fonction affine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfkLBxBxlQ4R"
   },
   "source": [
    "### R√©gle de l'accumulation\n",
    "\n",
    "Quand une fonction a plusieurs variables, $g(a,b,...)$, ses d√©riv√©es partielles  se calculent sans difficult√©. Par ex, pour calculer  $\\frac{\\partial g(a,b,...)}{\\partial a}$ il suffit de consid√©rer uniquement la fonction $a\\to g(a,b,...)$.\n",
    "\n",
    "\n",
    "Par contre, quand  une variable $x$ intervient plusieurs fois:\n",
    "$$\n",
    "z=h(x) =  g  [ f_1 (x), f_2 (x) , ...] = g [ y_1,y_2,...]\n",
    "$$\n",
    " Graphe de calcul (dit en diamant):\n",
    "$$\n",
    "x \\xrightarrow f  \\begin{bmatrix}  y_1 \\\\  y_2 \\\\ \\vdots \\end{bmatrix}  \\xrightarrow g z\n",
    " $$\n",
    " Les accroissements s'additionnent (s'accumulent):\n",
    "$$\n",
    "\\frac {\\partial  z  }{\\partial x}  =    \\sum_i        \\frac{\\partial y_i }{\\partial x}      \\frac {\\partial z }{\\partial y_i} =    \\sum_i     f'_i(x) g'(y_i)  \n",
    "$$\n",
    "\n",
    "\n",
    "***√Ä vous:*** vous connaissez par c≈ìur la r√©gle de d√©rivation d'un produit:\n",
    "$$\n",
    "(f_1 * f_2)' = f'_1 f_2 + f_1 f'_2\n",
    "$$\n",
    "V√©rifiez qu'il s'agit d'un cas particulier de la r√©gle d'accumulation. Pour vous aider, consid√©rer le graphe de calcul en diamant:\n",
    "$$\n",
    "x \\xrightarrow f  \\begin{bmatrix}  f_1(x) \\\\  f_2(x)  \\end{bmatrix}  \\xrightarrow * f_1(x) * f_2(x)\n",
    " $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYsUHSO71nOj"
   },
   "source": [
    "V√©rifions la r√©gle de l'accumulation en tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1730760458804,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "W84ggX9moYOd",
    "outputId": "86d5f694-3354-4278-b02d-bbb329c7a14a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.504779\n",
      "-15.504779\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable(7.)\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    y1=x**2\n",
    "    y2=tf.cos(x)\n",
    "    y3=tf.atan(x)\n",
    "    z=y1*y2/y3\n",
    "\n",
    "print(tape.gradient(z,x).numpy())\n",
    "\n",
    "dz_dy1=tape.gradient(z,y1)\n",
    "dz_dy2=tape.gradient(z,y2)\n",
    "dz_dy3=tape.gradient(z,y3)\n",
    "\n",
    "dy1_dx=tape.gradient(y1,x)\n",
    "dy2_dx=tape.gradient(y2,x)\n",
    "dy3_dx=tape.gradient(y3,x)\n",
    "\n",
    "dz_dx = dz_dy1*dy1_dx + dz_dy2*dy2_dx + dz_dy3*dy3_dx\n",
    "print(dz_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxKAvsOHw2Gn"
   },
   "source": [
    "### Comparaison avec le calcul formel \"symbolique\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K_WH9hCosA-w"
   },
   "outputs": [],
   "source": [
    "def fonction_complexe(x,y,z):\n",
    "    a=atan(x/y)\n",
    "    b=cos(z**2-x)\n",
    "    return x*y*a*b/z+a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730760458805,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "C34AL5wUsi_Y",
    "outputId": "b5039fa9-223b-48d2-c8e6-287e1b4452f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.6619678\n",
      "-1.7493755\n",
      "17.059452\n",
      "CPU times: user 14.3 ms, sys: 1.25 ms, total: 15.5 ms\n",
      "Wall time: 11.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow import cos,atan\n",
    "\n",
    "x=tf.Variable(7.)\n",
    "y=tf.Variable(5.)\n",
    "z=tf.Variable(2.)\n",
    "with tf.GradientTape() as tape:\n",
    "    f=fonction_complexe(x,y,z)\n",
    "\n",
    "[df_dx,df_dy,df_dz]=tape.gradient(f,[x,y,z])\n",
    "print(df_dx.numpy())\n",
    "print(df_dy.numpy())\n",
    "print(df_dz.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3167,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "YoOJFgOJtS6E",
    "outputId": "ad432dda-4dbc-4380-d678-ff2c15232dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.66196787253764\n",
      "-1.74937550466067\n",
      "17.0594520169513\n",
      "CPU times: user 867 ms, sys: 176 ms, total: 1.04 s\n",
      "Wall time: 1.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sympy\n",
    "from sympy import cos,atan\n",
    "\n",
    "x,y,z=sympy.symbols('x y z')\n",
    "f=fonction_complexe(x,y,z)\n",
    "df_dx=sympy.Derivative(f, x).doit()\n",
    "df_dy=sympy.Derivative(f, y).doit()\n",
    "df_dz=sympy.Derivative(f, z).doit()\n",
    "\n",
    "subs={x:7.,y:5.,z:2.}\n",
    "print(df_dx.evalf(subs=subs))\n",
    "print(df_dy.evalf(subs=subs))\n",
    "print(df_dz.evalf(subs=subs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubg0T4YKxGVE"
   },
   "source": [
    "Regardons les expressions que doit retenir `sympy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Ep3fUX0KxAC3",
    "outputId": "4eb39614-4759-4f35-c60b-162876a58c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-x*y*sin(x - z**2)*atan(x/y)/z + x*cos(x - z**2)/(z*(x**2/y**2 + 1)) + y*cos(x - z**2)*atan(x/y)/z + sin(x - z**2) + 1/(y*(x**2/y**2 + 1))\n"
     ]
    }
   ],
   "source": [
    "print(df_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIfS9fDN0fgd"
   },
   "source": [
    "## La technique torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fjzPS2DNTU9k"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgXeBvI5oxa0"
   },
   "source": [
    "### Premier exemple de graph de calcul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhcLpvwvzJHD"
   },
   "source": [
    "Voici un graphe de calcul tr√®s simple. Il faut le lire de bas en haut. Les `leaf` sont  `x` et `a`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_06Ij0Hyd-G"
   },
   "source": [
    "    x     a\n",
    "     \\   /\n",
    "       y=x*a\n",
    "       |\n",
    "       z=y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFJm4MmElAgU"
   },
   "source": [
    "***A vous:*** Est-il possible que dans un graph de calcul il y ait un cycle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TpKuIu3oEhY"
   },
   "source": [
    "Il faut pr√©ciser `requires_grad=True` sur les `leaf` par rapport auxquelles on veut d√©river."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "ks0R-7YSMRl2",
    "outputId": "0288ad89-3a5a-4ca9-90c2-61583c9518d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:8.0, a.grad:None\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2\n",
    "z.backward()\n",
    "\n",
    "print(f\"x.grad:{x.grad}, a.grad:{a.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5YgLlsO_0QMO"
   },
   "source": [
    "Si on veut aussi d√©river par rapport √† `a`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "TqqOUSwBwvh4",
    "outputId": "e5122c79-9bec-4799-db4d-ad6fb00080c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:8.0, a.grad:4.0\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True)\n",
    "y=a*x\n",
    "z=y**2\n",
    "z.backward()\n",
    "\n",
    "print(f\"x.grad:{x.grad}, a.grad:{a.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dsUHoUWq2p-_"
   },
   "source": [
    "### Second exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynaYx5zRo5DC"
   },
   "source": [
    "***A retenir:***\n",
    "\n",
    "* √Ä tout calcul, on peut mentalement associer un graphe de calcul\n",
    "* Mais ce graphe est physiquement cr√©√© par torch uniquement dans les branches  qui ont la propri√©t√© `requires_grad=True`\n",
    "* Quand on appelle la m√©thode `backward()` sur un n≈ìud, torch va remonter le graphe depuis ce n≈ìud pour calculer les gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INS07Q1Vy4Sc"
   },
   "source": [
    "Suivons l'exemple du calcul de d√©riv√©e de\n",
    "$$\n",
    "z=(x^2*cos(x))^2\n",
    "$$\n",
    "Le graph des calcul inclus un diamant puisque $x$ intervient deux fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwvWGdeiqGPH"
   },
   "source": [
    "Forward\n",
    "\n",
    "\n",
    "\n",
    "        x=ùúã\n",
    "       /   \\\n",
    "    a=x^2   b=cos(x)\n",
    "     =ùúã¬≤    =-1\n",
    "     \\      /\n",
    "       y=a*b\n",
    "        =-ùúã¬≤\n",
    "        |\n",
    "       z=y**2\n",
    "        =ùúã‚Å¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3u56ilMxZuz"
   },
   "source": [
    "On d√©clenche le passage backward par `z.backward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyL8tGIiqT68"
   },
   "source": [
    "\n",
    "\n",
    "Etape 1\n",
    "\n",
    "\n",
    "    dz/dy=2y\n",
    "         =-2ùúã¬≤\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrlhAnHLuza1"
   },
   "source": [
    "Etape 2\n",
    "       \n",
    "\n",
    "      dz/da           dz/db\n",
    "      =dz/dy*dy/da    =dz/dy*dy/db\n",
    "      =-2ùúã¬≤ *b        =-2ùúã¬≤ *a\n",
    "      =2ùúã¬≤            =-2ùúã‚Å¥\n",
    "        \\            /  \n",
    "           dz/dy=-2ùúã¬≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu0Hs3ZtyVBA"
   },
   "source": [
    "Etape 3\n",
    "\n",
    "            dz/dx\n",
    "            =  dz/da*da/dx\n",
    "              +dz/db*db/dx\n",
    "            =  2ùúã¬≤* 2x\n",
    "              -2ùúã‚Å¥* (-sin(x))\n",
    "            = 4ùúã¬≥\n",
    "          /          \\\n",
    "\n",
    "      dz/da           dz/db\n",
    "      =2ùúã¬≤            =-2ùúã‚Å¥\n",
    "        \\            /  \n",
    "           dz/dy=-2ùúã¬≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twEn_RzNoPh_"
   },
   "source": [
    "### D√©river par rapport √† une variable non-leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "7LiSTC6vocLz"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmfCfr73zmZ7"
   },
   "source": [
    "Dans le graph de calcul pr√©c√©dent, la variable `y` n'est pas une `leaf` mais elle `requires_grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "hScy7YNmyZew",
    "outputId": "fb9f2594-8fd2-4fb3-979c-432f7e4c42e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.requires_grad, y.is_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1g2nPvvfzxDT"
   },
   "source": [
    "Par d√©faut, on ne peut pas calculer ${\\partial z\\over \\partial y}$, sauf si demande √† $y$ de retenir le gradient qui la traverse pendant le backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "YWIwpG_kxKlU",
    "outputId": "96e97293-1455-4c77-c440-7a9b2e9a06d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.grad:8.0, a.grad:4.0, y.grad:4.0\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "y.retain_grad()\n",
    "z=y**2\n",
    "z.backward()\n",
    "\n",
    "print(f\"x.grad:{x.grad}, a.grad:{a.grad}, y.grad:{y.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gNQuL8QJner9"
   },
   "source": [
    "Il faut vraiment imaginer que les tenseurs torch ne sont pas des nombres, mais des r√©sultats d'√©valuation de fonctions compos√©es, et que toutes les √©tapes du calcul fonctionnel sont m√©moris√©es dans le tenseur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3l_0yIGq3Zu"
   },
   "source": [
    "### Des sources non-scalaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "WuUqI5VEpEhT",
    "outputId": "aabbffbb-a9f6-4ec2-dc24-42e3236d048d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dw:\n",
      " tensor([[6., 6., 6.],\n",
      "        [6., 6., 6.]])\n",
      "dz/db:\n",
      " tensor([6., 6., 6.])\n"
     ]
    }
   ],
   "source": [
    "#un exemple qui ressemble au calcul d'une loss de mod√®le lin√©aire\n",
    "\n",
    "w = torch.ones([2, 3], requires_grad=True)\n",
    "b = torch.ones([3],requires_grad=True)\n",
    "\n",
    "x = torch.ones([2])\n",
    "\n",
    "#d√©but du graph de calcul\n",
    "y = x@w+b\n",
    "z = y**2\n",
    "\n",
    "z.sum().backward()\n",
    "print(\"dz/dw:\\n\",w.grad)\n",
    "print(\"dz/db:\\n\",b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ih2F-pkK1U2d"
   },
   "source": [
    " Remarquons que `w` et `w.grad` ont les m√™mes shape. Logique puisque d√©river par rapport √† un tenseur signifie simplement d√©river par rapport √† tous les √©l√©ments du tenseur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY9MHoxT1MAV"
   },
   "source": [
    "***Attention:*** La m√©thode `y.backward()` n√©cessite que `y` est un scalaire. Remplacez\n",
    "\n",
    "    z.sum().backward()\n",
    "\n",
    "par\n",
    "\n",
    "    z.backward()\n",
    "\n",
    "Pour voir le message d'erreur qui apparait."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pUV1w4x17vZ"
   },
   "source": [
    "### Backpopager plusieurs fois √† travers un m√™me graphe de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OW44XGOqPLK"
   },
   "source": [
    "\n",
    "La m√©thode `.backward()` provoque  la backpropagation, et lors de cette op√©ration certaines des donn√©es stock√©es dans le graphe sont d√©truites (pour lib√©rer de l'espace m√©moire). Pour √©viter cela, on peut utiliser `.backward(retain_graph=True)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "z7okXdZ3TM9u",
    "outputId": "30d5817b-a42d-4976-b5fa-cfd90021848c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "y.backward(retain_graph=True) #tester en supprimant retain_graph=True\n",
    "\n",
    "z=y**2\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ClCDLGoGAdM"
   },
   "source": [
    "Comme vous pouvez le constater,  les gradients cr√©√©s par les 2 back-propagations se sont somm√©s. Si ce n'est pas le r√©sultat souhait√©, il faut penser √† intercaler la m√©thode `.zero_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "4YMSHU4HGlKG",
    "outputId": "aaa993c8-9433-42ba-ae47-51f23ed26c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "y.backward(retain_graph=True) #tester en supprimant retain_graph=True\n",
    "print(x.grad)\n",
    "x.grad.zero_()\n",
    "\n",
    "\n",
    "z=y**2\n",
    "z.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eOWQ1QPnujKT"
   },
   "source": [
    "Ci-dessous, on construit 2 fois le m√™me graph du calcul. Pas besoin de `retain_graph=True` puisqu'on refait les calculs.\n",
    "\n",
    "Mais ces 2 graphs sont construits √† partir de la m√™me variable source `x`. Du coup les gradients des 2 back-propagations s'accumulent dans `x.grad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730760461971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "2mYE8h6gto7p",
    "outputId": "4c3609c9-4e14-4d77-8705-75777fa6d127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1., requires_grad=True)\n",
    "y = x**2\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "y = x**2 #nouveau graph (on aurait pu changer de nom: z= ...)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jr6I-s8LoHEQ"
   },
   "source": [
    "### D√©sactiver les gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9bKCakrLRCh"
   },
   "source": [
    "La m√©thode `x.requires_grad_(True/False)` permet de changer le status du tenseur √† tout moment. Elle finit par un underscore puisqu'elle est `inplace`.\n",
    "\n",
    "\n",
    "On peut aussi d√©sactiver l'enregistrement des calculs  avec:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            calculs...\n",
    "\n",
    "\n",
    "Il existe plusieurs raisons de d√©sactiver le suivi de gradient :\n",
    "\n",
    "* Pour marquer certains param√®tres de votre r√©seau neuronal comme param√®tres gel√©s (ils ne sont plus modifi√©s par les optimizers car ils ne produisent plus de gradients).\n",
    "\n",
    "* Pour acc√©l√©rer les calculs lorsque vous effectuez uniquement des passages forward: comparez les temps de calculs des programmes ci-dessous (qui donnent le m√™me r√©sultat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DFTZOsiwRN38"
   },
   "source": [
    "### Calculer l'occupation de la m√©moire gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 304,
     "status": "ok",
     "timestamp": 1730801003191,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Lx9-Wqj97e2i"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730801003431,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "vLsl5t7PSpZB",
    "outputId": "6fbe4859-d60a-472b-8ca5-b0186a33c8f2"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mreset_peak_memory_stats()\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmax_memory_allocated()\n",
      "File \u001b[0;32m~/anaconda3/envs/myconda/lib/python3.12/site-packages/torch/cuda/memory.py:344\u001b[0m, in \u001b[0;36mreset_peak_memory_stats\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Reset the \"peak\" stats tracked by the CUDA memory allocator.\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03mSee :func:`~torch.cuda.memory_stats` for details. Peak stats correspond to the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    management.\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    343\u001b[0m device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_resetPeakMemoryStats(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_resetPeakMemoryStats'"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAPAby1Gfj4y"
   },
   "source": [
    "V√©rifiez que vous √™tes bien √† 0 ci-dessus. Sinon cela signifie que vous avez avant construits des tenseurs dans le gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1730801004965,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "yJNAB1tB7xWO"
   },
   "outputs": [],
   "source": [
    "size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 396,
     "status": "ok",
     "timestamp": 1730801006145,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "emTyDE5SURY7",
    "outputId": "0a58b89b-ca4f-4cdf-f183-761470f42b0a"
   },
   "outputs": [],
   "source": [
    "A=torch.ones(size,device=\"cuda\")\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1730801007265,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Uc--k8y8UYap",
    "outputId": "0a4513b8-25ce-4f42-82a5-2600560f23e7"
   },
   "outputs": [],
   "source": [
    "size*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1730801009932,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "RhM-STZoXJSD"
   },
   "outputs": [],
   "source": [
    "del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730800888332,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Tx7ZOMVjUfhR",
    "outputId": "e64c7f63-bfa1-46d5-c1f3-153a1e85653f"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1730800895367,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "cYzfNbzqUyom",
    "outputId": "75cb8d6e-d1f6-49cb-83a9-8109ad837b9f"
   },
   "outputs": [],
   "source": [
    "A=torch.ones(size,dtype=torch.float64,device=\"cuda\")\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1730800901141,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "TMHmAuAUU92Q",
    "outputId": "6ab8f6cf-fd5d-4f3c-988d-1684dbfbee51"
   },
   "outputs": [],
   "source": [
    "size*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1730800902683,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "PYi_oRC7VOaC"
   },
   "outputs": [],
   "source": [
    "del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730800903190,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "_0wH4ev6VCtA",
    "outputId": "075d1550-3da9-4493-e56c-df7b447db5e7"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyyufVVAVZa_"
   },
   "source": [
    "***√Ä vous:*** Que se passe-t-il si l'on remplace 1024 par une taille l√©g√®rement plus grande, ou plus petite ? Vous en d√©duirez pourquoi on aime bien d√©finir des tenseurs dont les tailles sont des puissances de 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqOFmj94X2P2"
   },
   "source": [
    "***√Ä vous:*** Que v√©rifie-t-on dans la suite ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1730801039483,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Kwtli05IHr7z"
   },
   "outputs": [],
   "source": [
    "def some_calculus(requires_grad,n):\n",
    "    A=torch.rand(1000,device=\"cuda\",requires_grad=requires_grad)\n",
    "    for _ in range(n):\n",
    "        A=A*torch.rand(1000,device=\"cuda\")\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730801040338,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "5Qf2qM5qV7oQ",
    "outputId": "cd52014e-0a51-458c-f114-fb6189985e68"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "torch.cuda.max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1730801046821,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "U3sPsD7RV-Ya",
    "outputId": "419da271-20b7-44e8-d1cd-7319a3b9fdb7"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "A=some_calculus(True,10)\n",
    "print(torch.cuda.max_memory_allocated())\n",
    "del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1730801077404,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "m9YpIu_HV-bu",
    "outputId": "03990d59-9f06-4e37-bbf8-d920e28d11b8"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "A=some_calculus(True,100)\n",
    "print(torch.cuda.max_memory_allocated())\n",
    "del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1730801131517,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "SSi6xGHSV-g9",
    "outputId": "bfc3ab64-700e-4f96-de0b-b21b515384ea"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "A=some_calculus(False,10)\n",
    "print(torch.cuda.max_memory_allocated())\n",
    "del A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1730801132971,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "De5BEG1XXu_7",
    "outputId": "8a0fa2de-c364-4b44-e4ca-1a00d9bdd47f"
   },
   "outputs": [],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "A=some_calculus(False,100)\n",
    "print(torch.cuda.max_memory_allocated())\n",
    "del A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-p26zwsYapG"
   },
   "source": [
    "## La fonction grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFFXpVaseM6G"
   },
   "source": [
    "### Pour sp√©cifier les sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrD1oOY9cH7b"
   },
   "source": [
    "Dans la m√©thode `backward()` on peut sp√©cifier les sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "m4Has0AKYheQ",
    "outputId": "357f9b7c-7777-4083-fdfe-6dc07e8f6d98"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2\n",
    "z.backward(inputs=[x])\n",
    "\n",
    "print(f\"x.grad:{x.grad}, a.grad:{a.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bRDn07mcfpM"
   },
   "source": [
    "Cependant, dans ce cas, c'est plus naturelle d'utiliser la fonction `grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "838OCEfQbvbV",
    "outputId": "f7cfa484-fc2e-4066-becc-59885bfb78d0"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import grad\n",
    "\n",
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2\n",
    "\n",
    "\n",
    "print(f\"x.grad:{grad(z,x)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "jWL_oMGXAjRd",
    "outputId": "fcf8971c-0d8a-4718-f611-0a818780e278"
   },
   "outputs": [],
   "source": [
    "print(x.grad)#rien dedans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0Acj5zqcxyE"
   },
   "source": [
    "Mais tout ce qu'on a dit avant reste valable: par exemple, on ne peut pas enchainer le programme pr√©c√©dent par `grad(z,a)` car cela impliquerait une seconde backpropagation dans le graphe des calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jGxl6JWYdApY"
   },
   "source": [
    "Pour pouvoir faire cela, il faut ajouter une option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "bSdvTZ2eco37",
    "outputId": "1b963d7b-1ddf-4632-e435-52a643a9d1b5"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2\n",
    "\n",
    "\n",
    "print(f\"x.grad:{grad(z,x,retain_graph=True)[0]}\")\n",
    "print(f\"a.grad:{grad(z,a)[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC41vlSXdunW"
   },
   "source": [
    "Mais ce n'est pas efficace: il vaut mieux calculer tous les gradients d'un coup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "Zx9huJyvdtx0",
    "outputId": "3ecee61b-e630-456e-9af6-6a019fc00fa0"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "a=torch.tensor(2.,requires_grad=True) #par d√©faut, requires_grad=False\n",
    "y=a*x\n",
    "z=y**2\n",
    "\n",
    "\n",
    "print(f\"x.grad:{grad(z,[x,a])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J529jL1weBR3"
   },
   "source": [
    "Ce qui revient exactement au m√™me que de faire un `z.backward()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjgmaLFvfG0A"
   },
   "source": [
    "### Pour calculer une d√©riv√©e seconde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "uTDdPFwmM90e",
    "outputId": "e3e4aded-7060-4892-88fb-d06ccd460e42"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(10.,requires_grad=True)\n",
    "y=torch.tensor(12.,requires_grad=True)\n",
    "\n",
    "u=x**2+y\n",
    "u_x=grad(u,x,create_graph=True)[0]\n",
    "\n",
    "u_xx=grad(u_x,x)[0]\n",
    "\n",
    "u_xx.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPRUPlxVTNot"
   },
   "source": [
    "La fonction `grad` contient aussi une option `retain_grad` qui permet d'utiliser plusieurs fois le bout de graph que cette fonction √† cr√©er."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGluZZBOt9zT"
   },
   "source": [
    "### Quelques particularit√©s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2HXZmZXua2Q"
   },
   "source": [
    "Remarquons que la fonction grad renvoie un message d'erreur quand la source n'est pas reli√© √† la cible. Sauf si l'on met l'option `allow_unused=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "4UhVrGxOs9jE",
    "outputId": "f7b85a8e-0ee5-4b8d-d43c-4f2c05c394ac"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(5.,requires_grad=True)\n",
    "y=torch.tensor(6.,requires_grad=True)\n",
    "z=y**2\n",
    "\n",
    "grad(z,x,allow_unused=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdefAWCMCDIS"
   },
   "source": [
    "Pour avoir 0 (comme on ferait en math) et pas 'None', on fait:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "RKd22Bmoxm7h",
    "outputId": "f3e85ac5-25fc-4618-bb51-0c3aecae02f5"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor(5.,requires_grad=True)\n",
    "y=torch.tensor(6.,requires_grad=True)\n",
    "z=y**2\n",
    "\n",
    "grad(z,x,allow_unused=True,materialize_grads=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6IybJmWCvK6"
   },
   "source": [
    "Attention quand on d√©rive plusieurs fois un polyn√¥me: quand la d√©riv√©e s'annule, √ßa plante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "i_ltRDzgtMJM",
    "outputId": "818f1ec8-4e21-4734-a65d-e9b9fdc42625"
   },
   "outputs": [],
   "source": [
    "x=torch.tensor([5.,6],requires_grad=True)\n",
    "u=3*x**2\n",
    "u_x=grad(u.sum(),x,create_graph=True)[0]\n",
    "u_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "tVDILc7vvRM9",
    "outputId": "99b9f057-25d3-4e73-aa9d-67f148f30053"
   },
   "outputs": [],
   "source": [
    "u_xx=grad(u_x.sum(),x,create_graph=True)[0]\n",
    "u_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730760462524,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "WsPvQGo1vZMk",
    "outputId": "5b43995d-3161-4452-c3f2-4e6655bf7cb4"
   },
   "outputs": [],
   "source": [
    "u_xxx=grad(u_xx.sum(),x,create_graph=True)[0]\n",
    "u_xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VUP_krFC32n"
   },
   "source": [
    "L'erreur ci-dessous vient du r√©sultat ci-dessus: pour le tenseur constant 0, torch a oubli√© de mettre une `gard_fn`. La d√©rivation ne peut plus continuer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730760462525,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "LUq7UALkv_hD",
    "outputId": "8cc031e2-0e93-440d-b271-52a63096daef"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    u_xxxx=grad(u_xxx.sum(),x,create_graph=True)[0]\n",
    "    print(u_xxxx)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oN9-NQYqNFvp"
   },
   "source": [
    "## Plong√©e profonde dans torch\n",
    "\n",
    "Je vous conseille vivement de regarder la vid√©o suivante qui d√©cortique la technique de diff√©rentiation automatique de torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGkT_zPkJAga"
   },
   "source": [
    "[vid√©o expliquant la m√©canique des tenseurs en torch](https://www.youtube.com/watch?v=MswxJw-8PvE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egypBxISAHhx"
   },
   "source": [
    "## Le jeu des ratages de gradient\n",
    "\n",
    "\n",
    "***√Ä vous:*** Voici plusieurs programmes o√π le calcul du gradient √©choue. Trouvez l'explication. Debuguez quand c'est possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lurelkt2srpF"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67RqfwBpoCZn"
   },
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730760462525,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "OEQQzmgyrVQd",
    "outputId": "b79474f3-84a4-4bf1-f78c-6028e4ff3f79"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(2.,requires_grad=True)\n",
    "y = torch.tensor(3.,requires_grad=True)\n",
    "\n",
    "z = y * y\n",
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itHdHQetoZoh"
   },
   "source": [
    "#### ‚ô°‚ô°\n",
    "\n",
    "Explication:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUFR-MhkoE_V"
   },
   "source": [
    "Pas de debug possible, c'est un probl√®me de conception du programme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7RcV3F-oHJQ"
   },
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730760462525,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "RF_U4g2RFXHD",
    "outputId": "0a8ab46c-f271-4fd4-85be-de8500b098b8"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    x = torch.tensor(2.,requires_grad=True)\n",
    "    y = x**2+1\n",
    "    z1 = y**3\n",
    "    z2 = (y-3)**3\n",
    "    z1.backward()\n",
    "    z2.backward()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJQeHsAaoRc6"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1730760462765,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "01Hk4DGAnusg",
    "outputId": "ffad3743-f1b6-4d83-b6c7-c61301a940e4"
   },
   "outputs": [],
   "source": [
    "DEBUG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ubpjFEcoOAc"
   },
   "source": [
    "    x.grad:348.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWT62hU6gtPD"
   },
   "source": [
    "### C\n",
    "\n",
    "Ci-dessous, on appelle deux fois la m√©thode `backward()`, et pourtant pas d'erreur pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dz7rTsEHGC7D"
   },
   "outputs": [],
   "source": [
    "y = torch.tensor(2.,requires_grad=True)\n",
    "z1 = y**3\n",
    "z2 = (y-3)**3\n",
    "z1.backward()\n",
    "z2.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4ydJ9eqUYIi"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCYKA7MVUaA5"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uAzbmmlgwnd"
   },
   "source": [
    "### D\n",
    "\n",
    "l'erreur de base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1730760462765,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "lPHH9t-OsATl",
    "outputId": "a972ea14-7f33-4ce5-9dda-1a332973875e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    x = torch.tensor(2.)\n",
    "    y = x**2+1\n",
    "    y.backward()\n",
    "    x.requires_grad_(True)\n",
    "    print(x.grad)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSymnQbCpZNn"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1730760462765,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "9zeq_tW-paiH",
    "outputId": "e15ec00f-364e-45bc-c344-80f665404391"
   },
   "outputs": [],
   "source": [
    "Debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eqd_9dUBq9iN"
   },
   "source": [
    "    tensor(4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWn8-7ojpjYw"
   },
   "source": [
    "### E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1730760512989,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "ZPexJat_rkBJ",
    "outputId": "81e0befa-2ec8-4e2f-bebf-b6f7dd0c5882"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(2.,requires_grad=True)\n",
    "#on veut calculer de gradient de y par rapport √† x=2, puis x=3, puis ...\n",
    "for epoch in range(3):\n",
    "    y = x**2+1\n",
    "    y.backward()\n",
    "    print(x.grad)\n",
    "    #on augmente la valeur de x\n",
    "    x = x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-woT-M9qNsm"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1730760575886,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "9QUpqJEdqMrE",
    "outputId": "513e68ba-a3fd-4d91-c461-b3f74fe4148d"
   },
   "outputs": [],
   "source": [
    "DEBUG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlNiXmibq43n"
   },
   "source": [
    "    tensor(4.)\n",
    "    tensor(6.)\n",
    "    tensor(8.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPdHVvakrDiT"
   },
   "source": [
    "### F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1730760589254,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "qaXFiZV6rGEy",
    "outputId": "9af4a45f-90f1-44b1-f1e8-f40be16b87af"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    a=torch.tensor(2,requires_grad=True)\n",
    "    b=a**3\n",
    "    b.backward()\n",
    "    print(f\"a.grad:{a.grad}\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2Ir9BuirqIz"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1730760596758,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "iCKTCrq-rleh",
    "outputId": "6944f52a-0cba-44ff-ed7b-8ce30490dbcd"
   },
   "outputs": [],
   "source": [
    " DEBUG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scRME5HKr58Z"
   },
   "source": [
    "    a.grad:12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rsjZVlD0s8Z0"
   },
   "source": [
    "### G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1730760599654,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "eBFkyGdhuCn1",
    "outputId": "625064db-39d5-4021-d585-015f5f859d01"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    A=torch.ones([2,2],requires_grad=True)\n",
    "    B=A**2\n",
    "    B.backward()\n",
    "    print(A.grad)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z3OSrcwVSh7"
   },
   "source": [
    "#### ‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 233,
     "status": "ok",
     "timestamp": 1730760601244,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "h5knil8YuRvc",
    "outputId": "577eca64-0823-452f-dc72-99d89de3a8dc"
   },
   "outputs": [],
   "source": [
    "DEBUG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmVjwZWEGFXc"
   },
   "source": [
    "## Petits exos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7j4pNXtYPGM"
   },
   "source": [
    "### Dessin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvMssCYiV4AX"
   },
   "source": [
    "#### ‚ô°‚ô°‚ô°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-9K5zULWLHA"
   },
   "source": [
    "D√©ssinez le graph de calcul suivant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1730760689311,
     "user": {
      "displayName": "vincent vigon",
      "userId": "09456169185020192907"
     },
     "user_tz": -60
    },
    "id": "0FNoKz1CZIuN",
    "outputId": "c615aadb-870b-4314-9cdb-b381ce854587"
   },
   "outputs": [],
   "source": [
    "x1 = torch.tensor(2.)\n",
    "x2 = torch.tensor(0.)\n",
    "x3 = torch.tensor(1.)\n",
    "y = (x1+x2)**2\n",
    "z = torch.exp(y*x3)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtRwVOXBWWL2"
   },
   "source": [
    "    tensor(54.5981)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJlB2KQMkZt6"
   },
   "source": [
    "### Des calculs √† la main puis √† la machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7PMylAdiQBY"
   },
   "source": [
    "Consid√©rons\n",
    "$$\n",
    "z=y^2\n",
    "$$\n",
    "o√π\n",
    "$$\n",
    "y = {x_1 \\over x_2}\n",
    "$$\n",
    "avec $x_1=2$ et $x_2=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttoR-AVTgqPH"
   },
   "source": [
    "---\n",
    "\n",
    "On a:\n",
    "$$\n",
    "{\\partial z \\over \\partial y} = 2y \\text{ en } y={x1\\over x2} =2\n",
    "$$\n",
    "Donc\n",
    "$$\n",
    "{\\partial z \\over \\partial y} =4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XswqBD7hUGe"
   },
   "source": [
    "---\n",
    "On a:\n",
    "$$\n",
    "{\\partial y \\over \\partial x_2} = -{x_1\\over x_2^2} = -2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdOoZVFDjdDg"
   },
   "source": [
    "---\n",
    "On a:\n",
    "$$\n",
    "{\\partial z \\over \\partial x_2} = ...\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GU9DI_l9khIe"
   },
   "source": [
    "#### ‚ô°‚ô°\n",
    "\n",
    "***√Ä vous:*** calculez ces d√©riv√©es avec torch en ne cr√©ant qu'un seul graph de calcul."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
