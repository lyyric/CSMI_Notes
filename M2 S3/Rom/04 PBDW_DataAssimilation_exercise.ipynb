{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd17df5d",
   "metadata": {},
   "source": [
    "# Lab: PBDW data assimilation on a 1D diffusion model\n",
    "\n",
    "**Goal.** Implement and test the core pieces of the *Parametrized-Background Data-Weak (PBDW)* method:\n",
    "- build a reduced **background space** $\\mathcal{Z}_N$ from snapshots (POD),\n",
    "- build an **observable space** $\\mathcal{U}_M$ from sensors (Riesz representers),\n",
    "- implement **offline** (assemble the saddle-point system) and **online** (reconstruct from data),\n",
    "- study the effects of **noise**, **number of sensors**, and **sensor placement** (GEIM).\n",
    "\n",
    "**How to use this notebook.** Work top-to-bottom. Cells marked **TODO** must be completed for the notebook to run.\n",
    "\n",
    "We use a uniform grid and the $V=L^2(0,1)$ inner product:\n",
    "$$\n",
    "(u,v)_V \\approx \\Delta x\\,u^Tv.\n",
    "$$\n",
    "Sensors are weighted averages $y_m=\\int w_m u$; discretely\n",
    "`observe(u, W, dx) = dx*(W @ u)`.\n",
    "\n",
    "A complete reference implementation is provided in the companion notebook `PBDW_DataAssimilation_fixed.ipynb`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f0c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import solve, lstsq\n",
    "from scipy.sparse import diags\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Callable\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab83ce0",
   "metadata": {},
   "source": [
    "## 1. Problem Setup: 1D Diffusion Equation\n",
    "\n",
    "We consider:\n",
    "$$-\\nabla \\cdot (\\kappa(x;\\mu) \\nabla u) = f(x), \\quad x \\in [0,1]$$\n",
    "with $u(0) = u(1) = 0$ and parametrized conductivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6517bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain discretization\n",
    "Nq = 200\n",
    "x = np.linspace(0, 1, Nq)\n",
    "dx = x[1] - x[0]\n",
    "\n",
    "# Parameter space: mu in [0.5, 2.0]^3 for conductivity variations\n",
    "P = 3  # Number of parameters\n",
    "mu_min = np.array([0.5, 0.5, 0.5])\n",
    "mu_max = np.array([2.0, 2.0, 2.0])\n",
    "\n",
    "def build_conductivity(mu):\n",
    "    \"\"\"Build conductivity field κ(x;μ) = 1 + sum_i (μ_i - 1) * φ_i(x)\"\"\"\n",
    "    centers = np.array([0.25, 0.5, 0.75])\n",
    "    width = 0.2\n",
    "    kappa = np.ones(Nq)\n",
    "    for i in range(P):\n",
    "        phi_i = np.exp(-((x - centers[i])**2) / (2 * width**2))\n",
    "        kappa += (mu[i] - 1) * phi_i\n",
    "    return kappa\n",
    "\n",
    "def solve_diffusion(kappa):\n",
    "    \"\"\"Solve -∇·(κ∇u) = f with finite differences\"\"\"\n",
    "    f = 10 * np.sin(2 * np.pi * x)  # Source term\n",
    "    \n",
    "    # Stiffness matrix\n",
    "    kappa_half = 0.5 * (kappa[:-1] + kappa[1:])\n",
    "    N_int = Nq - 2\n",
    "    \n",
    "    diag = (kappa_half[1:N_int+1] + kappa_half[0:N_int]) / dx**2\n",
    "    upper = -kappa_half[1:N_int] / dx**2\n",
    "    lower = -kappa_half[1:N_int] / dx**2\n",
    "    \n",
    "    A = diags([lower, diag, upper], [-1, 0, 1], format='csr')\n",
    "    u_int = spsolve(A, f[1:-1])\n",
    "    \n",
    "    u = np.zeros(Nq)\n",
    "    u[1:-1] = u_int\n",
    "    return u\n",
    "\n",
    "def sample_parameters(n):\n",
    "    \"\"\"Sample n parameters uniformly in parameter space\"\"\"\n",
    "    return mu_min + np.random.rand(n, P) * (mu_max - mu_min)\n",
    "\n",
    "# Test\n",
    "mu_test = np.array([1.5, 0.8, 1.2])\n",
    "kappa_test = build_conductivity(mu_test)\n",
    "u_test = solve_diffusion(kappa_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "axes[0].plot(x, kappa_test, 'b-', linewidth=2)\n",
    "axes[0].set_xlabel('x'); axes[0].set_ylabel('κ(x)')\n",
    "axes[0].set_title(f'Conductivity (μ={mu_test})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(x, u_test, 'r-', linewidth=2)\n",
    "axes[1].set_xlabel('x'); axes[1].set_ylabel('u(x)')\n",
    "axes[1].set_title('Solution')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff786f",
   "metadata": {},
   "source": [
    "## 2. Background space $\\mathcal{Z}_N$ via POD\n",
    "\n",
    "We generate a *training set* of solutions $\\{u(\\mu^i)\\}_{i=1}^{n_{\\mathrm{train}}}$ of the parametrized PDE\n",
    "and compute a Proper Orthogonal Decomposition (POD) basis.\n",
    "\n",
    "Let `S` be the snapshot matrix whose columns are the training solutions. The POD basis is obtained from an SVD\n",
    "`S = U Σ Vᵀ`; we set\n",
    "$$\n",
    "\\mathcal{Z}_N = \\mathrm{span}\\{U_1,\\dots,U_N\\}.\n",
    "$$\n",
    "\n",
    "This space represents what the model can already explain (anticipated physics).\n",
    "\n",
    "\n",
    "**TODO (implementation).** In the code cell below:\n",
    "1. Build the snapshot matrix `S`.\n",
    "2. Compute an SVD and select a POD basis `Z`.\n",
    "3. Plot singular values and the cumulative energy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24660d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training snapshots\n",
    "n_train = 100\n",
    "mu_train = sample_parameters(n_train)\n",
    "\n",
    "# TODO 2.1: Build the snapshot matrix S (shape: Nq × n_train).\n",
    "# Each column i should be u(mu_train[i]).\n",
    "S = np.zeros((Nq, n_train))\n",
    "for i, mu in enumerate(mu_train):\n",
    "    # kappa = ...\n",
    "    # S[:, i] = ...\n",
    "    raise NotImplementedError(\"TODO 2.1: fill snapshot generation loop\")\n",
    "\n",
    "# TODO 2.2: POD via SVD: S = U Σ Vᵀ\n",
    "U_pod, sigma, Vt = np.linalg.svd(S, full_matrices=False)\n",
    "\n",
    "# TODO 2.3: Choose N and define the background basis Z = U[:, :N]\n",
    "N = 8\n",
    "Z = U_pod[:, :N]\n",
    "\n",
    "# TODO 2.4: Compute and plot the cumulative POD energy\n",
    "energy = np.cumsum(sigma**2) / np.sum(sigma**2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].semilogy(sigma[:30], 'bo-')\n",
    "axes[0].axvline(N, color='r', linestyle='--', label=f'N={N}')\n",
    "axes[0].set_xlabel('Mode'); axes[0].set_ylabel('Singular value')\n",
    "axes[0].set_title('POD singular values')\n",
    "axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(energy[:30], 'go-')\n",
    "axes[1].axvline(N, color='r', linestyle='--', label=f'N={N}: {energy[N-1]:.2%}')\n",
    "axes[1].axhline(0.99, color='gray', linestyle=':')\n",
    "axes[1].set_xlabel('Modes'); axes[1].set_ylabel('Cumulative energy')\n",
    "axes[1].set_title('POD energy')\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Background space Z_N: N={N} modes, {energy[N-1]:.2%} energy captured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eade30",
   "metadata": {},
   "source": [
    "## 3. Sensors and observable space $\\mathcal{U}_M$\n",
    "\n",
    "A *sensor* is a continuous linear functional $\\ell_m: V \\to \\mathbb{R}$.\n",
    "In this notebook we use **localized averages**\n",
    "$$\n",
    "\\ell_m(v) = \\int_0^1 w_m(x)\\,v(x)\\,dx,\n",
    "$$\n",
    "where $w_m$ is a normalized bump (Gaussian/box). With the $L^2$ inner product, the **Riesz representer**\n",
    "satisfying $(q_m,v)_V = \\ell_m(v)$ is simply $q_m = w_m$. Therefore\n",
    "$$\n",
    "\\mathcal{U}_M = \\mathrm{span}\\{q_1,\\dots,q_M\\}.\n",
    "$$\n",
    "\n",
    "Discretization (uniform grid):\n",
    "- `W` is the matrix of sensor *densities* $w_m(x_i)$ (rows).\n",
    "- Measurements are computed by quadrature: `y = observe(u, W, dx) = dx*(W @ u)`.\n",
    "- The matrix of Riesz representers is `Q = W.T` (columns $q_m$).\n",
    "\n",
    "\n",
    "**TODO (implementation).** In the code cell below:\n",
    "1. Implement `build_sensor_matrix` for `dirac`, `gaussian`, and `box` sensors.\n",
    "2. Implement `observe(u, W, dx)`.\n",
    "3. Implement `build_riesz_representers(W, dx)` for the L2 inner product.\n",
    "\n",
    "*Hint:* define sensors as **densities** `w_m` with `dx*np.sum(w_m)=1`. Then `observe(u,W,dx)=dx*(W@u)` approximates $\\int w_m u$. For `dirac`, choose `w_m = e_i/dx` so the observation is approximately `u(x_i)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e999df",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SensorConfig:\n",
    "    \"\"\"Configuration for sensor setup\"\"\"\n",
    "    positions: np.ndarray  # Sensor center positions\n",
    "    width: float           # Sensor width (for Gaussian/box)\n",
    "    type: str              # 'dirac', 'gaussian', 'box'\n",
    "\n",
    "def build_sensor_matrix(x: np.ndarray, config: SensorConfig) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build sensor density matrix W (M × Nq), where row m approximates w_m(x_i).\n",
    "\n",
    "    Convention used throughout the notebook:\n",
    "      y = observe(u, W, dx) = dx*(W @ u) ≈ ∫ w_m(x) u(x) dx.\n",
    "    \"\"\"\n",
    "    M = len(config.positions)\n",
    "    Nq = len(x)\n",
    "    dx = x[1] - x[0]\n",
    "    W = np.zeros((M, Nq))\n",
    "\n",
    "    # TODO 3.1: fill W row-by-row depending on config.type.\n",
    "    # - 'dirac': choose the closest grid index i and set W[m, i] = 1/dx\n",
    "    # - 'gaussian': set W[m, :] proportional to exp(-(x-pos)^2/(2*width^2)) and normalize so dx*sum = 1\n",
    "    # - 'box': set W[m, mask]=const on |x-pos|<=width/2 and normalize so dx*sum = 1\n",
    "    raise NotImplementedError(\"TODO 3.1: implement build_sensor_matrix\")\n",
    "\n",
    "def observe(u: np.ndarray, W: np.ndarray, dx: float) -> np.ndarray:\n",
    "    \"\"\"Return measurements y_m = ∫ w_m(x) u(x) dx via quadrature.\"\"\"\n",
    "    # TODO 3.2\n",
    "    raise NotImplementedError(\"TODO 3.2: implement observe\")\n",
    "\n",
    "def build_riesz_representers(W: np.ndarray, dx: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return Q (Nq × M) whose columns are the Riesz representers q_m in V.\n",
    "\n",
    "    For V=L2 and ell_m(v)=∫ w_m v, we have q_m = w_m.\n",
    "    \"\"\"\n",
    "    # TODO 3.3\n",
    "    raise NotImplementedError(\"TODO 3.3: implement build_riesz_representers\")\n",
    "\n",
    "# Configure sensors (you may change M, type, width later)\n",
    "M = 15\n",
    "sensor_positions = np.linspace(0.05, 0.95, M)\n",
    "sensor_config = SensorConfig(positions=sensor_positions, width=0.05, type='gaussian')\n",
    "\n",
    "# Build sensor matrix and Riesz representers\n",
    "W = build_sensor_matrix(x, sensor_config)\n",
    "Q = build_riesz_representers(W, dx)\n",
    "\n",
    "print(f\"Sensor matrix W: {W.shape}\")\n",
    "print(f\"Observable space Q (Riesz representers): {Q.shape}\")\n",
    "\n",
    "# Visualize a few sensors (plot quadrature weights w_m * dx)\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "for m in range(0, M, 3):\n",
    "    ax.plot(x, W[m, :] * dx, label=f'Sensor {m+1}' if m < 6 else None)\n",
    "ax.scatter(sensor_positions, np.zeros(M), c='red', s=50, zorder=5, label='Sensor centers')\n",
    "ax.set_xlabel('x'); ax.set_ylabel('quadrature weight')\n",
    "ax.set_title(f'{sensor_config.type.capitalize()} sensors (M={M})')\n",
    "ax.legend(); ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09347121",
   "metadata": {},
   "source": [
    "## 4. PBDW formulation (saddle-point system)\n",
    "\n",
    "We seek an estimator of the form\n",
    "$$\n",
    "u_{N,M} = z_N + \\eta_M, \\qquad z_N \\in \\mathcal{Z}_N,\\ \\eta_M \\in \\mathcal{U}_M,\n",
    "$$\n",
    "where $\\mathcal{Z}_N$ is a reduced **background/model** space (POD) and\n",
    "$\\mathcal{U}_M$ is the **observable/update** space spanned by the Riesz representers $\\{q_m\\}_{m=1}^M$.\n",
    "\n",
    "With $\\ell_m(v) = (q_m, v)_V$ and data $y_m^{\\mathrm{obs}} = \\ell_m(u^{\\mathrm{true}})$, the (noise-free) PBDW conditions are:\n",
    "\n",
    "- **Data matching:** $(q_m, u_{N,M})_V = y_m^{\\mathrm{obs}}$, for $m=1,\\dots,M$.\n",
    "- **Minimal update:** $(\\eta_M, z)_V = 0$ for all $z \\in \\mathcal{Z}_N$ (selects the smallest correction in the $V$-norm).\n",
    "\n",
    "In coefficient form, with bases $Z=[z_1,\\dots,z_N]$ and $Q=[q_1,\\dots,q_M]$,\n",
    "this yields the saddle-point linear system\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "A & B \\\\\n",
    "B^T & 0\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\eta \\\\ z\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "y^{\\mathrm{obs}} \\\\ 0\n",
    "\\end{pmatrix},\n",
    "\\qquad\n",
    "A = (Q,Q)_V,\\ \\ B = (Q,Z)_V.\n",
    "$$\n",
    "\n",
    "The *inf-sup constant* $\\beta_{N,M}$ (computed below) controls stability and appears in a standard bound\n",
    "$\\|u^{\\mathrm{true}}-u_{N,M}\\|_V \\le (1+1/\\beta_{N,M})\\,\\inf_{z\\in\\mathcal{Z}_N}\\|u^{\\mathrm{true}}-z\\|_V$ in the idealized setting.\n",
    "\n",
    "\n",
    "**TODO (implementation).** Implement the offline and online routines in the next code cell. Your implementation should:\n",
    "- build A and B using the L2 inner product with quadrature weight dx,\n",
    "- solve the saddle-point system,\n",
    "- (optional but recommended) compute the inf-sup constant β.\n",
    "\n",
    "*Sanity checks (noise-free):* after reconstruction, `observe(u_rec, W, dx)` should match `y_obs` up to ~1e-12.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebd4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PBDWModel:\n",
    "    \"\"\"Offline quantities for PBDW\"\"\"\n",
    "    Z: np.ndarray          # Background basis (Nq × N)\n",
    "    Q: np.ndarray          # Riesz representers (Nq × M)\n",
    "    W: np.ndarray          # Sensor densities (M × Nq)\n",
    "    A: np.ndarray          # Gramian in U_M: A = (Q,Q)_V\n",
    "    B: np.ndarray          # Cross Gramian:  B = (Q,Z)_V\n",
    "    K: np.ndarray          # Saddle-point matrix\n",
    "    beta: float            # Inf-sup constant (stability)\n",
    "\n",
    "def pbdw_offline(Z: np.ndarray, Q: np.ndarray, W: np.ndarray, dx: float) -> PBDWModel:\n",
    "    \"\"\"\n",
    "    TODO 4.1: Offline stage.\n",
    "\n",
    "    Use the discrete L2 inner product (u,v)_V ≈ dx * u^T v.\n",
    "\n",
    "    You should build:\n",
    "      A = dx * Q.T @ Q          (M×M)\n",
    "      B = dx * Q.T @ Z          (M×N)\n",
    "      K = [[A, B], [B.T, 0]]    ((M+N)×(M+N))\n",
    "\n",
    "    Optional: compute the inf-sup constant beta using a normalized SVD:\n",
    "      beta = σ_min( A^{-1/2} B (Z^T M Z)^{-1/2} ), with M = dx*I.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"TODO 4.1: implement pbdw_offline\")\n",
    "\n",
    "def pbdw_online(model: PBDWModel, y_obs: np.ndarray, lam: float = 0.0):\n",
    "    \"\"\"\n",
    "    TODO 4.2: Online reconstruction.\n",
    "\n",
    "    Noise-free case: solve K [eta_coef; z_coef] = [y_obs; 0].\n",
    "\n",
    "    Noisy case (Tikhonov): one practical option is to modify the (1,1) block:\n",
    "      A -> A + lam*A\n",
    "    (i.e., add lam times the V-norm penalty on η).\n",
    "\n",
    "    Return:\n",
    "      u_rec = Q @ eta_coef + Z @ z_coef\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"TODO 4.2: implement pbdw_online\")\n",
    "\n",
    "# Build PBDW model (will work after TODOs are completed)\n",
    "model = pbdw_offline(Z, Q, W, dx)\n",
    "\n",
    "print(f\"PBDW Model:\")\n",
    "print(f\"  Background space dimension: N = {Z.shape[1]}\")\n",
    "print(f\"  Observable space dimension: M = {Q.shape[1]}\")\n",
    "print(f\"  Inf-sup constant: β = {model.beta:.4f}\")\n",
    "print(f\"  Stability factor (1 + 1/β): {1 + 1/model.beta:.2f}\")\n",
    "print(f\"  Condition number of K: {np.linalg.cond(model.K):.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf211d6",
   "metadata": {},
   "source": [
    "## 5. Test: Noise-Free State Estimation\n",
    "\n",
    "**Questions.**\n",
    "1. Why do we add a *model error* term? What should PBDW do with it?\n",
    "2. Compare the PBDW reconstruction with the best approximation in $\\mathcal{Z}_N$. When is PBDW strictly better?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \"true\" state (with model error!)\n",
    "mu_true = np.array([1.3, 0.7, 1.8])  # True parameters\n",
    "kappa_true = build_conductivity(mu_true)\n",
    "u_true = solve_diffusion(kappa_true)\n",
    "\n",
    "# Add model error: true state has additional unmodeled component\n",
    "model_error = 0.1 * np.sin(5 * np.pi * x) * np.exp(-10*(x-0.5)**2)\n",
    "u_true_with_error = u_true + model_error\n",
    "\n",
    "# Generate noise-free observations\n",
    "y_obs = observe(u_true_with_error, W, dx)\n",
    "\n",
    "# PBDW reconstruction\n",
    "u_pbdw, eta_coef, z_coef = pbdw_online(model, y_obs)\n",
    "\n",
    "# Also compute best approximation in Z_N (projection)\n",
    "z_best_coef = np.linalg.lstsq(Z, u_true_with_error, rcond=None)[0]\n",
    "u_best = Z @ z_best_coef\n",
    "\n",
    "# Errors\n",
    "err_pbdw = np.linalg.norm(u_true_with_error - u_pbdw) * np.sqrt(dx)\n",
    "err_best = np.linalg.norm(u_true_with_error - u_best) * np.sqrt(dx)\n",
    "err_ratio = err_pbdw / err_best\n",
    "\n",
    "print(f\"Noise-free reconstruction:\")\n",
    "print(f\"  ||u_true - u_pbdw||_V = {err_pbdw:.6e}\")\n",
    "print(f\"  ||u_true - u_best||_V = {err_best:.6e}  (best in Z_N)\")\n",
    "print(f\"  Ratio: {err_ratio:.2f}  (theory: ≤ {1 + 1/model.beta:.2f})\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(x, u_true_with_error, 'k-', linewidth=2, label='True (with model error)')\n",
    "axes[0].plot(x, u_pbdw, 'r--', linewidth=2, label='PBDW')\n",
    "axes[0].plot(x, u_best, 'b:', linewidth=2, label='Best in $\\mathcal{Z}_N$')\n",
    "axes[0].scatter(sensor_positions, np.full(M, u_true_with_error.min()), \n",
    "                c='green', marker='^', s=50, label='Sensors')\n",
    "axes[0].set_xlabel('x'); axes[0].set_ylabel('u(x)')\n",
    "axes[0].set_title('State Estimation')\n",
    "axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(x, np.abs(u_true_with_error - u_pbdw), 'r-', linewidth=2, label='PBDW error')\n",
    "axes[1].plot(x, np.abs(u_true_with_error - u_best), 'b--', linewidth=2, label='Best approx error')\n",
    "axes[1].set_xlabel('x'); axes[1].set_ylabel('|error|')\n",
    "axes[1].set_title('Pointwise Errors')\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Decomposition: z + eta\n",
    "z_component = Z @ z_coef\n",
    "eta_component = Q @ eta_coef\n",
    "axes[2].plot(x, z_component, 'b-', linewidth=2, label='$z_N$ (model)')\n",
    "axes[2].plot(x, eta_component, 'g-', linewidth=2, label='$\\eta_M$ (correction)')\n",
    "axes[2].plot(x, model_error, 'k--', linewidth=1, label='True model error')\n",
    "axes[2].set_xlabel('x'); axes[2].set_ylabel('Component')\n",
    "axes[2].set_title('PBDW Decomposition')\n",
    "axes[2].legend(); axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a0afa",
   "metadata": {},
   "source": [
    "## 6. Test: Noisy Observations\n",
    "\n",
    "With noisy observations $y_m^{\\text{obs}} = \\ell_m(u^{\\text{true}}) + \\epsilon_m$, we use Tikhonov regularization.\n",
    "\n",
    "**Questions.**\n",
    "1. What happens when λ=0 and the data are noisy?\n",
    "2. How would you choose λ as a function of the noise level δ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to observations\n",
    "noise_levels = [0.0, 1e-3, 5e-3, 1e-2, 5e-2]\n",
    "\n",
    "results = []\n",
    "for delta in noise_levels:\n",
    "    # Noisy observations\n",
    "    noise = delta * np.random.randn(M)\n",
    "    y_noisy = y_obs + noise\n",
    "    \n",
    "    # Try different regularization parameters\n",
    "    if delta == 0:\n",
    "        lambdas = [0.0]\n",
    "    else:\n",
    "        lambdas = [0.0, delta**2, delta, delta*10]\n",
    "    \n",
    "    for lam in lambdas:\n",
    "        u_rec, _, _ = pbdw_online(model, y_noisy, lam=lam)\n",
    "        err = np.linalg.norm(u_true_with_error - u_rec) * np.sqrt(dx)\n",
    "        results.append((delta, lam, err))\n",
    "\n",
    "# Display results\n",
    "print(\"PBDW with noisy observations:\")\n",
    "print(f\"{'Noise δ':<12} {'λ':<12} {'Error ||u-u_rec||':<20}\")\n",
    "print(\"-\" * 50)\n",
    "for delta, lam, err in results:\n",
    "    print(f\"{delta:<12.1e} {lam:<12.1e} {err:<20.6e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize effect of noise and regularization\n",
    "delta = 1e-2\n",
    "noise = delta * np.random.randn(M)\n",
    "y_noisy = y_obs + noise\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "lambdas_plot = [0.0, delta, delta*10]\n",
    "titles = ['No regularization', f'λ = δ = {delta}', f'λ = 10δ = {10*delta}']\n",
    "\n",
    "for ax, lam, title in zip(axes, lambdas_plot, titles):\n",
    "    u_rec, _, _ = pbdw_online(model, y_noisy, lam=lam)\n",
    "    err = np.linalg.norm(u_true_with_error - u_rec) * np.sqrt(dx)\n",
    "    \n",
    "    ax.plot(x, u_true_with_error, 'k-', linewidth=2, label='True')\n",
    "    ax.plot(x, u_rec, 'r--', linewidth=2, label=f'PBDW (err={err:.4f})')\n",
    "    ax.set_xlabel('x'); ax.set_ylabel('u(x)')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(); ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a8f933",
   "metadata": {},
   "source": [
    "## 7. Overdetermined Case: $M > N$\n",
    "\n",
    "Using more sensors than basis functions improves robustness.\n",
    "\n",
    "**Question.** How does increasing M affect (i) β, (ii) the condition number, and (iii) the reconstruction error?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different M values\n",
    "M_values = [8, 12, 20, 30, 50]\n",
    "delta = 1e-2\n",
    "\n",
    "errors_vs_M = []\n",
    "betas_vs_M = []\n",
    "\n",
    "for M_test in M_values:\n",
    "    # New sensor configuration\n",
    "    positions = np.linspace(0.05, 0.95, M_test)\n",
    "    config = SensorConfig(positions=positions, width=0.05, type='gaussian')\n",
    "    W_test = build_sensor_matrix(x, config)\n",
    "    Q_test = build_riesz_representers(W_test, dx)\n",
    "    \n",
    "    # Build PBDW model\n",
    "    model_test = pbdw_offline(Z, Q_test, W_test, dx)\n",
    "    betas_vs_M.append(model_test.beta)\n",
    "    \n",
    "    # Noisy observations\n",
    "    y_test = observe(u_true_with_error, W_test, dx)\n",
    "    y_noisy_test = y_test + delta * np.random.randn(M_test)\n",
    "    \n",
    "    # Reconstruction with optimal lambda ~ delta\n",
    "    u_rec, _, _ = pbdw_online(model_test, y_noisy_test, lam=delta)\n",
    "    err = np.linalg.norm(u_true_with_error - u_rec) * np.sqrt(dx)\n",
    "    errors_vs_M.append(err)\n",
    "    \n",
    "    print(f\"M={M_test:3d}: β={model_test.beta:.4f}, error={err:.6e}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(M_values, betas_vs_M, 'bo-', markersize=8)\n",
    "axes[0].axhline(0, color='r', linestyle='--')\n",
    "axes[0].set_xlabel('M (number of sensors)')\n",
    "axes[0].set_ylabel('Inf-sup constant β')\n",
    "axes[0].set_title(f'Stability vs Sensors (N={N})')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].semilogy(M_values, errors_vs_M, 'rs-', markersize=8)\n",
    "axes[1].axhline(err_best, color='gray', linestyle=':', label='Best approx error')\n",
    "axes[1].set_xlabel('M (number of sensors)')\n",
    "axes[1].set_ylabel('Reconstruction error')\n",
    "axes[1].set_title(f'Error vs Sensors (noise δ={delta})')\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf6bb60",
   "metadata": {},
   "source": [
    "## 8. GEIM + PBDW: Combined Approach\n",
    "\n",
    "Use GEIM to select optimal sensors, then PBDW for state estimation.\n",
    "\n",
    "**Motivation**: Uniform sensor placement is simple but may not be optimal. GEIM provides a principled way to select sensors that maximize the inf-sup constant $\\beta_{N,M}$, leading to better stability and accuracy.\n",
    "\n",
    "**TODO (implementation).** Implement GEIM greedy sensor selection in the code cell below. You may follow the algorithm:\n",
    "1. Pick the snapshot with largest norm.\n",
    "2. Select the sensor (row of the dictionary) with maximal absolute response.\n",
    "3. Normalize to build the first GEIM basis function.\n",
    "4. Iterate on the worst-approximated snapshot.\n",
    "\n",
    "*Hint:* for this 1D demo, you may use the discrete dot product `A_dict @ v` as the sensor response.\n",
    "\n",
    "**Questions:**\n",
    "1. Why does GEIM select sensors at certain locations? How does this relate to the structure of the solution manifold?\n",
    "2. Compare the inf-sup constants for uniform vs GEIM sensors. Which is larger and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514740e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geim_sensor_selection(S: np.ndarray, A_dict: np.ndarray, M_geim: int, tol: float = 1e-10):\n",
    "    \"\"\"\n",
    "    TODO 8.1: GEIM greedy algorithm for sensor selection.\n",
    "\n",
    "    Args:\n",
    "        S: Snapshot matrix (Nq × n_train)\n",
    "        A_dict: Dictionary of candidate sensors (Ns × Nq) (rows = sensor densities)\n",
    "        M_geim: number of sensors to select\n",
    "\n",
    "    Returns:\n",
    "        J: list of selected sensor indices (length M_geim)\n",
    "        Q_geim: GEIM basis matrix (Nq × M_geim)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"TODO 8.1: implement GEIM greedy selection\")\n",
    "\n",
    "# Build sensor dictionary (candidate sensors)\n",
    "Ns_dict = 50\n",
    "dict_positions = np.linspace(0.02, 0.98, Ns_dict)\n",
    "dict_config = SensorConfig(positions=dict_positions, width=0.04, type='gaussian')\n",
    "A_dict = build_sensor_matrix(x, dict_config)\n",
    "\n",
    "# GEIM sensor selection\n",
    "M_geim = 15\n",
    "J_geim, Q_geim = geim_sensor_selection(S, A_dict, M_geim)\n",
    "\n",
    "print(f\"GEIM selected sensors: {J_geim}\")\n",
    "print(f\"Selected positions: {[f'{dict_positions[j]:.2f}' for j in J_geim]}\")\n",
    "\n",
    "# Build PBDW model with GEIM-selected sensors\n",
    "W_geim = A_dict[J_geim, :]\n",
    "Q_riesz_geim = build_riesz_representers(W_geim, dx)\n",
    "model_geim = pbdw_offline(Z, Q_riesz_geim, W_geim, dx)\n",
    "\n",
    "print(f\"GEIM+PBDW model:\")\n",
    "print(f\"  Inf-sup constant: β = {model_geim.beta:.4f}\")\n",
    "print(f\"  Stability factor: {1 + 1/model_geim.beta:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare uniform vs GEIM sensor selection\n",
    "delta = 1e-2\n",
    "\n",
    "# Uniform sensors (original)\n",
    "y_uniform = observe(u_true_with_error, W, dx) + delta * np.random.randn(M)\n",
    "u_uniform, _, _ = pbdw_online(model, y_uniform, lam=delta)\n",
    "err_uniform = np.linalg.norm(u_true_with_error - u_uniform) * np.sqrt(dx)\n",
    "\n",
    "# GEIM sensors\n",
    "y_geim = observe(u_true_with_error, W_geim, dx) + delta * np.random.randn(len(J_geim))\n",
    "u_geim_pbdw, _, _ = pbdw_online(model_geim, y_geim, lam=delta)\n",
    "err_geim = np.linalg.norm(u_true_with_error - u_geim_pbdw) * np.sqrt(dx)\n",
    "\n",
    "print(f\"Comparison (noise δ={delta}):\")\n",
    "print(f\"  Uniform sensors:  β={model.beta:.4f}, error={err_uniform:.6e}\")\n",
    "print(f\"  GEIM sensors:     β={model_geim.beta:.4f}, error={err_geim:.6e}\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(x, u_true_with_error, 'k-', linewidth=2, label='True')\n",
    "axes[0].plot(x, u_uniform, 'b--', linewidth=2, label=f'Uniform (err={err_uniform:.4f})')\n",
    "axes[0].plot(x, u_geim_pbdw, 'r--', linewidth=2, label=f'GEIM (err={err_geim:.4f})')\n",
    "axes[0].scatter(sensor_positions, np.zeros(M) + u_true_with_error.min()*0.9, \n",
    "                c='blue', marker='^', s=40, label='Uniform sensors')\n",
    "axes[0].scatter(dict_positions[J_geim], np.zeros(len(J_geim)) + u_true_with_error.min()*0.95, \n",
    "                c='red', marker='v', s=40, label='GEIM sensors')\n",
    "axes[0].set_xlabel('x'); axes[0].set_ylabel('u(x)')\n",
    "axes[0].set_title('PBDW: Uniform vs GEIM Sensors')\n",
    "axes[0].legend(); axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Error distribution\n",
    "axes[1].plot(x, np.abs(u_true_with_error - u_uniform), 'b-', linewidth=2, label='Uniform')\n",
    "axes[1].plot(x, np.abs(u_true_with_error - u_geim_pbdw), 'r-', linewidth=2, label='GEIM')\n",
    "axes[1].set_xlabel('x'); axes[1].set_ylabel('|error|')\n",
    "axes[1].set_title('Pointwise Errors')\n",
    "axes[1].legend(); axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b635d23",
   "metadata": {},
   "source": [
    "## 9. Exercise: Systematic Comparison of GEIM+PBDW vs Uniform+PBDW\n",
    "\n",
    "In this exercise, you will perform a comprehensive comparison between uniform sensor placement and GEIM-based optimal sensor selection within the PBDW framework.\n",
    "\n",
    "**TODO 9.1: Convergence study with increasing M**\n",
    "\n",
    "Study how the inf-sup constant $\\beta_{N,M}$ and reconstruction error evolve as the number of sensors $M$ increases, for both uniform and GEIM sensor placement.\n",
    "\n",
    "Complete the code cell below to:\n",
    "1. For $M \\in \\{N, N+2, N+4, \\ldots, 3N\\}$, compute:\n",
    "   - $\\beta_{N,M}$ for uniform sensors\n",
    "   - $\\beta_{N,M}$ for GEIM-selected sensors\n",
    "   - Reconstruction error (with noise $\\delta = 10^{-2}$) for both\n",
    "2. Plot $\\beta_{N,M}$ vs $M$ and error vs $M$ for both strategies\n",
    "\n",
    "**Questions:**\n",
    "1. For what value of $M$ does $\\beta_{N,M}$ stabilize? Is there a benefit to using $M \\gg N$?\n",
    "2. Does GEIM always outperform uniform placement? Under what conditions might uniform be sufficient?\n",
    "3. How does the theoretical bound $(1 + 1/\\beta_{N,M}) \\inf_{z \\in \\mathcal{Z}_N} \\|u^{\\text{true}} - z\\|_V$ compare to the actual error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e08616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9.1: Convergence study - GEIM vs Uniform sensor placement\n",
    "\n",
    "def convergence_study_geim_vs_uniform(Z, S, x, dx, u_true, A_dict, dict_positions, \n",
    "                                       M_values, delta=1e-2, n_trials=10):\n",
    "    \"\"\"\n",
    "    TODO: Complete this function to compare GEIM vs uniform sensor placement.\n",
    "    \n",
    "    For each M in M_values:\n",
    "    1. Build uniform sensors and compute beta_uniform, err_uniform\n",
    "    2. Run GEIM to select M sensors and compute beta_geim, err_geim\n",
    "    3. Average errors over n_trials (different noise realizations)\n",
    "    \n",
    "    Returns:\n",
    "        results: dict with keys 'M', 'beta_uniform', 'beta_geim', \n",
    "                 'err_uniform', 'err_geim'\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'M': M_values,\n",
    "        'beta_uniform': [],\n",
    "        'beta_geim': [],\n",
    "        'err_uniform': [],\n",
    "        'err_geim': [],\n",
    "        'geim_positions': []\n",
    "    }\n",
    "    \n",
    "    for M_test in M_values:\n",
    "        print(f\"Processing M = {M_test}...\")\n",
    "        \n",
    "        # --- Uniform sensors ---\n",
    "        # TODO: Build uniform sensor configuration\n",
    "        # positions_uniform = ...\n",
    "        # config_uniform = SensorConfig(...)\n",
    "        # W_uniform = build_sensor_matrix(x, config_uniform)\n",
    "        # Q_uniform = build_riesz_representers(W_uniform, dx)\n",
    "        # model_uniform = pbdw_offline(Z, Q_uniform, W_uniform, dx)\n",
    "        \n",
    "        # --- GEIM sensors ---\n",
    "        # TODO: Run GEIM selection with M_test sensors\n",
    "        # J_geim, Q_geim = geim_sensor_selection(S, A_dict, M_test)\n",
    "        # W_geim = A_dict[J_geim, :]\n",
    "        # Q_riesz_geim = build_riesz_representers(W_geim, dx)\n",
    "        # model_geim = pbdw_offline(Z, Q_riesz_geim, W_geim, dx)\n",
    "        \n",
    "        # --- Compute errors (average over noise realizations) ---\n",
    "        # TODO: For each trial, add noise and compute reconstruction error\n",
    "        # err_uniform_trials = []\n",
    "        # err_geim_trials = []\n",
    "        # for trial in range(n_trials):\n",
    "        #     noise_uniform = delta * np.random.randn(M_test)\n",
    "        #     noise_geim = delta * np.random.randn(M_test)\n",
    "        #     ...\n",
    "        \n",
    "        # TODO: Store results\n",
    "        # results['beta_uniform'].append(model_uniform.beta)\n",
    "        # results['beta_geim'].append(model_geim.beta)\n",
    "        # results['err_uniform'].append(np.mean(err_uniform_trials))\n",
    "        # results['err_geim'].append(np.mean(err_geim_trials))\n",
    "        # results['geim_positions'].append(dict_positions[J_geim])\n",
    "        \n",
    "        raise NotImplementedError(\"TODO 9.1: Complete the convergence study\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the convergence study\n",
    "N = Z.shape[1]\n",
    "M_values = list(range(N, 3*N + 1, 2))  # M from N to 3N\n",
    "\n",
    "# TODO: Uncomment after implementing convergence_study_geim_vs_uniform\n",
    "# results = convergence_study_geim_vs_uniform(\n",
    "#     Z, S, x, dx, u_true_with_error, A_dict, dict_positions, M_values\n",
    "# )\n",
    "\n",
    "print(\"TODO: Implement convergence_study_geim_vs_uniform and run the study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c22e21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9.2: Visualization of convergence results\n",
    "# After completing TODO 9.1, run this cell to visualize the results\n",
    "\n",
    "def plot_convergence_results(results, err_best):\n",
    "    \"\"\"Plot the convergence study results.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # Plot 1: Inf-sup constant vs M\n",
    "    axes[0].plot(results['M'], results['beta_uniform'], 'bo-', \n",
    "                 markersize=8, linewidth=2, label='Uniform')\n",
    "    axes[0].plot(results['M'], results['beta_geim'], 'rs-', \n",
    "                 markersize=8, linewidth=2, label='GEIM')\n",
    "    axes[0].set_xlabel('M (number of sensors)')\n",
    "    axes[0].set_ylabel('Inf-sup constant β')\n",
    "    axes[0].set_title('Stability: β vs Number of Sensors')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Reconstruction error vs M\n",
    "    axes[1].semilogy(results['M'], results['err_uniform'], 'bo-', \n",
    "                     markersize=8, linewidth=2, label='Uniform')\n",
    "    axes[1].semilogy(results['M'], results['err_geim'], 'rs-', \n",
    "                     markersize=8, linewidth=2, label='GEIM')\n",
    "    axes[1].axhline(err_best, color='gray', linestyle=':', \n",
    "                    linewidth=2, label='Best approx in $\\mathcal{Z}_N$')\n",
    "    axes[1].set_xlabel('M (number of sensors)')\n",
    "    axes[1].set_ylabel('Reconstruction error')\n",
    "    axes[1].set_title('Accuracy: Error vs Number of Sensors')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Theoretical bound vs actual error\n",
    "    theoretical_uniform = [(1 + 1/b) * err_best for b in results['beta_uniform']]\n",
    "    theoretical_geim = [(1 + 1/b) * err_best for b in results['beta_geim']]\n",
    "    \n",
    "    axes[2].semilogy(results['M'], theoretical_uniform, 'b--', \n",
    "                     linewidth=2, label='Bound (Uniform)')\n",
    "    axes[2].semilogy(results['M'], results['err_uniform'], 'bo', \n",
    "                     markersize=8, label='Actual (Uniform)')\n",
    "    axes[2].semilogy(results['M'], theoretical_geim, 'r--', \n",
    "                     linewidth=2, label='Bound (GEIM)')\n",
    "    axes[2].semilogy(results['M'], results['err_geim'], 'rs', \n",
    "                     markersize=8, label='Actual (GEIM)')\n",
    "    axes[2].set_xlabel('M (number of sensors)')\n",
    "    axes[2].set_ylabel('Error')\n",
    "    axes[2].set_title('Theoretical Bound vs Actual Error')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Uncomment after completing TODO 9.1\n",
    "# plot_convergence_results(results, err_best)\n",
    "\n",
    "print(\"TODO: Run after completing the convergence study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2951d",
   "metadata": {},
   "source": [
    "## 10. Exercise: Noise Robustness Analysis\n",
    "\n",
    "**TODO 9.3: Study how GEIM+PBDW and Uniform+PBDW behave under different noise levels.**\n",
    "\n",
    "For a fixed number of sensors $M = 2N$, compare the reconstruction error as the noise level $\\delta$ varies from $10^{-4}$ to $10^{-1}$.\n",
    "\n",
    "**Questions:**\n",
    "1. At what noise level does regularization become essential?\n",
    "2. Does GEIM provide more robustness to noise than uniform placement?\n",
    "3. How should the regularization parameter $\\lambda$ scale with $\\delta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa76712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9.3: Noise robustness study\n",
    "\n",
    "def noise_robustness_study(model_uniform, model_geim, W_uniform, W_geim, \n",
    "                           u_true, dx, noise_levels, n_trials=20):\n",
    "    \"\"\"\n",
    "    TODO: Compare GEIM vs Uniform under varying noise levels.\n",
    "    \n",
    "    For each noise level delta:\n",
    "    1. Generate noisy observations\n",
    "    2. Reconstruct with optimal regularization lambda ~ delta\n",
    "    3. Compute and store reconstruction errors\n",
    "    \n",
    "    Returns:\n",
    "        results: dict with keys 'delta', 'err_uniform', 'err_geim',\n",
    "                 'err_uniform_no_reg', 'err_geim_no_reg'\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'delta': noise_levels,\n",
    "        'err_uniform': [],\n",
    "        'err_geim': [],\n",
    "        'err_uniform_no_reg': [],\n",
    "        'err_geim_no_reg': []\n",
    "    }\n",
    "    \n",
    "    for delta in noise_levels:\n",
    "        print(f\"Processing noise level δ = {delta:.1e}...\")\n",
    "        \n",
    "        # TODO: For each noise level, compute average error over n_trials\n",
    "        # Consider both with regularization (lambda = delta) and without (lambda = 0)\n",
    "        \n",
    "        # err_uniform_trials = []\n",
    "        # err_geim_trials = []\n",
    "        # err_uniform_no_reg_trials = []\n",
    "        # err_geim_no_reg_trials = []\n",
    "        \n",
    "        # for trial in range(n_trials):\n",
    "        #     ...\n",
    "        \n",
    "        raise NotImplementedError(\"TODO 9.3: Complete the noise robustness study\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define noise levels to test\n",
    "noise_levels = [1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1]\n",
    "\n",
    "# TODO: Build models with M = 2*N sensors for both uniform and GEIM\n",
    "# M_test = 2 * N\n",
    "# ... (build W_uniform_2N, model_uniform_2N, W_geim_2N, model_geim_2N)\n",
    "\n",
    "# TODO: Run the noise robustness study\n",
    "# noise_results = noise_robustness_study(...)\n",
    "\n",
    "print(\"TODO: Implement and run the noise robustness study\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 9.4: Visualization of noise robustness results\n",
    "\n",
    "def plot_noise_robustness(noise_results):\n",
    "    \"\"\"Plot noise robustness study results.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot 1: Error vs noise level (with regularization)\n",
    "    axes[0].loglog(noise_results['delta'], noise_results['err_uniform'], 'bo-', \n",
    "                   markersize=8, linewidth=2, label='Uniform (with reg)')\n",
    "    axes[0].loglog(noise_results['delta'], noise_results['err_geim'], 'rs-', \n",
    "                   markersize=8, linewidth=2, label='GEIM (with reg)')\n",
    "    axes[0].set_xlabel('Noise level δ')\n",
    "    axes[0].set_ylabel('Reconstruction error')\n",
    "    axes[0].set_title('Error vs Noise Level (λ = δ)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    # Plot 2: Effect of regularization\n",
    "    axes[1].loglog(noise_results['delta'], noise_results['err_uniform_no_reg'], 'b--', \n",
    "                   markersize=6, linewidth=1, label='Uniform (no reg)')\n",
    "    axes[1].loglog(noise_results['delta'], noise_results['err_uniform'], 'bo-', \n",
    "                   markersize=8, linewidth=2, label='Uniform (with reg)')\n",
    "    axes[1].loglog(noise_results['delta'], noise_results['err_geim_no_reg'], 'r--', \n",
    "                   markersize=6, linewidth=1, label='GEIM (no reg)')\n",
    "    axes[1].loglog(noise_results['delta'], noise_results['err_geim'], 'rs-', \n",
    "                   markersize=8, linewidth=2, label='GEIM (with reg)')\n",
    "    axes[1].set_xlabel('Noise level δ')\n",
    "    axes[1].set_ylabel('Reconstruction error')\n",
    "    axes[1].set_title('Effect of Regularization')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3, which='both')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# TODO: Uncomment after completing TODO 9.3\n",
    "# plot_noise_robustness(noise_results)\n",
    "\n",
    "print(\"TODO: Run after completing the noise robustness study\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107dd3ae",
   "metadata": {},
   "source": [
    "## 11. Summary and Deliverables\n",
    "\n",
    "### PBDW Key Points:\n",
    "\n",
    "1. **Decomposition**: $u_{N,M} = z_N + \\eta_M$\n",
    "   - $z_N \\in \\mathcal{Z}_N$: Model-based component (anticipated physics)\n",
    "   - $\\eta_M \\in \\mathcal{U}_M$: Data-based correction (unmodeled physics)\n",
    "\n",
    "2. **Error bound**: $\\|u^{\\text{true}} - u_{N,M}\\|_V \\leq (1 + 1/\\beta_{N,M}) \\inf_{z \\in \\mathcal{Z}_N} \\|u^{\\text{true}} - z\\|_V$\n",
    "\n",
    "3. **Inf-sup constant**: $\\beta_{N,M} = \\sqrt{\\lambda_{\\min}(\\mathbf{B}^T \\mathbf{A}^{-1} \\mathbf{B})}$ (for orthonormal $\\mathcal{Z}_N$)\n",
    "\n",
    "4. **Noise robustness**: Tikhonov regularization with $\\lambda \\sim \\delta$ (noise level)\n",
    "\n",
    "5. **GEIM + PBDW synergy**:\n",
    "   - GEIM provides optimal sensor selection maximizing $\\beta_{N,M}$\n",
    "   - PBDW provides rigorous state estimation with error bounds\n",
    "   - Combined approach: better stability and accuracy than uniform placement\n",
    "\n",
    "### References:\n",
    "- Maday, Patera, Penn, Yano (2014): *A parameterized-background data-weak approach to variational data assimilation*\n",
    "- Maday, Mula, Patera, Yano (2015): *The generalized empirical interpolation method: stability theory on Hilbert spaces with an application to the Stokes equation*\n",
    "- Binev, Cohen, Dahmen, DeVore, Petrova, Wojtaszczyk (2017): *Data assimilation in reduced modeling*\n",
    "\n",
    "### Deliverables:\n",
    "\n",
    "**Report** (2-3 pages) summarizing your numerical findings:\n",
    "\n",
    "1. **Implementation**: Briefly describe your implementation of POD, sensors, PBDW offline/online, and GEIM.\n",
    "\n",
    "2. **Noise-free case** (Section 5): \n",
    "   - Compare PBDW reconstruction with best approximation in $\\mathcal{Z}_N$\n",
    "   - Verify the error bound $(1 + 1/\\beta_{N,M})$\n",
    "\n",
    "3. **Noisy case** (Section 6): \n",
    "   - Effect of noise on reconstruction\n",
    "   - Role of regularization parameter $\\lambda$\n",
    "\n",
    "4. **Sensor count** (Section 7):\n",
    "   - How does increasing $M$ affect $\\beta_{N,M}$ and accuracy?\n",
    "\n",
    "5. **GEIM vs Uniform** (Sections 9-10):\n",
    "   - Convergence study: $\\beta_{N,M}$ and error vs $M$\n",
    "   - Noise robustness comparison\n",
    "   - When is GEIM beneficial?\n",
    "\n",
    "**Include**: Key plots and tables supporting your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd8692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics (run after completing all exercises)\n",
    "\n",
    "def print_final_summary():\n",
    "    \"\"\"Print comprehensive summary of PBDW study.\"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"PBDW STATE ESTIMATION - FINAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\n1. BACKGROUND SPACE (POD):\")\n",
    "    print(f\"   Dimension N = {N}\")\n",
    "    print(f\"   Energy captured: {energy[N-1]:.2%}\")\n",
    "    print(f\"   Best approximation error: {err_best:.6e}\")\n",
    "    \n",
    "    print(f\"\\n2. OBSERVABLE SPACE (Uniform sensors):\")\n",
    "    print(f\"   Number of sensors M = {M}\")\n",
    "    print(f\"   Sensor type: {sensor_config.type}\")\n",
    "    print(f\"   Inf-sup constant β = {model.beta:.4f}\")\n",
    "    print(f\"   Stability factor (1 + 1/β) = {1 + 1/model.beta:.2f}\")\n",
    "    \n",
    "    print(f\"\\n3. NOISE-FREE RECONSTRUCTION:\")\n",
    "    print(f\"   PBDW error: {err_pbdw:.6e}\")\n",
    "    print(f\"   Error ratio (PBDW/best): {err_ratio:.2f}\")\n",
    "    print(f\"   Theoretical bound: {1 + 1/model.beta:.2f}\")\n",
    "    \n",
    "    print(f\"\\n4. GEIM+PBDW:\")\n",
    "    print(f\"   Selected {len(J_geim)} sensors from {Ns_dict} candidates\")\n",
    "    print(f\"   Inf-sup constant β = {model_geim.beta:.4f}\")\n",
    "    print(f\"   Improvement factor: {model_geim.beta / model.beta:.2f}x\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"KEY TAKEAWAYS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"• PBDW combines model knowledge (Z_N) with data (U_M)\")\n",
    "    print(\"• Inf-sup constant β controls stability and error amplification\")\n",
    "    print(\"• GEIM optimizes sensor placement to maximize β\")\n",
    "    print(\"• Regularization essential for noisy observations\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Run summary (will work after all TODOs are completed)\n",
    "try:\n",
    "    print_final_summary()\n",
    "except NameError as e:\n",
    "    print(f\"Complete all exercises first. Missing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
