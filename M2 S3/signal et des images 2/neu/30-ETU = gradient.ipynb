{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "metadata": {"id": "cBSSULReUITm"}, "source": ["# D\u00e9rivation"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "QmaoIBF9PTCk"}, "source": ["%reset -f"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Fjjt2Z_LI9rf"}, "source": ["import tensorflow as tf\n", "import torch\n", "import jax\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "plt.style.use(\"default\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "biOeIVOkzWiQ"}, "source": ["## Introduction\n", "\n", "Mais comment calcule-t-on des d\u00e9riv\u00e9es ? Pas sur du papier, mais avec un ordinateur ? La bonne r\u00e9ponse est venue tardivement (1985 environ) et a permis le d\u00e9veloppement du deep-learning.  \n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "fPXqvl3yfH7Y"}, "source": ["### D\u00e9rivation compos\u00e9e (Chain rule)\n", "\n", "D\u00e9taillons les maths sur un exemple"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Lw6RWnrRe-Nr"}, "source": ["Analysons la d\u00e9riv\u00e9e de la fonction $  h \\circ g \\circ f (x)  $.  Voici son graphe de calcul:\n", "\n", "$$\n", "x \\xrightarrow  f   y   \\xrightarrow g z   \\xrightarrow h  t\n", "$$\n", "  Les accroissements infinit\u00e9simaux se multiplient (c'est la chain rule) :\n", "\n", "\\begin{alignat}{1}\n", "\\frac {\\partial  t  }{\\partial x}      &=        \\frac{ \\partial y }{ \\partial x}   \\frac{ \\partial z }{ \\partial y}   \\frac{ \\partial t }{ \\partial z } \\\\\n", "&=  f'(x) g'(y) h'(z)    \n", "\\end{alignat}\n", "\n", "\n", "\n", "\n"], "outputs": []}, {"cell_type": "markdown", "source": ["## Passage forward puis d\u00e9rivation backward"], "metadata": {"id": "mCWCayV06OD_"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "9Rmy4pcOgATn"}, "source": ["Nous allons d\u00e9cortiquer le calcul de cette d\u00e9riv\u00e9e en un point pr\u00e9cis. Pour fixer les id\u00e9es:\n", "\n", "* $f(a) = \\sin(a)$, donc $f'(a) = \\cos(a)$\n", "* $g(a) =  4 a^2$, donc $g'(a) = 8 a$\n", "* $h(a)=  \\tanh(a)$ donc $h'(a)= 1-\\tanh^2(a)$\n", "\n", "Notons que l'ordinateur sait \u00e9valuer pr\u00e9cis\u00e9ment ces fonctions \u00e9l\u00e9mentaire. Et de plus, les lib comme Jax,tensorflow, torch savent associer \u00e0 une fonction \u00e9l\u00e9mentaire, sa d\u00e9riv\u00e9ee (ce n'est pas le cas de numpy).\n", "\n", " Maintenant il s'agit de bien composer les calculs. Nous voulons calculer\n", "$$\n", "   \\frac{\\partial (h \\circ g \\circ f )(x)} {\\partial x}  \n", "$$\n", "en $x=7$.\n", "\n", "Forward pass:\n", "1. Calcul et stockage de $y=f(x)$\n", "2. Calcul et stockage de $z=g(y)$\n", "3. Calcul et stockage de $t=h(z)$\n", "\n", "Backward pass:\n", "1. Calcul de $\\frac{\\partial t}{\\partial z} = h'(z)$\n", "2. Calcul de $\\frac{\\partial t}{\\partial y} = g'(y) h'(z)$.\n", "3. Calcul de $\\frac{\\partial t}{\\partial x} = f'(x) g'(y) h'(z)$.\n", "\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "sQd1sR1PoNaO"}, "source": ["### Impl\u00e9mentations"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "BGoYC3_QoDFK", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1755549908756, "user_tz": -120, "elapsed": 9, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0c778eea-bf81-4b52-b031-8778871068a2"}, "source": ["x=tf.Variable(7.)\n", "with tf.GradientTape(persistent=False) as tape:\n", "    t = tf.tanh(4*tf.cos(x)**2)\n", "\n", "print(tape.gradient(t,x).numpy())"], "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["x=torch.tensor(7.,requires_grad=True)\n", "t = torch.tanh(4*torch.cos(x)**2)\n", "t.backward()\n", "print(x.grad)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "vbYAO1p27hNX", "executionInfo": {"status": "ok", "timestamp": 1755549963591, "user_tz": -120, "elapsed": 161, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a56bdbdd-a1a0-437a-a10e-9d127315ec42"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["x=jax.numpy.array(7.)\n", "fn = lambda x: jax.numpy.tanh(4*jax.numpy.cos(x)**2)\n", "grad = jax.grad(fn)(x)\n", "print(grad)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rNZBdDOT7rUt", "executionInfo": {"status": "ok", "timestamp": 1755550065806, "user_tz": -120, "elapsed": 764, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ea97c4ca-63e8-43de-a716-d259997aa448"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qU9Rvv38f_mG"}, "source": ["***\u00c0 vous:***  Consid\u00e9rons des scalaires $a,b,c,d$ et les fonctions affines\n", "\n", "* $f(x) = ax+b $ et\n", "* $g(x) = cx + d $.\n", "\n", "\n", "Calculez explicitement $g\\circ f(x+\\epsilon) - g\\circ f(x)$.    \n", "\n", "\n", "En comparant cet exo et la 'chain rule', vous comprendrez que : les accroissements infinit\u00e9simaux des fonctions lisses, se composent de la m\u00eame mani\u00e8re que les accroissements des fonctions affines.  En bref : toute fonction lisse est localement une fonction affine.\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "PfkLBxBxlQ4R"}, "source": ["### R\u00e9gle de l'accumulation\n", "\n", "Quand une fonction a plusieurs variables, $g(a,b,...)$, ses d\u00e9riv\u00e9es partielles  se calculent sans difficult\u00e9. Par ex, pour calculer  $\\frac{\\partial g(a,b,...)}{\\partial a}$ il suffit de consid\u00e9rer uniquement la fonction $a\\to g(a,b,...)$.\n", "\n", "\n", "Par contre, quand  une variable $x$ intervient plusieurs fois:\n", "$$\n", "z=h(x) =  g  [ f_1 (x), f_2 (x) , ...] = g [ y_1,y_2,...]\n", "$$\n", " Graphe de calcul (dit en diamant):\n", "$$\n", "x \\xrightarrow f  \\begin{bmatrix}  y_1 \\\\  y_2 \\\\ \\vdots \\end{bmatrix}  \\xrightarrow g z\n", " $$\n", " Les accroissements s'additionnent (s'accumulent):\n", "$$\n", "\\frac {\\partial  z  }{\\partial x}  =    \\sum_i        \\frac{\\partial y_i }{\\partial x}      \\frac {\\partial z }{\\partial y_i} =    \\sum_i     f'_i(x) g'(y_i)  \n", "$$\n", "\n", "\n", "***\u00c0 vous:*** vous connaissez par c\u0153ur la r\u00e9gle de d\u00e9rivation d'un produit:\n", "$$\n", "(f_1 * f_2)' = f'_1 f_2 + f_1 f'_2\n", "$$\n", "V\u00e9rifiez qu'il s'agit d'un cas particulier de la r\u00e9gle d'accumulation. Pour vous aider, consid\u00e9rer le graphe de calcul en diamant:\n", "$$\n", "x \\xrightarrow f  \\begin{bmatrix}  f_1(x) \\\\  f_2(x)  \\end{bmatrix}  \\xrightarrow * f_1(x) * f_2(x)\n", " $$\n", "\n", "\n", "\n", "\n", "\n"], "outputs": []}, {"cell_type": "markdown", "source": ["V\u00e9rifions la r\u00e9gle de l'accumulation en tensorflow:"], "metadata": {"id": "IYsUHSO71nOj"}, "outputs": []}, {"cell_type": "code", "metadata": {"id": "W84ggX9moYOd", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760458804, "user_tz": -60, "elapsed": 638, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "86d5f694-3354-4278-b02d-bbb329c7a14a"}, "source": ["x=tf.Variable(7.)\n", "\n", "with tf.GradientTape(persistent=True) as tape:\n", "    y1=x**2\n", "    y2=tf.cos(x)\n", "    y3=tf.atan(x)\n", "    z=y1*y2/y3\n", "\n", "print(tape.gradient(z,x).numpy())\n", "\n", "dz_dy1=tape.gradient(z,y1)\n", "dz_dy2=tape.gradient(z,y2)\n", "dz_dy3=tape.gradient(z,y3)\n", "\n", "dy1_dx=tape.gradient(y1,x)\n", "dy2_dx=tape.gradient(y2,x)\n", "dy3_dx=tape.gradient(y3,x)\n", "\n", "dz_dx = dz_dy1*dy1_dx + dz_dy2*dy2_dx + dz_dy3*dy3_dx\n", "print(dz_dx.numpy())"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "zxKAvsOHw2Gn"}, "source": ["### Comparaison avec le calcul formel \"symbolique\""], "outputs": []}, {"cell_type": "code", "metadata": {"id": "K_WH9hCosA-w"}, "source": ["def fonction_complexe(x,y,z):\n", "    a=atan(x/y)\n", "    b=cos(z**2-x)\n", "    return x*y*a*b/z+a-b"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "C34AL5wUsi_Y", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760458805, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b5039fa9-223b-48d2-c8e6-287e1b4452f5"}, "source": ["%%time\n", "from tensorflow import cos,atan\n", "\n", "x=tf.Variable(7.)\n", "y=tf.Variable(5.)\n", "z=tf.Variable(2.)\n", "with tf.GradientTape() as tape:\n", "    f=fonction_complexe(x,y,z)\n", "\n", "[df_dx,df_dy,df_dz]=tape.gradient(f,[x,y,z])\n", "print(df_dx.numpy())\n", "print(df_dy.numpy())\n", "print(df_dz.numpy())"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "YoOJFgOJtS6E", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760461971, "user_tz": -60, "elapsed": 3167, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ad432dda-4dbc-4380-d678-ff2c15232dab"}, "source": ["%%time\n", "import sympy\n", "from sympy import cos,atan\n", "\n", "x,y,z=sympy.symbols('x y z')\n", "f=fonction_complexe(x,y,z)\n", "df_dx=sympy.Derivative(f, x).doit()\n", "df_dy=sympy.Derivative(f, y).doit()\n", "df_dz=sympy.Derivative(f, z).doit()\n", "\n", "subs={x:7.,y:5.,z:2.}\n", "print(df_dx.evalf(subs=subs))\n", "print(df_dy.evalf(subs=subs))\n", "print(df_dz.evalf(subs=subs))"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ubg0T4YKxGVE"}, "source": ["Regardons les expressions que doit retenir `sympy`"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "Ep3fUX0KxAC3", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730760461971, "user_tz": -60, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4eb39614-4759-4f35-c60b-162876a58c77"}, "source": ["print(df_dx)"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### graph de calul\n", "\n", "C'est le d\u00e9tails des calculs"], "metadata": {"id": "bgXeBvI5oxa0"}, "outputs": []}, {"cell_type": "markdown", "source": ["Voici un graphe de calcul de `z=(x*a)**2`. Il faut le lire de bas en haut."], "metadata": {"id": "MhcLpvwvzJHD"}, "outputs": []}, {"cell_type": "markdown", "source": ["    x     a\n", "     \\   /\n", "       y=x*a\n", "       |\n", "       z=y**2"], "metadata": {"id": "R_06Ij0Hyd-G"}, "outputs": []}, {"cell_type": "markdown", "source": ["Remarquons qu'il n'y a pas de cycle dans un graph de calcul, sinon on ne serez pas faire le calcul. Par contre il peut y avoir des diaments, ce qui oblige \u00e0 utiliser la r\u00e9gle d'accumulation."], "metadata": {"id": "tFJm4MmElAgU"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Second exemple"], "metadata": {"id": "dsUHoUWq2p-_"}, "outputs": []}, {"cell_type": "markdown", "source": ["Suivons l'exemple du calcul de d\u00e9riv\u00e9e de\n", "$$\n", "z=(x^2*cos(x))^2\n", "$$\n", "Le graph des calcul inclus un diamant puisque $x$ intervient deux fois."], "metadata": {"id": "INS07Q1Vy4Sc"}, "outputs": []}, {"cell_type": "markdown", "source": ["Forward\n", "\n", "\n", "\n", "        x=\ud835\udf0b\n", "       /   \\\n", "    a=x^2   b=cos(x)\n", "     =\ud835\udf0b\u00b2    =-1\n", "     \\      /\n", "       y=a*b\n", "        =-\ud835\udf0b\u00b2\n", "        |\n", "       z=y**2\n", "        =\ud835\udf0b\u2074"], "metadata": {"id": "qwvWGdeiqGPH"}, "outputs": []}, {"cell_type": "markdown", "source": ["Backward"], "metadata": {"id": "d3u56ilMxZuz"}, "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "Etape 1\n", "\n", "\n", "    dz/dy=2y\n", "         =-2\ud835\udf0b\u00b2\n", "\n", "\n", "            \n", "\n", "\n", "\n"], "metadata": {"id": "tyL8tGIiqT68"}, "outputs": []}, {"cell_type": "markdown", "source": ["Etape 2\n", "       \n", "\n", "      dz/da           dz/db\n", "      =dz/dy*dy/da    =dz/dy*dy/db\n", "      =-2\ud835\udf0b\u00b2 *b        =-2\ud835\udf0b\u00b2 *a\n", "      =2\ud835\udf0b\u00b2            =-2\ud835\udf0b\u2074\n", "        \\            /  \n", "           dz/dy=-2\ud835\udf0b\u00b2"], "metadata": {"id": "ZrlhAnHLuza1"}, "outputs": []}, {"cell_type": "markdown", "source": ["Etape 3\n", "\n", "            dz/dx\n", "            =  dz/da*da/dx\n", "              +dz/db*db/dx\n", "            =  2\ud835\udf0b\u00b2* 2x\n", "              -2\ud835\udf0b\u2074* (-sin(x))\n", "            = 4\ud835\udf0b\u00b3\n", "          /          \\\n", "\n", "      dz/da           dz/db\n", "      =2\ud835\udf0b\u00b2            =-2\ud835\udf0b\u2074\n", "        \\            /  \n", "           dz/dy=-2\ud835\udf0b\u00b2"], "metadata": {"id": "uu0Hs3ZtyVBA"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Calculer l'occupation de la m\u00e9moire gpu"], "metadata": {"id": "DFTZOsiwRN38"}, "outputs": []}, {"cell_type": "markdown", "source": ["Red\u00e9marez la session."], "metadata": {"id": "Og9Yk124-IMt"}, "outputs": []}, {"cell_type": "code", "source": ["import torch"], "metadata": {"id": "Lx9-Wqj97e2i"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "torch.cuda.max_memory_allocated()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "vLsl5t7PSpZB", "executionInfo": {"status": "ok", "timestamp": 1730801003431, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6fbe4859-d60a-472b-8ca5-b0186a33c8f2"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["V\u00e9rifiez que vous \u00eates bien \u00e0 0 ci-dessus. Sinon cela signifie que vous avez avant construits des tenseurs dans le gpu."], "metadata": {"id": "fAPAby1Gfj4y"}, "outputs": []}, {"cell_type": "code", "source": ["size=1024"], "metadata": {"id": "yJNAB1tB7xWO"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["A=torch.ones(size,device=\"cuda\")\n", "torch.cuda.max_memory_allocated()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "emTyDE5SURY7", "executionInfo": {"status": "ok", "timestamp": 1730801006145, "user_tz": -60, "elapsed": 396, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0a58b89b-ca4f-4cdf-f183-761470f42b0a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["size*4"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Uc--k8y8UYap", "executionInfo": {"status": "ok", "timestamp": 1730801007265, "user_tz": -60, "elapsed": 243, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0a4513b8-25ce-4f42-82a5-2600560f23e7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["del A"], "metadata": {"id": "RhM-STZoXJSD"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "torch.cuda.max_memory_allocated()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Tx7ZOMVjUfhR", "executionInfo": {"status": "ok", "timestamp": 1730800888332, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "e64c7f63-bfa1-46d5-c1f3-153a1e85653f"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["A=torch.ones(size,dtype=torch.float64,device=\"cuda\")\n", "torch.cuda.max_memory_allocated()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "cYzfNbzqUyom", "executionInfo": {"status": "ok", "timestamp": 1730800895367, "user_tz": -60, "elapsed": 278, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "75cb8d6e-d1f6-49cb-83a9-8109ad837b9f"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["size*8"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "TMHmAuAUU92Q", "executionInfo": {"status": "ok", "timestamp": 1730800901141, "user_tz": -60, "elapsed": 271, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6ab8f6cf-fd5d-4f3c-988d-1684dbfbee51"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["del A"], "metadata": {"id": "PYi_oRC7VOaC"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "torch.cuda.max_memory_allocated()"], "metadata": {"id": "_0wH4ev6VCtA", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730800903190, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "075d1550-3da9-4493-e56c-df7b447db5e7"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["***\u00c0 vous:*** Que se passe-t-il si l'on remplace 1024 par une taille l\u00e9g\u00e8rement plus grande, ou plus petite ? Vous en d\u00e9duirez pourquoi on aime bien d\u00e9finir des tenseurs dont les tailles sont des puissances de 2."], "metadata": {"id": "fyyufVVAVZa_"}, "outputs": []}, {"cell_type": "markdown", "source": ["***\u00c0 vous:*** Que v\u00e9rifie-t-on dans la suite ?"], "metadata": {"id": "fqOFmj94X2P2"}, "outputs": []}, {"cell_type": "code", "source": ["def some_calculus(requires_grad,n):\n", "    A=torch.rand(1000,device=\"cuda\",requires_grad=requires_grad)\n", "    for _ in range(n):\n", "        A=A*torch.rand(1000,device=\"cuda\")\n", "    return A"], "metadata": {"id": "Kwtli05IHr7z"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "torch.cuda.max_memory_allocated()"], "metadata": {"id": "5Qf2qM5qV7oQ", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730801040338, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "cd52014e-0a51-458c-f114-fb6189985e68"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "A=some_calculus(True,10)\n", "print(torch.cuda.max_memory_allocated())\n", "del A"], "metadata": {"id": "U3sPsD7RV-Ya", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730801046821, "user_tz": -60, "elapsed": 268, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "419da271-20b7-44e8-d1cd-7319a3b9fdb7"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "A=some_calculus(True,100)\n", "print(torch.cuda.max_memory_allocated())\n", "del A"], "metadata": {"id": "m9YpIu_HV-bu", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730801077404, "user_tz": -60, "elapsed": 233, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "03990d59-9f06-4e37-bbf8-d920e28d11b8"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "A=some_calculus(False,10)\n", "print(torch.cuda.max_memory_allocated())\n", "del A"], "metadata": {"id": "SSi6xGHSV-g9", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730801131517, "user_tz": -60, "elapsed": 252, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bfc3ab64-700e-4f96-de0b-b21b515384ea"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["torch.cuda.reset_peak_memory_stats()\n", "A=some_calculus(False,100)\n", "print(torch.cuda.max_memory_allocated())\n", "del A"], "metadata": {"id": "De5BEG1XXu_7", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1730801132971, "user_tz": -60, "elapsed": 271, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "8a0fa2de-c364-4b44-e4ca-1a00d9bdd47f"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Jax champion de la simplicit\u00e9\n", "\n", "Dans les ann\u00e9es pass\u00e9es j'ai beaucoup pratiqu\u00e9 torch et tensorflow, et il y a beaucoup de chose bizarre quand on d\u00e9rive.\n", "\n", "Jax est plus simple est souvent plus performant"], "metadata": {"id": "Q_m4kzuc-5zc"}, "outputs": []}, {"cell_type": "markdown", "source": ["Et en plus, il est proche des maths: car on d\u00e9rive des fonctions! et pas des r\u00e9sultats d'\u00e9valuations de fonctions."], "metadata": {"id": "IztkeRAV_R0e"}, "outputs": []}, {"cell_type": "code", "source": ["%reset -f"], "metadata": {"id": "gnJ2cfFfBC5c"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import jax.numpy as jnp\n", "import jax\n", "from jax import grad, jit, vmap\n", "import matplotlib.pyplot as plt"], "metadata": {"id": "acOVKtzi_sth"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["f_of_x = lambda x:x**2\n", "\n", "f_of_x_dx = grad(f_of_x)\n", "\n", "f_of_xV = vmap(f_of_x)\n", "f_of_xV_dx = vmap(f_of_x_dx)"], "metadata": {"id": "FB5e49ZC_cv5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["xV = jnp.linspace(-5,5,100)\n", "fig,ax=plt.subplots(figsize=(10,6))\n", "ax.plot(xV,f_of_xV(xV),label=\"f(x)\")\n", "ax.plot(xV,f_of_xV_dx(xV),label=\"f'(x)\")\n", "ax.legend();"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 522}, "id": "Up0wi49S_0J5", "executionInfo": {"status": "ok", "timestamp": 1755551407666, "user_tz": -120, "elapsed": 376, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "c130857f-59c2-40b3-9966-21c792a1d35c"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["C'est normal que l'on ne puisse pas faire:\n", "\n", "    grad(f_of_x)(xV)\n", "\n", "Dans la logique Jax, on travaille avec des fonctions \u00e0 valeur scalaire, et on les vectorisent juste avant leur \u00e9valuation."], "metadata": {"id": "LT5qqeIzAhqk"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Jitons"], "metadata": {"id": "jYZar7bmE-kk"}, "outputs": []}, {"cell_type": "code", "source": ["import jax.numpy as jnp\n", "import jax\n", "from jax import grad, jit, vmap\n", "import jax.random as jr\n", "import matplotlib.pyplot as plt"], "metadata": {"id": "IhhB8YO1F-lh"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "def f_of_\u0398_x(\u0398,x):\n", "    return jnp.tanh(\u0398@jnp.tanh(\u0398@x))\n", "\n", "def loss(\u0398,x,y):\n", "    return jnp.mean((f_of_\u0398_x(\u0398,x)-y)**2)\n", "\n", "def loss_grad(\u0398,x,y):\n", "    return grad(loss)(\u0398,x,y)\n", "\n", "\n", "\u0398 = jr.normal(jr.PRNGKey(0), (100, 100))\n", "x = jr.normal(jr.PRNGKey(1), (100,))\n", "y = jr.normal(jr.PRNGKey(2), ())\n", "\n", "d\u0398 = loss_grad(\u0398,x,y)\n", "d\u0398.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Jo7MlydFE37B", "executionInfo": {"status": "ok", "timestamp": 1755552796721, "user_tz": -120, "elapsed": 20, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "d7088c0b-b314-48d0-a8ef-c5adacfa428a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def compute_loss_and_d\u0398():\n", "    \u0398 = jr.normal(jr.PRNGKey(0), (100, 100))\n", "    x = jr.normal(jr.PRNGKey(1), (100,))\n", "    y = jr.normal(jr.PRNGKey(2), ())\n", "\n", "    d\u0398 = loss_grad(\u0398,x,y)\n", "    print(d\u0398.shape)\n", "\n", "    return loss(\u0398,x,y),d\u0398"], "metadata": {"id": "GJomGHlJFfMB"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "_ = compute_loss_and_d\u0398()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ZnHoOX9QHBPV", "executionInfo": {"status": "ok", "timestamp": 1755552993059, "user_tz": -120, "elapsed": 42, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0f5f6c1b-1024-4e41-80cc-3961a023d21a"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["compute_loss_and_d\u0398_jit=jit(compute_loss_and_d\u0398)\n", "_ = compute_loss_and_d\u0398_jit()"], "metadata": {"id": "QmaHEo1_HESk"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["%%time\n", "_ = compute_loss_and_d\u0398_jit()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Ejd2kvv7HUOR", "executionInfo": {"status": "ok", "timestamp": 1755553049650, "user_tz": -120, "elapsed": 7, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "1fcf7c6a-0301-4bac-d7cb-2e9580ec791f"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On peut encore l\u00e9g\u00e8rement am\u00e9liorer les performances en utilisant `jax.value_and_grad` ce qui \u00e9conomise un passage forward.  "], "metadata": {"id": "LAKNaa_rIhSh"}, "outputs": []}, {"cell_type": "code", "source": ["def loss_value_and_grad(\u0398,x,y):\n", "    return jax.value_and_grad(loss)(\u0398,x,y)"], "metadata": {"id": "8y0Xv7gKHatV"}, "execution_count": null, "outputs": []}]}