{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4", "collapsed_sections": ["drDf_uaZ0FWA"], "toc_visible": true, "authorship_tag": "ABX9TyM0rXMKOe/AIujVvQ7dWGkj"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "metadata": {"id": "TAHhmyOQP09P"}, "source": ["# Etude d'un cas"], "outputs": []}, {"cell_type": "code", "source": ["!pip install equinox"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "cG0hQ4MejXYN", "executionInfo": {"status": "ok", "timestamp": 1763374269273, "user_tz": -60, "elapsed": 10134, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "8ce7c624-5a6a-455c-8912-ab04fc1e0e5d"}, "execution_count": 1, "outputs": []}, {"cell_type": "code", "source": ["%reset -f"], "metadata": {"id": "At55nBVX0RFz", "executionInfo": {"status": "ok", "timestamp": 1763374269369, "user_tz": -60, "elapsed": 44, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": ["import tensorflow as tf\n", "import os\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import pandas as pd\n", "import datetime\n", "import seaborn as sns\n", "import time\n", "\n", "import jax\n", "from jax import vmap, jit\n", "import jax.numpy as jnp\n", "import jax.random as jr\n", "import equinox as eqx\n", "from jax import lax"], "metadata": {"id": "rvApsxngjuQ_", "executionInfo": {"status": "ok", "timestamp": 1763374289278, "user_tz": -60, "elapsed": 19893, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": ["### Importation\n", "\n", "Nos donn\u00e9es ont \u00e9t\u00e9 import\u00e9e depuis l'url\n", "\n", "    https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip\n", "\n", "Pour \u00eatre ind\u00e9pendant de toute mise \u00e0 jour de ce lien, je les ai plac\u00e9 sur mon serveur."], "metadata": {"id": "iZ1bkpJ4viFR"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "TokBlnUhWFw9"}, "source": ["## Le jeu de donn\u00e9es m\u00e9t\u00e9o\n", "\n", "Cet s\u00e9ries temporelle contient 14 caract\u00e9ristiques (features)  telles que la temp\u00e9rature de l'air, la pression atmosph\u00e9rique, l'humidit\u00e9... Celles-ci ont \u00e9t\u00e9 collect\u00e9es toutes les 10 minutes, \u00e0 partir de 2003.\n"], "outputs": []}, {"cell_type": "code", "source": ["data_frame_10min = pd.read_csv(\"http://octaviogame.com/liens/data/jena_climate_2009_2016.csv\", sep=\",\")"], "metadata": {"id": "UMf14yCfv9HI", "executionInfo": {"status": "ok", "timestamp": 1763374298575, "user_tz": -60, "elapsed": 9292, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": ["data_frame_10min"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 683}, "id": "CQrqsQ5rxDih", "executionInfo": {"status": "ok", "timestamp": 1763374298856, "user_tz": -60, "elapsed": 274, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b3d314ba-378e-4098-d63e-86d8a6dcc1c8"}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": ["L'indexe n'est pas la colonne \"Date Time\". Modifions cela:"], "metadata": {"id": "THgRo1KZmU7Y"}, "outputs": []}, {"cell_type": "code", "source": ["#Convertir la colonne en datetime\n", "data_frame_10min['Date Time'] = pd.to_datetime(data_frame_10min['Date Time'],format='%d.%m.%Y %H:%M:%S')\n", "data_frame_10min = data_frame_10min.set_index('Date Time')\n", "data_frame_10min"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 920}, "id": "SjdWUuuQmNdw", "executionInfo": {"status": "ok", "timestamp": 1763374302827, "user_tz": -60, "elapsed": 3955, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "fc4b58ca-ce8c-43e7-bd28-fd30da9c35ab"}, "execution_count": 6, "outputs": []}, {"cell_type": "code", "source": ["data_frame_10min.describe()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 350}, "id": "wFreuYWdoGFR", "executionInfo": {"status": "ok", "timestamp": 1763374303463, "user_tz": -60, "elapsed": 624, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "8b11ff44-8772-489a-8d2d-91f419b79195"}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": ["On voit qu'on a la valeur \"-9999.000000\" qui semble abh\u00e9rente dans les colonnes \"wv\"."], "metadata": {"id": "B3Jv6VjQoevv"}, "outputs": []}, {"cell_type": "code", "source": ["data_frame_10min_clean=data_frame_10min.replace(-9999.0,0)"], "metadata": {"id": "ZLgQEgwYotws", "executionInfo": {"status": "ok", "timestamp": 1763374303483, "user_tz": -60, "elapsed": 19, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 8, "outputs": []}, {"cell_type": "code", "source": ["data_frame_10min_clean.isna().sum()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 544}, "id": "zfPFEKSQpkv_", "executionInfo": {"status": "ok", "timestamp": 1763374303524, "user_tz": -60, "elapsed": 40, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2dcb467f-6501-4983-a244-790ed18a789a"}, "execution_count": 9, "outputs": []}, {"cell_type": "markdown", "source": ["On ne garde qu'une mesure par heure:"], "metadata": {"id": "czvrQQ63nZR4"}, "outputs": []}, {"cell_type": "code", "source": ["data_frame=data_frame_10min_clean.resample('h').mean().dropna()\n", "data_frame"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 920}, "id": "A9xsyzeTmjsG", "executionInfo": {"status": "ok", "timestamp": 1763374304139, "user_tz": -60, "elapsed": 614, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "da9c3d0c-fdb1-4b9b-e9db-efa92adab1cf"}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": ["data_frame.isna().sum()#date_time = pd.to_datetime(data_frame.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')"], "metadata": {"id": "Yq4ellfByBdU", "colab": {"base_uri": "https://localhost:8080/", "height": 544}, "executionInfo": {"status": "ok", "timestamp": 1763374304184, "user_tz": -60, "elapsed": 41, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "f351139d-5c23-41c7-ff11-d0358d699988"}, "execution_count": 11, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "WRzj1inMfgcO"}, "source": ["Voici l'\u00e9volution de quelques features au fil du temps."], "outputs": []}, {"cell_type": "code", "source": ["plot_cols = ['p (mbar)','T (degC)',  'rho (g/m**3)']\n", "plot_features = data_frame[plot_cols]\n", "#plot_features.index = date_time"], "metadata": {"id": "AtVpjvV6zxsy", "executionInfo": {"status": "ok", "timestamp": 1763374304184, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Vg5XIc5tfNlG", "colab": {"base_uri": "https://localhost:8080/", "height": 705}, "executionInfo": {"status": "ok", "timestamp": 1763374307293, "user_tz": -60, "elapsed": 3110, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0ca575fc-2052-420e-ba17-7fc58d92526e"}, "source": ["plot_features.plot(subplots=True,figsize=(10,10));"], "execution_count": 13, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "FYyEaqiD6j4s"}, "source": ["### Transformons le vent\n", "\n", "La derni\u00e8re colonne des donn\u00e9es, wd (deg) , donne la direction du vent en unit\u00e9s de degr\u00e9s. Les angles ne font pas de bonnes entr\u00e9es de mod\u00e8le, 359 \u00b0 et 0 \u00b0 doivent \u00eatre proches l'un de l'autre ! La direction ne devrait pas avoir d'importance si le vent ne souffle tr\u00e8s peu.\n", "\n", "Pour l'instant, la distribution des donn\u00e9es \u00e9oliennes ressemble \u00e0 ceci:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "YO7JGTcWQG2z", "colab": {"base_uri": "https://localhost:8080/", "height": 455}, "executionInfo": {"status": "ok", "timestamp": 1763374307367, "user_tz": -60, "elapsed": 73, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4dc1fae2-8a2a-42e2-fb53-6fecb24b16de"}, "source": ["plt.hist2d(data_frame['wd (deg)'], data_frame['wv (m/s)'], bins=(50, 50), vmax=400)\n", "plt.colorbar()\n", "plt.xlabel('Wind Direction [deg]')\n", "plt.ylabel('Wind Velocity [m/s]');"], "execution_count": 14, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "yWnf5dwMU1_g"}, "source": ["\n", "Mais cela sera plus facile \u00e0 interpr\u00e9ter pour le mod\u00e8le si on converti ceci en un \"vecteur de vent\" qui indique la direction et la puissance du vent."], "outputs": []}, {"cell_type": "code", "source": ["wv = data_frame['wv (m/s)']\n", "max_wv = data_frame['max. wv (m/s)']"], "metadata": {"id": "kx1PGjm7qM3Q", "executionInfo": {"status": "ok", "timestamp": 1763374307369, "user_tz": -60, "elapsed": 1, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 15, "outputs": []}, {"cell_type": "code", "source": ["wd_rad = data_frame['wd (deg)']*np.pi / 180"], "metadata": {"id": "5QzzY-phn8Z4", "executionInfo": {"status": "ok", "timestamp": 1763374307372, "user_tz": -60, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": ["# Calculate the wind x and y components.\n", "data_frame['Wx'] = wv*np.cos(wd_rad)\n", "data_frame['Wy'] = wv*np.sin(wd_rad)"], "metadata": {"id": "nvPz0GtOqGSb", "executionInfo": {"status": "ok", "timestamp": 1763374307377, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "metadata": {"id": "6GmSTHXw6lI1", "executionInfo": {"status": "ok", "timestamp": 1763374307387, "user_tz": -60, "elapsed": 9, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["# Calculate the max wind x and y components.\n", "data_frame['max Wx'] = max_wv*np.cos(wd_rad)\n", "data_frame['max Wy'] = max_wv*np.sin(wd_rad)"], "execution_count": 18, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "7iI0zDoxWDyB"}, "source": ["La distribution des vecteurs de vent est beaucoup plus simple \u00e0 interpr\u00e9ter pour le mod\u00e8le (et pour nous aussi)."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "bMgCG5o2SYKD", "colab": {"base_uri": "https://localhost:8080/", "height": 449}, "executionInfo": {"status": "ok", "timestamp": 1763374307442, "user_tz": -60, "elapsed": 54, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2ffaa269-55a2-4e23-855c-285e08b27b35"}, "source": ["fig,ax=plt.subplots()\n", "ax.hist2d(data_frame['Wx'], data_frame['Wy'], bins=(50, 50), vmax=400)\n", "ax.set_xlabel('Wind X [m/s]')\n", "ax.set_ylabel('Wind Y [m/s]');"], "execution_count": 19, "outputs": []}, {"cell_type": "code", "source": ["fig,ax=plt.subplots()\n", "ax.hist2d(data_frame['max Wx'], data_frame['max Wy'], bins=(50, 50), vmax=400)\n", "ax.set_xlabel('Wind X [m/s]')\n", "ax.set_ylabel('Wind Y [m/s]');"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 449}, "id": "tkLIUkVUrQEr", "executionInfo": {"status": "ok", "timestamp": 1763374307488, "user_tz": -60, "elapsed": 46, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0f6070ca-8122-4e59-8425-c726443d311e"}, "execution_count": 20, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-4PRDOKG9fFx"}, "source": ["***A vous:*** Quels sont les vents dominants ?"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "_8im1ttOWlRB"}, "source": ["### Transformons le temps"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "7YE21HKK40zQ"}, "source": ["Je r\u00e9cup\u00e8re mon temps en seconde."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "LIFf-VjMfnh3", "executionInfo": {"status": "ok", "timestamp": 1763374307491, "user_tz": -60, "elapsed": 2, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["timestamp_s = data_frame.index.map(datetime.datetime.timestamp)"], "execution_count": 21, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "EC_pnM1D5Sgc"}, "source": ["Tout comme la direction du vent, le temps en secondes n'est pas une entr\u00e9e facile \u00e0 interpr\u00e9ter pour les mod\u00e8les: Rappelons que c'est mod\u00e8les font des multiplications/addition/activation sur les donn\u00e9es de bases et que les param\u00e8tres appris le sont sur une base statistique. Or le temps en seconde est une variable qui a une grande amplitude, et de plus chaque valeur apparait une unique fois! Pas facile de faire des stats avec des quantit\u00e9s qui ne se r\u00e9pettent pas.\n", "\n", "\n", "\n", "Or les donn\u00e9es m\u00e9t\u00e9orologiques suivent des p\u00e9riodicit\u00e9s quotidienne et annuelle tr\u00e8s naturelles.\n", "Une technique simple consiste alors \u00e0 utiliser sin et cos pour convertir l'heure absolue en un encodage indiquant la \"partie du jour\" et \"partie de l'ann\u00e9e\" (c'est les coordonn\u00e9e des \u00e9guilles des horloges):"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "MBfX6CDwax73", "executionInfo": {"status": "ok", "timestamp": 1763374307499, "user_tz": -60, "elapsed": 8, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["day = 24*60*60\n", "year = (365.2425)*day\n", "\n", "\n", "data_frame['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n", "data_frame['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n", "data_frame['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n", "data_frame['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"], "execution_count": 22, "outputs": []}, {"cell_type": "code", "metadata": {"id": "mXBbTJZfuuTC", "colab": {"base_uri": "https://localhost:8080/", "height": 472}, "executionInfo": {"status": "ok", "timestamp": 1763374307623, "user_tz": -60, "elapsed": 123, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a0617c84-1d73-4601-987c-34f0d793aa36"}, "source": ["plt.plot(np.array(data_frame['Day sin'])[:100])\n", "plt.plot(np.array(data_frame['Day cos'])[:100])\n", "plt.xlabel('Time [h]')\n", "plt.title('Time of day signal');"], "execution_count": 23, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "HiurzTGQgf_D"}, "source": ["Cette convertion permet au mod\u00e8le d'acc\u00e9der aux caract\u00e9ristiques fr\u00e9quentielle les plus importantes. Dans notre cas, nous savions \u00e0 l'avance quelles fr\u00e9quences \u00e9taient importantes.\n", "\n", "Si on ne connaissait pas les fr\u00e9quences principales, on aurait pu les d\u00e9terminer avec la `fft`:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "EN4U1fcMiTYs", "colab": {"base_uri": "https://localhost:8080/", "height": 455}, "executionInfo": {"status": "ok", "timestamp": 1763374309587, "user_tz": -60, "elapsed": 843, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "8f49510b-0dab-46ca-aac7-c34590975652"}, "source": ["fft = tf.signal.rfft(data_frame['T (degC)'])\n", "f_per_dataset = np.arange(0, len(fft))\n", "\n", "n_samples_h = len(data_frame['T (degC)'])\n", "hours_per_year = 24*365.2524\n", "years_per_dataset = n_samples_h/(hours_per_year)\n", "\n", "f_per_year = f_per_dataset/years_per_dataset\n", "plt.step(f_per_year, np.abs(fft))\n", "plt.xscale('log')\n", "plt.ylim(0, 400000)\n", "plt.xlim([0.1, max(plt.xlim())])\n", "plt.xticks([1, 365.2524], labels=['1/Year', '1/day'])\n", "_ = plt.xlabel('Frequency (log scale)')"], "execution_count": 24, "outputs": []}, {"cell_type": "markdown", "source": ["### On supprime les noms de colonnes"], "metadata": {"id": "hIgZa0c9sx5j"}, "outputs": []}, {"cell_type": "code", "source": ["data_frame.columns"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "rcVd2GJRs4ML", "executionInfo": {"status": "ok", "timestamp": 1763374309599, "user_tz": -60, "elapsed": 8, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "5740f087-4f80-4839-a093-b120e74d994f"}, "execution_count": 25, "outputs": []}, {"cell_type": "code", "source": ["data_frame_clean=data_frame.drop(['wv (m/s)', 'max. wv (m/s)','wd (deg)'],axis=1)"], "metadata": {"id": "fPmH4sb3tA2G", "executionInfo": {"status": "ok", "timestamp": 1763374309601, "user_tz": -60, "elapsed": 1, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 26, "outputs": []}, {"cell_type": "markdown", "source": ["Avec `.values` on ne garde que oublie les noms des colonnes."], "metadata": {"id": "rnFAlpKYu0HL"}, "outputs": []}, {"cell_type": "code", "source": ["MAT_np=data_frame_clean.values.astype(np.float32)\n", "MAT_np.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "K3dbKZrauTqY", "executionInfo": {"status": "ok", "timestamp": 1763374309606, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "afe7543b-514e-4bc0-c742-05e1c06debd7"}, "execution_count": 27, "outputs": []}, {"cell_type": "code", "source": ["MAT_jnp=jnp.array(MAT_np)"], "metadata": {"id": "6M6l5EuFufLO", "executionInfo": {"status": "ok", "timestamp": 1763374311691, "user_tz": -60, "elapsed": 2084, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 28, "outputs": []}, {"cell_type": "code", "source": ["MAT_jnp.devices()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "7EXCsr9vmB3f", "executionInfo": {"status": "ok", "timestamp": 1763374311707, "user_tz": -60, "elapsed": 13, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "650e7b58-e9ab-4572-f21d-4eb6925989ac"}, "execution_count": 29, "outputs": []}, {"cell_type": "markdown", "source": ["\u21d1 si vous avez acc\u00e8s \u00e0 un GPU, les donn\u00e9es sont maintenant sur GPU (sinon cela fonctionnera plus lentement)."], "metadata": {"id": "8f3mq_GumHaE"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "2rbL8bSGDHy3"}, "source": ["### S\u00e9paration Train/Val/Test"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "qoFJZmXBaxCc"}, "source": ["On utilise le d\u00e9coupage `(70%, 20%, 10%)` pour les ensembles training, validation, et test.\n", "\n", "On d\u00e9coupe par grand segment temporelles:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "ia-MPAHxbInX", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1763374312195, "user_tz": -60, "elapsed": 480, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "34b3f848-38db-4beb-eb25-697589bb5854"}, "source": ["n = len(data_frame)\n", "n1,n2=int(n*0.7), int(n*0.9)\n", "\n", "\n", "TRAIN_MAT = MAT_jnp[0:n1]\n", "VAL_MAT = MAT_jnp[n1:n2]\n", "TEST_MAT = MAT_jnp[n2:]\n", "\n", "TRAIN_MAT.shape, VAL_MAT.shape, TEST_MAT.shape"], "execution_count": 30, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-eFckdUUHWmT"}, "source": ["### Normalisation\n"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "mxbIic5TMlxx"}, "source": ["La moyenne et l'\u00e9cart type doivent \u00eatre calcul\u00e9s uniquement \u00e0 l'aide des donn\u00e9es d'apprentissage afin que les mod\u00e8les n'aient pas acc\u00e8s aux valeurs des ensembles de validation et de test.\n", "\n", "On peut \u00e9galement dire que le mod\u00e8le ne devrait pas avoir acc\u00e8s aux valeurs futures de l'ensemble d'entra\u00eenement lors de l'entra\u00eenement. Ainsi la normalisation devrait \u00eatre effectu\u00e9e \u00e0 l'aide de moyennes mobiles non-anticipative. Mais par souci de simplicit\u00e9, ce tutoriel utilise une moyenne simple.\n"], "outputs": []}, {"cell_type": "code", "source": ["train_mean = TRAIN_MAT.mean(axis=0,keepdims=True)\n", "train_std = TRAIN_MAT.std(axis=0,keepdims=True)\n", "train_mean.shape,train_std.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "WptkzBOxwCEX", "executionInfo": {"status": "ok", "timestamp": 1763374312407, "user_tz": -60, "elapsed": 211, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "32486dc4-5ac5-4124-de0a-54e6e58e7956"}, "execution_count": 31, "outputs": []}, {"cell_type": "code", "metadata": {"id": "Eji6njXvHusN", "executionInfo": {"status": "ok", "timestamp": 1763374312683, "user_tz": -60, "elapsed": 275, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["TRAIN_MAT = (TRAIN_MAT - train_mean) / train_std\n", "VAL_MAT = (VAL_MAT - train_mean) / train_std\n", "TEST_MAT = (TEST_MAT - train_mean) / train_std"], "execution_count": 32, "outputs": []}, {"cell_type": "code", "source": ["TRAIN_MAT.shape, VAL_MAT.shape, TEST_MAT.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "sZBV50UR0JLb", "executionInfo": {"status": "ok", "timestamp": 1763374312704, "user_tz": -60, "elapsed": 16, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b1399a35-08ab-4dbd-a6e5-955b2cac9c3b"}, "execution_count": 33, "outputs": []}, {"cell_type": "markdown", "source": ["### Un plot de v\u00e9rif"], "metadata": {"id": "lH78-Z8KOt95"}, "outputs": []}, {"cell_type": "code", "source": ["titles=list(data_frame_clean.keys())"], "metadata": {"id": "X68L717oxuI3", "executionInfo": {"status": "ok", "timestamp": 1763374312706, "user_tz": -60, "elapsed": 1, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 34, "outputs": []}, {"cell_type": "code", "source": ["fig,axs=plt.subplots(19,1,figsize=(2,20),sharex=\"all\")\n", "for i in range(19):\n", "    axs[i].hist(TRAIN_MAT[:,i],bins=50)\n", "    axs[i].set_title(titles[i])\n", "fig.tight_layout()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "_iQQSFLexRec", "executionInfo": {"status": "ok", "timestamp": 1763374315700, "user_tz": -60, "elapsed": 2967, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "be9d69b0-3f6e-40ae-bcdb-5a307661d4ae"}, "execution_count": 35, "outputs": []}, {"cell_type": "markdown", "source": ["***A vous:*** Comment expliquer la forme bizarre des derniers histogrammes ?"], "metadata": {"id": "VyMMXj9iyN4C"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ZBBmdxZ2HgfJ"}, "source": ["## Fen\u00eatrage\n", "\n", "On va utiliser la fonction suivante pour fen\u00e9trer nos donn\u00e9es. Observons l\u00e0 sur des donn\u00e9es bidons:"], "outputs": []}, {"cell_type": "code", "source": ["#donn\u00e9es bidons pour les tests.\n", "nb_t, dim = 8, 3\n", "T = jnp.arange(0, nb_t)\n", "ones = jnp.ones([ nb_t,dim])\n", "DATA_dummy = ones * T[ :, None]"], "metadata": {"id": "1fCCxEsh1DuM", "executionInfo": {"status": "ok", "timestamp": 1763374315779, "user_tz": -60, "elapsed": 74, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 36, "outputs": []}, {"cell_type": "code", "source": ["DATA_dummy"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "UNbfY2H41FPq", "executionInfo": {"status": "ok", "timestamp": 1763374315787, "user_tz": -60, "elapsed": 6, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "f94aa2b6-2adb-42ce-c857-c5e4a6a052a0"}, "execution_count": 37, "outputs": []}, {"cell_type": "markdown", "source": ["\u21d1 une s\u00e9rie temporelle avec `seq_len`=8 et de dimension 3."], "metadata": {"id": "Baauza88nESf"}, "outputs": []}, {"cell_type": "markdown", "source": ["### tous les d\u00e9calages possibles"], "metadata": {"id": "qXuS0auvpdba"}, "outputs": []}, {"cell_type": "code", "source": ["def make_consecutive_windows(data,window_size):\n", "    nb_t = data.shape[0]\n", "    nb_possible_windows = nb_t - window_size + 1\n", "    all_shifts = []\n", "    for i in range(window_size):\n", "        # on cr\u00e9e tous les d\u00e9calages possibles.\n", "        all_shifts.append(data[i:nb_possible_windows + i])\n", "\n", "    all_shifts_stack = jnp.stack(all_shifts, axis=0)\n", "    dim=len(all_shifts_stack.shape)\n", "    axes=tuple(range(dim))\n", "    axes_perm=(1,0)+axes[2:]\n", "\n", "    return jnp.transpose(all_shifts_stack,axes_perm)"], "metadata": {"id": "vxpSBQRvtufz", "executionInfo": {"status": "ok", "timestamp": 1763374315793, "user_tz": -60, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 38, "outputs": []}, {"cell_type": "code", "source": ["def make_consecutive_windows(data,window_size):\n", "    nb_t = data.shape[0]\n", "    nb_possible_windows = nb_t - window_size + 1\n", "    all_shifts = []\n", "    for i in range(window_size):\n", "        # on cr\u00e9e tous les d\u00e9calages possibles.\n", "        all_shifts.append(data[i:nb_possible_windows + i])\n", "\n", "    all_shifts_stack = jnp.stack(all_shifts, axis=0)\n", "\n", "    #les fen\u00eatres sont les colonnes de la matrice. On les transforme en ligne.\n", "    return all_shifts_stack.T"], "metadata": {"id": "kMhRL5UzS2Xl", "executionInfo": {"status": "ok", "timestamp": 1763374364735, "user_tz": -60, "elapsed": 40, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 39, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    res=make_consecutive_windows(DATA_dummy,window_size=4) #b,nb_window*window_size (all shift),window_size,nb_part,dimX\n", "    print(res)\n", "    print(res.shape)\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "oCqOGlmbuAtF", "executionInfo": {"status": "ok", "timestamp": 1763374366592, "user_tz": -60, "elapsed": 152, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "83f9edaf-b67c-438b-b011-f50ed0c2ab16"}, "execution_count": 40, "outputs": []}, {"cell_type": "markdown", "source": ["On a cette shape `(5,4,3)` car:\n", "\n", "* 5 fen\u00eatres possibles\n", "* chacune de taille 4\n", "* dimensions des donn\u00e9es pour un temps: 3"], "metadata": {"id": "rV3cJ4J_r1Ns"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Par batch"], "metadata": {"id": "1Jdm7So03L0e"}, "outputs": []}, {"cell_type": "markdown", "source": ["Voici maintenant une classe qui permet de batcher des donn\u00e9es"], "metadata": {"id": "ArYn2PsLzMUy"}, "outputs": []}, {"cell_type": "code", "source": ["def batcher(data,batch_size):\n", "    size0 = data.shape[0]\n", "\n", "    data=data[np.random.permutation(size0)]\n", "    nb_batch=size0//batch_size\n", "\n", "\n", "    for i in range(nb_batch):\n", "        batch=data[i*batch_size:(i+1)*batch_size]\n", "        yield batch"], "metadata": {"id": "CD4kc5W1tmzy"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    data=jnp.arange(22)\n", "    for x in batcher(data,5):\n", "        print(x)\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "HIwjr35tsKDz", "executionInfo": {"status": "ok", "timestamp": 1761049439409, "user_tz": -120, "elapsed": 24, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "3d5b45a7-0b8a-4451-dbed-d0c50df9dc65"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Mais pour notre sujet, les \u00e9l\u00e9ments du batchs sont des fen\u00eatres"], "metadata": {"id": "OXi6xkljs21J"}, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    data_window=make_consecutive_windows(DATA_dummy,window_size=4) #b,nb_window*window_size (all shift),window_size,nb_part,dimX\n", "\n", "    for batch in batcher(data_window,batch_size=2):\n", "        print(batch)\n", "        print(\"-------------\")\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "k-8uoWLluX0P", "executionInfo": {"status": "ok", "timestamp": 1761049440193, "user_tz": -120, "elapsed": 12, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "36aa8251-e281-4ed5-a778-7201738da355"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Remarquons qu'on peut aussi tout distribuer en un seul batch:"], "metadata": {"id": "cm5m1n9pRqsx"}, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    data_window=make_consecutive_windows(DATA_dummy,window_size=4) #b,nb_window*window_size (all shift),window_size,nb_part,dimX\n", "\n", "    for batch in batcher(data_window,batch_size=len(data_window)):\n", "        print(batch)\n", "        print(\"-------------\")\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "Q1_-4GaZtETl", "executionInfo": {"status": "ok", "timestamp": 1761049440972, "user_tz": -120, "elapsed": 12, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "504306c1-631e-4a03-c448-e1be164401ed"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "BoHCEZp9ZnZ9"}, "source": ["### L'output\n", "\n", "Pour un probl\u00e8me de pr\u00e9diction, l'output, c'est simplement l'input d\u00e9caler dans le temps:"], "outputs": []}, {"cell_type": "markdown", "source": ["\n", "\n", "* L'input c'est une fen\u00eatre de taille $N$:\n", "\n", "$\n", "X_{0} \\ X_{1} \\ X_{2} \\ X_{3} \\ \\dots \\ \\dots \\ \\dots\\ \\dots X_{N-1}   \n", "$\n", "\n", "\n", "* L'output c'est cette fen\u00eatre translat\u00e9 d'un shift $s$ impos\u00e9:\n", "\n", "$\n", "X_{s} \\ X_{s+1} \\ X_{s+2} \\ X_{s+3} \\ \\dots X_{s+N-1}   \n", "$\n", "\n", "\n", "\n", "\n", "\n", "    \n", "\n"], "metadata": {"id": "aInp7OpoMjS_"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "LYpA5WjdzV3f"}, "source": ["On va param\u00e9trer notre distributeur de donn\u00e9es avec:\n", "* `input_duration`\n", "* `shift`\n"], "outputs": []}, {"cell_type": "code", "source": ["class DataDealer:\n", "    def __init__(self,data,input_duration,shift,batch_size):\n", "\n", "        self.dimension_to_keep=2 #temp\u00e9rature et pression\n", "\n", "\n", "        if input_duration is None:\n", "            input_duration=data.shape[0]-shift #taille maximale: une seule fen\u00eatre\n", "\n", "        self.input_duration=input_duration\n", "        self.output_duration=input_duration\n", "\n", "        window_size=input_duration+shift\n", "        assert window_size<=data.shape[0] , f\"On a input_duration={input_duration} et shift={shift}. Or la somme des deux doit \u00eatre inf\u00e9rieur {data.shape[0]} qui est la longueur de la s\u00e9rie temporelle \"\n", "\n", "\n", "        self.data_in_windows=make_consecutive_windows(data,window_size)\n", "\n", "\n", "        if batch_size is not None:\n", "            self.batch_size=batch_size\n", "        else:\n", "            self.batch_size=len(self.data_in_windows)#on passe tout en un seul batch\n", "\n", "\n", "    def one_epoch_iterator(self):\n", "        for window in batcher(self.data_in_windows,self.batch_size):\n", "\n", "            yield window[:,:self.input_duration,:],window[:,-self.output_duration:,:self.dimension_to_keep]\n", "\n"], "metadata": {"id": "QgfLRnNhvl1q"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "rStC2tGZ0YFV"}, "source": ["Testons:"], "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    data_dealer=DataDealer(DATA_dummy,input_duration=3,shift=2,batch_size=2)\n", "\n", "    for x,y in data_dealer.one_epoch_iterator():\n", "        print(\"x\")\n", "        print(x)\n", "        print(\"y\")\n", "        print(y)\n", "        print(\"-----------\")\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "mDQdAXxQw4ku", "executionInfo": {"status": "ok", "timestamp": 1761049444173, "user_tz": -120, "elapsed": 13, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6902f16d-241f-4665-ad07-1be95e192776"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    #un seul batch et une fen\u00eatre de taille maximale\n", "    data_dealer=DataDealer(DATA_dummy,input_duration=None,shift=2,batch_size=None)\n", "\n", "    for x,y in data_dealer.one_epoch_iterator():\n", "        print(\"x\")\n", "        print(x)\n", "        print(\"y\")\n", "        print(y)\n", "        print(\"-----------\")\n", "test()"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "nFDCE4IRalwH", "executionInfo": {"status": "ok", "timestamp": 1761049444819, "user_tz": -120, "elapsed": 13, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a6333577-b274-41e5-c5ca-6187e30f12de"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "K16rFYO0_q18"}, "source": ["### Illustration graphique sur des donn\u00e9es bidons"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "8eARrkl8iF46"}, "source": ["def plot_ds(data,input_duration,shift):\n", "\n", "    batch_size=2\n", "\n", "\n", "    data_dealer=DataDealer(data,input_duration,shift,batch_size)\n", "\n", "\n", "    X,Y = next(data_dealer.one_epoch_iterator())\n", "\n", "    fig,axs=plt.subplots(batch_size,2,figsize=(15,10),sharex=\"all\")\n", "\n", "    output_duration=input_duration\n", "    deb_output=input_duration+shift-output_duration\n", "    abs_output=np.arange(deb_output,deb_output+output_duration)\n", "\n", "    abs_input=np.arange(input_duration)\n", "\n", "    for i in range(batch_size):\n", "\n", "        axs[i,0].plot(abs_input, X[i,:,0],\"o-\",label=\"X\")\n", "        axs[i,0].plot(abs_output,Y[i,:,0],\"+-\",label=\"Y\")\n", "\n", "        axs[i,1].plot(abs_input, X[i,:,1],\"o-\",label=\"X\")\n", "        axs[i,1].plot(abs_output,Y[i,:,1],\"+-\",label=\"Y\")\n", "\n", "    plt.legend()\n", "    axs[0,0].set_title(\"temp\u00e9rature\")\n", "    axs[0,1].set_title(\"pression\")"], "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plot_ds(DATA_dummy,input_duration=3,shift=4)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 656}, "id": "BmdolP_wp_ph", "executionInfo": {"status": "ok", "timestamp": 1761049447034, "user_tz": -120, "elapsed": 548, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "155e9c43-8b1c-47cd-b7ae-4827c0faa04b"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plot_ds(DATA_dummy,input_duration=3,shift=1)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 649}, "id": "NjjyfopMqCVC", "executionInfo": {"status": "ok", "timestamp": 1761049448397, "user_tz": -120, "elapsed": 523, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "7ace47c7-d830-4f35-a4fd-f0c573294417"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["\u21d1 Ce n'est pas grave si l'input et l'output se superposent, car les mod\u00e8les RNN sont non-anticipatif:\n", "$$\n", "\\forall t \\qquad model(X_t) = fonction(X_t,X_{t-1},X_{t-2},...)\n", "$$"], "metadata": {"id": "aJ5qzVqXSdWm"}, "outputs": []}, {"cell_type": "markdown", "source": ["Sur les vraies donn\u00e9es"], "metadata": {"id": "ryQ58EMxPTX_"}, "outputs": []}, {"cell_type": "code", "source": ["TRAIN_MAT.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "f17N-BOr_ToY", "executionInfo": {"status": "ok", "timestamp": 1761049448767, "user_tz": -120, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bffdedc6-643f-4e7a-9bd1-90c392e0fee5"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plot_ds(TRAIN_MAT,input_duration=12,shift=2)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 644}, "id": "1b5PXtaMN86K", "executionInfo": {"status": "ok", "timestamp": 1761049450673, "user_tz": -120, "elapsed": 1225, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bb262c62-378d-4724-e2cb-426e511e2c42"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## PARAMETRE GLOBAUX"], "metadata": {"id": "-YFJAGLhMPai"}, "outputs": []}, {"cell_type": "code", "source": ["SHIFT=3 #on pr\u00e9dit 3 heures \u00e0 l'avance\n", "N_EPOCH= 10 #Cela ira assez vite. N'h\u00e9sitez pas \u00e0 augmenter ce chiffre"], "metadata": {"id": "RiHmF8_TMUGM"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["import pickle\n", "from dataclasses import dataclass\n", "from typing import Callable\n", "import optax"], "metadata": {"id": "_f597py9qrJh"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Mod\u00e8le et agent"], "metadata": {"id": "S9-CIkPCrWhq"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Mod\u00e8le"], "metadata": {"id": "OG9BIkOwS67A"}, "outputs": []}, {"cell_type": "code", "source": ["class RNN_layer(eqx.Module):\n", "    hidden_size: int\n", "    cell: eqx.Module\n", "\n", "    def __init__(self, in_size, out_size, hidden_size,cell_type,rkey):\n", "        assert cell_type in [\"gru\",\"lstm\"]\n", "\n", "        self.hidden_size = hidden_size\n", "        if cell_type==\"gru\":\n", "            self.cell = eqx.nn.GRUCell(in_size, hidden_size, key=rkey)\n", "        else:\n", "            self.cell = eqx.nn.LSTMCell(in_size, hidden_size, key=rkey)\n", "\n", "\n", "    def __call__(self, input):\n", "\n", "        h_init = jnp.zeros((self.hidden_size,))\n", "\n", "        def f(carry, inp):\n", "            h=self.cell(inp, carry)\n", "            #return 2 fois h: le premier pour \u00eatre utilis\u00e9 par le prochain appelle de la cellule, le second pour \u00eatre stocker dans les outputs\n", "            return h, h\n", "\n", "        h_final, output = lax.scan(f, h_init, input)\n", "\n", "        return output"], "metadata": {"id": "mSpSqsksg_2n"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["class RNN_model(eqx.Module):\n", "    layers: list[eqx.Module]\n", "    final_layer: eqx.nn.Linear\n", "    initial_layer: eqx.nn.Linear\n", "\n", "    def __init__(self, in_size, out_size, hidden_size, n_layer,cell_type, rkey):\n", "\n", "        self.initial_layer = eqx.nn.Linear(in_size, hidden_size, key=rkey)\n", "        self.final_layer = eqx.nn.Linear(hidden_size, out_size, key=rkey)\n", "\n", "        self.layers=[]\n", "        for _ in range(n_layer):\n", "            rk,rkey=jr.split(rkey)\n", "            self.layers.append(RNN_layer(hidden_size, hidden_size, hidden_size,cell_type,rk))\n", "\n", "\n", "    def __call__(self, input):\n", "\n", "        X=vmap(self.initial_layer)(input)\n", "        for layer in self.layers:\n", "            X=layer(X)\n", "        return vmap(self.final_layer)(X)"], "metadata": {"id": "eYJCRDeHhogX"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["***A vous:*** Expliquer \u00e0 quoi sert les 2 vmap qui apparaissent dans la m\u00e9thode `__call__`"], "metadata": {"id": "QC-llURUKUl3"}, "outputs": []}, {"cell_type": "markdown", "source": ["Remarque: on pourrait vouloir mettre ces 2 `vmap` dans le constructeur:\n", "\n", "\n", "    def __init__(self, in_size, out_size, hidden_size, n_layer,cell_type, rkey):\n", "\n", "            self.initial_layer = vmap(eqx.nn.Linear(in_size, hidden_size, key=rkey))\n", "            self.final_layer = vmap(eqx.nn.Linear(hidden_size, out_size, key=rkey))\n", "\n", "\n", "Mais dans ce cas on a un warning d'equinox tr\u00e8s explicite: si l'on applique un transformation-jax dans le constructeur, les param\u00e9tres de la fonctions transform\u00e9e ne seront plus collect\u00e9e par le `eqx.partition`, et donc ne seront pas entrain\u00e9e.\n", "\n", "\n"], "metadata": {"id": "Hr1hYJprk_S_"}, "outputs": []}, {"cell_type": "code", "source": ["def test():\n", "    seq_len=24\n", "    in_size=7\n", "    out_size=3\n", "    hidden_size=32\n", "    input=jnp.ones([seq_len,in_size])\n", "    n_layer=2\n", "    cell_type=\"gru\"\n", "    rkey=jr.key(0)\n", "    model=RNN_model(in_size, out_size, hidden_size, n_layer,cell_type, rkey)\n", "    assert model(input).shape == (24,3)\n", "test()"], "metadata": {"id": "qTfFGRD5S8at"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def model_fnm(hyper_param):\n", "\n", "    in_size=19\n", "    out_size=2\n", "    hidden_size=hyper_param[\"hidden_size\"]\n", "    n_layer=hyper_param[\"n_layer\"]\n", "    cell_type=hyper_param[\"cell_type\"]\n", "\n", "\n", "    def model_init(rkey):\n", "        model_eqx=RNN_model(in_size, out_size, hidden_size, n_layer,cell_type, rkey)\n", "        param,_ = eqx.partition(model_eqx,eqx.is_array)\n", "        return param\n", "\n", "\n", "    model_eqx=RNN_model(in_size, out_size, hidden_size, n_layer,cell_type, jr.key(0))\n", "\n", "    def model_apply(param,inp):\n", "        _,static = eqx.partition(model_eqx,eqx.is_array)\n", "        return eqx.combine(static,param)(inp)\n", "\n", "\n", "    return model_init, jit(model_apply)\n", "\n", "\n", "\n", "def test():#on fait un test en batch\n", "    hyper_param={\"hidden_size\":32,\"n_layer\":2,\"cell_type\":\"gru\"}\n", "    batch_size=13\n", "    inpV=jnp.ones([batch_size,24,19])\n", "\n", "    model_init,U_of_param_inp=model_fnm(hyper_param)\n", "\n", "    U_of_param_inpV=vmap(U_of_param_inp,[None,0])\n", "    param=model_init(jr.key(0))\n", "    assert U_of_param_inpV(param,inpV).shape == (batch_size,24,2)\n", "test()\n"], "metadata": {"id": "OkEzw-PgUReW"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### fonctions de loss et d'update"], "metadata": {"id": "VelA_Emj2ir2"}, "outputs": []}, {"cell_type": "code", "source": ["def jit_creator(U_of_param_inpV,optimizer):\n", "    @jax.jit\n", "    def loss_compute(params, X,Y):\n", "        Y_pred=U_of_param_inpV(params,X)\n", "        return jnp.mean((Y_pred-Y)**2)\n", "\n", "    @jax.jit\n", "    def update_model_param(optimizer_state, model_param, X,Y):\n", "        grads = jax.grad(loss_compute)(model_param, X,Y)\n", "        updates, optimizer_state = optimizer.update(grads, optimizer_state)\n", "        #here the model_param is modified\n", "        model_param = optax.apply_updates(model_param, updates)\n", "        return optimizer_state, model_param\n", "\n", "    return loss_compute,update_model_param"], "metadata": {"id": "jJvQsieV2n81"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Fonctions de sauvegarde"], "metadata": {"id": "Mb1GOjcmK-sB"}, "outputs": []}, {"cell_type": "code", "source": ["def save_as_pickle(file_name,serializable):\n", "    pickle.dump(serializable,open(file_name,\"wb\"))\n", "def load_from_pickle(file_name):\n", "    return pickle.load(open(file_name,\"rb\"))\n", "def save_as_str(file_name,serializable):\n", "    with open(file_name, \"wt\") as f:\n", "        f.write(str(serializable))\n", "def load_from_str(file_name):\n", "    with open(file_name, \"rt\") as f:\n", "        res = eval(f.read())\n", "    return res"], "metadata": {"id": "xRl3y94NK9Sr"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### L'Agent en personne"], "metadata": {"id": "rjNptirZLaH7"}, "outputs": []}, {"cell_type": "code", "source": ["import time\n", "\n", "@dataclass\n", "class AgentResult:\n", "    hyper_param:dict\n", "    best_loss:float\n", "    score:float\n", "    model_param:dict\n", "    U_of_param_inp:Callable\n", "\n", "\n", "class Agent:\n", "    @staticmethod\n", "    def load(folder):\n", "        assert os.path.exists(folder),f\"folder:{folder} does not exist\"\n", "        model_param = load_from_pickle(f\"{folder}/model_param\")\n", "        best_loss = load_from_str(f\"{folder}/best_loss\")\n", "        score = load_from_str(f\"{folder}/score\")\n", "        model_param=load_from_pickle(f\"{folder}/model_param\")\n", "        hyper_param=load_from_str(f\"{folder}/hyper_param\")\n", "        _,U_of_param_inp=model_fnm(hyper_param)\n", "        return AgentResult(hyper_param,best_loss,score,model_param,U_of_param_inp)\n", "\n", "\n", "    @staticmethod\n", "    def train(folder,hyper_param,n_epoch=N_EPOCH,verbose=True):\n", "\n", "\n", "        train_data_dealer=DataDealer(TRAIN_MAT,input_duration=hyper_param[\"input_duration\"],shift=SHIFT,batch_size=hyper_param[\"batch_size\"])\n", "\n", "        #batch_size=None, toutes les donn\u00e9es en 1 seul batch\n", "        val_data_dealer=DataDealer(VAL_MAT,input_duration=hyper_param[\"input_duration\"],shift=SHIFT,batch_size=None)\n", "        x_val,y_val=next(val_data_dealer.one_epoch_iterator())\n", "\n", "        model_init, U_of_param_inp = model_fnm(hyper_param)\n", "\n", "        U_of_param_inpV=vmap(U_of_param_inp,[None,0])\n", "\n", "        optimizer = optax.adam(hyper_param[\"learning_rate\"])\n", "        batch_size = hyper_param[\"batch_size\"]\n", "\n", "        if os.path.exists(folder):\n", "            if verbose:\n", "                print(f\"Existing folder:{folder}, we load model_param and best_loss from if\")\n", "            model_param = load_from_pickle(f\"{folder}/model_param\")\n", "            best_loss =load_from_str(f\"{folder}/best_loss\")\n", "\n", "        else:#c'est la premi\u00e8re fois qu'on teste cet hyper_param\u00e8tre.\n", "            os.makedirs(folder, exist_ok=True)\n", "            if verbose:\n", "                print(f\"New folder:{folder}, model_param are randomly initialized\")\n", "            model_param=model_init(jr.key(0))\n", "            best_loss=1e10#l'infini ou presque\n", "            save_as_pickle(f\"{folder}/model_param\", model_param)\n", "            save_as_str(f\"{folder}/best_loss\", best_loss)\n", "\n", "        save_as_str(f\"{folder}/hyper_param\", hyper_param)\n", "        optimizer_state=optimizer.init(model_param)\n", "\n", "        loss_compute, update_model_param=jit_creator(U_of_param_inpV,optimizer)\n", "\n", "\n", "        ti0=time.time()\n", "        for _ in range(n_epoch):\n", "\n", "            for x,y in train_data_dealer.one_epoch_iterator():\n", "                optimizer_state, model_param = update_model_param(optimizer_state, model_param, x,y)\n", "\n", "            val_loss=loss_compute(model_param, x_val, y_val)\n", "            if val_loss <= best_loss:\n", "                best_loss=val_loss\n", "                if verbose:\n", "                    print(f\"\u2b0a{val_loss:.3g}\", end=\"\")\n", "                save_as_pickle(f\"{folder}/model_param\",model_param)\n", "                save_as_str(f\"{folder}/best_loss\",best_loss)\n", "            else:\n", "                if verbose:\n", "                    print(\".\",end=\"\")\n", "        if verbose:\n", "            print(\"| end of the optimization loop.\")\n", "\n", "        val_loss.block_until_ready()\n", "        duration=time.time()-ti0\n", "\n", "        score=best_loss*duration\n", "        save_as_str(f\"{folder}/score\",score)\n", "\n", "        return score #utile si on utiliser hyperopt par exemple.\n"], "metadata": {"id": "vcg52BBsLfNt"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "D1bbPiR3VAm_"}, "source": ["### Baseline\n", "\n", "Il est toujours bon d'avoir une pr\u00e9diction triviale (une BaseLine) que nos mod\u00e8les plus complexe doivent absolument battre.\n", "\n", "Pour pr\u00e9dire la temp\u00e9rature dans le future, on peut simplement donner la temp\u00e9rature actuelle. C'est valable si le future n'est pas trop lointain.\n", "\n", "\n", "Ainsi si notre s\u00e9rie temporelle est `data`. L'entr\u00e9e c'est\n", "\n", "\n", "    X=data[:-shift,:]\n", "\n", "La cible c'est\n", "\n", "    Y=data[shift:,[0,1]]\n", "\n", "La pr\u00e9diction triviale c'est simplement:\n", "\n", "    Y_pred=X[:-shift,[0,1]]\n", "\n", "\n", "\n", "***A vous:***\n", "\n", "* si `shift=1` la baseline sera meilleure que si `shift=12`\n", "* mais si `shift=24` la baseline sera meilleure que si `shift=12`\n", "\n", "Pourquoi ?\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "AhLeg_HsRecx"}, "source": ["def evaluate_base_line(shift):\n", "    X=VAL_MAT\n", "    Y=X[shift:,[0,1]]\n", "    Y_pred=X[:-shift,[0,1]]\n", "    return jnp.mean(jnp.square(Y-Y_pred))"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 167}, "id": "JnrWLpb1UIUf", "executionInfo": {"status": "error", "timestamp": 1763105460999, "user_tz": -60, "elapsed": 16, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "4dc1380b-159e-4851-82f8-bec5f75d4b1f"}, "source": ["mse_baseline=evaluate_base_line(SHIFT)\n", "mse_baseline"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## Entrainement"], "metadata": {"id": "KMh7y_wwu3Lk"}, "outputs": []}, {"cell_type": "markdown", "source": ["###  c'est parti"], "metadata": {"id": "vqrCgDxx9UOF"}, "outputs": []}, {"cell_type": "code", "source": ["import shutil\n", "\n", "mother_folder=\"varying_model_capacity\"\n", "#on part de z\u00e9ro\n", "shutil.rmtree(mother_folder,ignore_errors=True)\n", "\n", "for n_layer in [1,3]:\n", "    for hidden_size in [32,128]:\n", "        hyper_param={\"batch_size\":256,\"hidden_size\":hidden_size,\"n_layer\":n_layer,\"cell_type\":\"gru\",\"input_duration\":24,\"learning_rate\":1e-3}\n", "        folder=f\"{mother_folder}/n_layer:{n_layer},hidden_size:{hidden_size}\"\n", "        score=Agent.train(folder,hyper_param)\n", "        print(f\"score:{score}\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "ywQhPenr9WAe", "executionInfo": {"status": "ok", "timestamp": 1761049689933, "user_tz": -120, "elapsed": 53432, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "a4b71ddd-0d79-430d-820d-478da5f8bc07"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["\u21d1 Ensuite c'est \u00e0 vous de juger si vous voulez favoriser la rapidit\u00e9 ou la pr\u00e9cision. En tout cas, tous les mod\u00e8les font mieux que la base-line (ouf).  "], "metadata": {"id": "yOtBkhOMMSE5"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "twpLxC7Zb8Qv"}, "source": ["### Observons la pr\u00e9diction sur le jeu Test\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "QQOzOHWKZa-8"}, "source": ["def plot_prediction(folders,shift=SHIFT,add_baseline=False,up=200,model_names=None):\n", "    #on ne trace que les 'up' premiers temps\n", "    data=TEST_MAT\n", "\n", "\n", "    #La cyble, c'est les data d\u00e9cal\u00e9es\n", "    Y=data[shift:,[0,1]] #(nb_t-shift,2)\n", "    fig,axs=plt.subplots(2,1,figsize=(15,6),sharex=\"all\")\n", "\n", "    axs[0].plot(Y[:up,0],label=\"true\")\n", "    axs[1].plot(Y[:up,1],label=\"true\")\n", "\n", "    axs[0].set_title(\"pressure\")\n", "    axs[1].set_title(\"temperature\")\n", "\n", "    if add_baseline:\n", "        #la baseline, c'est de renvoyer simplement les data.\n", "        Y_baseline=data[:-shift,:3]\n", "        axs[0].plot(Y_baseline[:up,0],label=\"baseline\",alpha=0.5)\n", "        axs[1].plot(Y_baseline[:up,1],label=\"baseline\",alpha=0.5)\n", "\n", "\n", "    x=data[:-shift,:]   #(1,nb_t-shift,19)\n", "    for i,folder in enumerate(folders):\n", "        agentResult=Agent.load(folder)\n", "        U_of_inp=lambda inp : agentResult.U_of_param_inp(agentResult.model_param,inp)\n", "\n", "        Y_pred=U_of_inp(x)[:,:3]\n", "        label=\"pred\"\n", "        if model_names is not None:\n", "            label+=model_names[i]\n", "        axs[0].plot(Y_pred[:up,0],label=label)\n", "        axs[1].plot(Y_pred[:up,1],label=label)\n", "\n", "\n", "    axs[0].legend()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["folder_mini=f\"{mother_folder}/n_layer:{1},hidden_size:{32}\"\n", "folder_maxi=f\"{mother_folder}/n_layer:{3},hidden_size:{128}\""], "metadata": {"id": "LtwZk8iY82_k"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["plot_prediction([folder_mini,folder_maxi],add_baseline=True,model_names=[\" model mini\",\" model maxi\"])"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 413}, "id": "bpw3ztfG87p2", "executionInfo": {"status": "ok", "timestamp": 1761049729827, "user_tz": -120, "elapsed": 1295, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "84015578-eadf-4073-f107-d58fd8d5ff2e"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### Influence de la longueur des s\u00e9quences"], "metadata": {"id": "BM9x2JEoRu13"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "lmBbRAzeqbOg"}, "source": ["Pour l'entrainement d'un RNN, les grandes fen\u00eatres sont pr\u00e9f\u00e9rables. Mais il ne faut pas non plus prendre des fen\u00eatre temporelles trop longue car:\n", "\n", "* On pourra produire moins de donn\u00e9es ind\u00e9pendantes (les longues fen\u00eatre ayant tendance \u00e0 se superpose)\n", "* et il y a le ph\u00e9nom\u00e8ne de la disparition du gradient: si l'on prend des fen\u00eatres d'entrainement trop longue, le gradient l'erreur a du mal \u00e0 traverser toutes les cellules RNN: la d\u00e9riv\u00e9e d'une longue composition de fonction cr\u00e9e de longs produits qui finissent par \u00eatre nul (plus d'apprentissage) ou infini (explosion du gradient, \u00e9chec de l'apprentissage).\n", "\n", "\n", "Pour l'\u00e9valuation d'un RNN, autant prendre la fen\u00eatre la plus longue possible. Cela n'a pas d'inconv\u00e9nient, et il n'y a qu'un seul \u00e9chauffement \u00e0 faire au tout d\u00e9but."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "UcQmUeeyHWuu"}, "source": ["## Feature importance\n", "\n", "Comment savoir si une feature a plus d'importance qu'une autre dans le mod\u00e8le.\n", "\n", "Une technique simple est de calculer la d\u00e9riv\u00e9e du r\u00e9sultat du mod\u00e8le par rapport \u00e0 chacune des features."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ChPSXES0Jm3l"}, "source": ["Notre mod\u00e8le est une fonctions comme ceci:\n", "\\begin{align}\n", "M :  \\mathbb R^{T} *\\mathbb R^{19}& \\to \\mathbb R^{S}*\\mathbb R^2 \\\\\n", " (x_{t,i})  &\\to M(x)\n", "\\end{align}\n", "Dans notre exemple $S=T$.\n", "\n", "La loss c'est une fonction comme ceci:\n", "\\begin{align}\n", "L :  \\mathbb R^{T} *\\mathbb R^{19} &\\to \\mathbb R \\\\\n", "(x_{t,i})  &\\mapsto L(x) = \\|M(x) - Y_{true} \\|^2\n", "\\end{align}\n", "\n", "\n", "\n", "On cacul d'abord la d\u00e9riv\u00e9e par rapport \u00e0 chaque entr\u00e9e de la s\u00e9rie temporelle:\n", "$$\n", "G_{t,i} := \\partial_{x_{t,i}} L\n", "$$\n", "Puis on somme sur les temps:\n", "$$\n", "G_i =\\sum_t |G_{t,i}|\n", "$$"], "outputs": []}, {"cell_type": "code", "source": ["folder=f\"{mother_folder}/n_layer:{3},hidden_size:{128}\"\n", "agentResult=Agent.load(folder)\n", "U_of_\u03f4_x=agentResult.U_of_param_inp\n", "\u03f4=agentResult.model_param"], "metadata": {"id": "LEkxgBW8v0Xu"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["#les inputs de validation, que l'on renome x par simplicit\u00e9\n", "x=VAL_MAT[:-SHIFT,:]\n", "x.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "NAP0cnFKyHuy", "executionInfo": {"status": "ok", "timestamp": 1761050458957, "user_tz": -120, "elapsed": 8, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "280efb3b-e3ee-4a4e-dcf5-72110355b292"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["y_true=VAL_MAT[SHIFT:,[0,1]]\n", "y_true.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "8QDwhGrKyWSA", "executionInfo": {"status": "ok", "timestamp": 1761050470425, "user_tz": -120, "elapsed": 45, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "94210973-5ef4-42f9-ee03-cf59fa39468e"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["def loss_of_x(x):\n", "    y_pred=U_of_\u03f4_x(\u03f4,x)\n", "    return jnp.mean((y_pred-y_true)**2)"], "metadata": {"id": "A6Q3l-Ucw5ox"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["\u03b4xloss_at_x=jax.grad(loss_of_x)(x)\n", "\u03b4xloss_at_x.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "NPAtd0Hrwg8p", "executionInfo": {"status": "ok", "timestamp": 1761050517533, "user_tz": -120, "elapsed": 2902, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "0961686c-a763-4a65-a810-59b2ed165af1"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": ["G=jnp.mean(jnp.abs(\u03b4xloss_at_x),axis=0)\n", "G.shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "aHSgm7Cwy1kn", "executionInfo": {"status": "ok", "timestamp": 1761050612673, "user_tz": -120, "elapsed": 194, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b1e28a57-5a3c-46e4-9fa4-55d57e5edb85"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["Rappelons le noms de nos 19 features:"], "metadata": {"id": "mBw3D1-w3rvm"}, "outputs": []}, {"cell_type": "code", "source": ["feature_names=data_frame_clean.columns\n", "feature_names"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "c0wL4_DQ3fAb", "executionInfo": {"status": "ok", "timestamp": 1761050541845, "user_tz": -120, "elapsed": 44, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "91a4b7d8-de42-49fa-fa64-964338aa5cb9"}, "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "fD4d85JiJl5U", "colab": {"base_uri": "https://localhost:8080/", "height": 556}, "executionInfo": {"status": "ok", "timestamp": 1761050621571, "user_tz": -120, "elapsed": 440, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "82efa89e-1242-46cf-8087-670375552df8"}, "source": ["fig,ax=plt.subplots()\n", "x=range(19)\n", "ax.bar(x=x,height=G)\n", "ax.set_xticks(x)\n", "ax.set_xticklabels(feature_names, rotation=90);"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["On voit que pour pr\u00e9dire la m\u00e9t\u00e9o future du coin o\u00f9 l'on se trouve, il faut utiliser le barom\u00e9tre."], "metadata": {"id": "JdlNWuuUMpQq"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "YiuEQvpnwhGu"}, "source": ["Attention: ces mesures d'importance sont \u00e0 interpr\u00e9ter avec pr\u00e9caution: quand deux variable apportent des informations \u00e9quivalentes, les gradient en s\u00e9lectionne une au hasard."], "outputs": []}]}