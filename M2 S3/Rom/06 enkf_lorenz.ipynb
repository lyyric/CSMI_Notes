{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EnKF on the Lorenz-63 system\n",
        "Master 2 exercise: implement and analyze an Ensemble Kalman Filter (EnKF) on the Lorenz-63 model.\n",
        "Goals: (i) code Lorenz-63 and visualize chaos, (ii) illustrate the butterfly effect, (iii) assimilate noisy observations with an EnKF when the forecast model is imperfect (coarse time-stepping, parameter bias), (iv) discuss filters' behavior (spread, RMSE, inflation, partial obs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model and parameters\n",
        "Lorenz-63 ODE on $\\mathbb{R}^3$:\\n",
        "$\\dot x = \\sigma (y - x)$, $\\dot y = x(\\rho - z) - y$, $\\dot z = xy - \\beta z$.\\n",
        "Default: $\\sigma = 10$, $\\rho = 28$, $\\beta = 8/3$. Domain: all $\\mathbb{R}^3$, solutions stay on the Lorenz attractor for these parameters.\n",
        "Time step suggestion: $\\Delta t = 0.01$ with RK4 for a trusted \"truth\".\n",
        "Observations: full state with additive Gaussian noise $R = \\sigma_o^2 I$ unless otherwise specified.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.set_printoptions(precision=3, suppress=True)\nrng = np.random.default_rng(0)\nplt.style.use('seaborn-v0_8')\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q1. Implement the model and integrators\n",
        "Tasks:\n",
        "- Implement `lorenz63(x, sigma, rho, beta)`.\n",
        "- Implement `rk4_step` (reference integrator) and `euler_step` (coarse/degraded).\n",
        "- Quick test: integrate with RK4 for 2000 steps (dt=0.01) from x0=[1,1,1] and plot (x,z) projection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def lorenz63(x, sigma=10.0, rho=28.0, beta=8.0/3.0):\n    raise NotImplementedError\n\ndef rk4_step(f, x, dt, **kwargs):\n    raise NotImplementedError\n\ndef euler_step(f, x, dt, **kwargs):\n    raise NotImplementedError\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q2. Butterfly effect\n",
        "Tasks:\n",
        "- Integrate two trajectories with initial states separated by $10^{-6}$ in x (use RK4, dt=0.01).\n",
        "- Plot the Euclidean distance vs time (semilogy).\n",
        "- Change parameters (e.g., $\\rho=20$) or use Euler with larger dt to see sensitivity to numerical accuracy.\n",
        "Hint: expect exponential separation in the chaotic regime; reduced separation if parameters leave the attractor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q3. Truth and observations\n",
        "Create a \"truth\" trajectory with RK4, dt=0.01, parameters as above. Sample noisy observations every `obs_interval` steps with noise std `obs_noise_std`.\n",
        "Questions: how do sparser observations affect the analysis problem?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def simulate_truth_obs(x0, n_steps, dt, obs_interval, obs_noise_std, params=None):\n    raise NotImplementedError\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q4. EnKF with a degraded forecast model\n",
        "We now build a stochastic EnKF where the forecast model is imperfect: coarse integrator (Euler, larger dt) and biased parameter (e.g., $\\rho=26$ instead of 28).\n",
        "Tasks:\n",
        "- Implement `enkf_lorenz` using a chosen forecast stepper (Euler or RK4) and forecast parameters.\n",
        "- Use full-state observations (H=I); perturb observations with $\\mathcal{N}(0,R)$.\n",
        "- Track ensemble mean/spread and compute RMSE vs truth.\n",
        "Questions: how does model imperfection show up? does inflation help?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "def enkf_lorenz(x0, dt, n_steps, obs, obs_times, R, N_ens=30, inflation=1.0, forecast_stepper=None, forecast_params=None):\n    H = np.eye(3)\n    forecast_stepper = forecast_stepper or rk4_step\n    forecast_params = forecast_params or {}\n    ensemble = x0 + rng.normal(0.0, 2.0, size=(N_ens, 3))\n    mean = np.zeros((n_steps, 3))\n    spread = np.zeros(n_steps)\n    rmse = np.zeros(n_steps)\n    mean[0] = ensemble.mean(axis=0)\n    spread[0] = ensemble.std(axis=0).mean()\n    obs_lookup = {int(t): y for t, y in zip(obs_times, obs)}\n\n    for k in range(1, n_steps):\n        for i in range(N_ens):\n            ensemble[i] = forecast_stepper(lorenz63, ensemble[i], dt, **forecast_params)\n\n        if inflation != 1.0:\n            m = ensemble.mean(axis=0)\n            ensemble = m + inflation * (ensemble - m)\n\n        if k in obs_lookup:\n            y_obs = obs_lookup[k]\n            m_f = ensemble.mean(axis=0)\n            A = (ensemble - m_f).T\n            P_f = (A @ A.T) / (N_ens - 1)\n            S = H @ P_f @ H.T + R\n            K = (P_f @ H.T) @ np.linalg.inv(S)\n            for i in range(N_ens):\n                pert = rng.multivariate_normal(np.zeros(3), R)\n                ensemble[i] = ensemble[i] + K @ (y_obs + pert - H @ ensemble[i])\n\n        mean[k] = ensemble.mean(axis=0)\n        spread[k] = ensemble.std(axis=0).mean()\n    return mean, spread, rmse\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q5. Experiments and analysis\n",
        "Run the following and discuss (plots + short comments):\n",
        "1. Baseline: truth (RK4, dt=0.01, rho=28), obs_interval=5, obs_noise_std=2.0; EnKF with Euler forecast dt=0.02 and rho=26; N_ens=40; inflation=1.02. Plot truth vs mean (x component) and spread; compute RMSE.\n",
        "2. Effect of inflation: vary inflation in [1.0, 1.1].\n",
        "3. Effect of ensemble size: N_ens = 10 vs 50.\n",
        "4. Partial observations: observe only x (adjust H) and comment on performance.\n",
        "Hints: model error should be visible as bias/drift without assimilation; good inflation counteracts collapse; partial obs increase spread and degrade unobserved components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Q6. Further questions (short answers)\n",
        "- When is inflation too large? What symptom do you see?\n",
        "- How would you augment the state to estimate $\\rho$ online? What would you expect?\n",
        "- In high dimension we localize covariances; why is localization unnecessary here?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Deliverables\n",
        "- Plots for Q2, Q3 (obs vs truth), Q5 (mean vs truth, RMSE vs spread).\n",
        "- Short comments on each question.\n",
        "- Code cells filled.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}