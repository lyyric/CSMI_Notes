{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 4 - Neural Galerkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import grad as grad\n",
    "from torch.func import functional_call, jacrev, vmap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"torch loaded; device is {device}\")\n",
    "\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(torch.nn.Module):\n",
    "    def __init__(self, layer_widths = list):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_widths = layer_widths\n",
    "        \n",
    "        self.hidden_layers = []\n",
    "        for i in range( len(layer_widths)-1):\n",
    "            self.hidden_layers.append(torch.nn.Linear(self.layer_widths[i], self.layer_widths[i+1], dtype=torch.double))\n",
    "\n",
    "        self.hidden_layers = torch.nn.ModuleList(self.hidden_layers)\n",
    "        self.activation = torch.nn.Tanh()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        for i in range( len(self.layer_widths)-2):\n",
    "                inputs = self.activation(self.hidden_layers[i].forward(inputs))\n",
    "\n",
    "        inputs = self.hidden_layers[-1].forward(inputs)\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SamplerBox:\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_make_data():\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinn class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralGalerkin:\n",
    "\n",
    "    pass \n",
    "\n",
    "    \n",
    "    def compute_jacobian(self, x, mu):\n",
    "        \"\"\"\n",
    "        this function computes the Jacobians of the model with respect to the weights at each (x,mu) of a tensor\n",
    "        If we have n points, we have n jacobians J(\\theta)(x,mu).\n",
    "        \"\"\"\n",
    "        theta = {k: v.detach() for k, v in self.network.named_parameters()}\n",
    "\n",
    "        def fnet(theta, x, mu):\n",
    "            return functional_call(self.network, theta, torch.cat([x, mu], axis=0))\n",
    "        \n",
    "        # (None, 0, 0) means that:\n",
    "        #   - the first argument (params) is not batched\n",
    "        #   - the second argument (x) is batched along the first dimension\n",
    "        #   - the third argument (mu) is batched along the first dimension\n",
    "        jac = vmap(jacrev(fnet), (None, 0, 0))(theta, x, mu).values()\n",
    "\n",
    "        # jac is a dict of jagged tensors, we want to:\n",
    "        #   - first reshape each jagged tensor to (nb_data, nb_unknowns, nb_params)\n",
    "        #   - then concatenate them along the last dimension\n",
    "        nb_data = x.shape[0]\n",
    "        return torch.cat([j.reshape((nb_data, 1, -1)) for j in jac], axis=-1)\n",
    "\n",
    "    def compute_M_and_F(self):\n",
    "        \"\"\"\n",
    "        this function computes the mass matrix and the RHS of the Neural Galerkin method\n",
    "        M(theta) = frac1/N sum (J(theta) otimes J(theta))(x,mu)\n",
    "        F(theta) = frac1/N sum (J(theta) f(theta))(x,mu)\n",
    "        \"\"\"\n",
    "        nb_data = 10000\n",
    "        x = self.sampler_space(nb_data)\n",
    "        mu = self.sampler_param(nb_data)\n",
    "        jacobian = self.compute_jacobian(x, mu)\n",
    "\n",
    "        self.M = self.regularization_matrix + torch.einsum(\"bjs,bjr->sr\", jacobian, jacobian) / nb_data\n",
    "\n",
    "        #advection = ...\n",
    "\n",
    "        self.F = torch.einsum(\"bji,bj->i\", jacobian, advection.unsqueeze(1)) / nb_data\n",
    "        self.F.flatten()\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}