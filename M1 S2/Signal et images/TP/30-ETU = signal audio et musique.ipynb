{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "authorship_tag": "ABX9TyPM+tg0tQvIZaPlrjSoTCWo"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {"id": "A662YFN5Y7Bn"}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {"id": "PfTj5SaNG0S2"}, "source": ["# Audio Signals"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "xjEYcb9hQh-Z"}, "source": ["### pull some data from github"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "Rr87xbZWQWWF", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1675117541826, "user_tz": -60, "elapsed": 2831, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6453e2dd-b7b7-4759-aa63-6792d1472efd"}, "source": ["\"we import (=clone) all the data or just update (=pull) them\"\n", "\n", "import os\n", "\n", "if not os.path.exists(\"assets_signal\"):\n", "    print(\"the directory assets_signal is create\")\n", "    !git clone https://github.com/vincentvigon/assets_signal\n", "else:\n", "    print(\"the directory assets_signal is updated\")\n", "    %cd assets_signal\n", "    !git pull https://github.com/vincentvigon/assets_signal\n", "    %cd ..\n"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "6ZWWe2P0AlDh"}, "source": ["### basic imports"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "uF2XFFW5Amjq"}, "source": ["%reset -f\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import IPython\n", "\n", "np.set_printoptions(linewidth=500,precision=3,suppress=True)\n", "plt.style.use(\"default\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "-cJacOrZ7w3V"}, "source": ["## Sounds"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "ebE9GKty_CFd"}, "source": ["### Import a sound file\n", "\n", "I want to import and export sound file with python. How can I do?\n", "\n", "I ask to google ->  \"python read write sound files\"\n", "\n", "Often, the best place to see the answer is stackoverflow. I look at the debates:\n", "\n", "* Some people say that `PySoundFile` is the more complete lib.\n", "* But I see that `scipy` has also a `io.wavfile` package. Because I already have `scipy`, I try it in first. It is OK to import sounds, but not so good to export them: the generate sounds cannot be easily open.\n", "* so finaly, I used  `PySoundFile`\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "0wMBTb-KFlob", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1675117548650, "user_tz": -60, "elapsed": 6117, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "18e26fdc-81ad-475f-fbe5-fbbe41fbb3bc"}, "source": ["!pip install PySoundFile"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ZQZmYEKuFqoi", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1675117548650, "user_tz": -60, "elapsed": 5, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b36218f5-89f5-4561-e542-a4dd4b7049b3"}, "source": ["\"\"\"recall: samplerate is the number of measures make in one second\"\"\"\n", "import soundfile as sf\n", "sound, samplerate = sf.read('assets_signal/bornwild.wav')\n", "sound.shape,samplerate"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "zaPo8AbwQXEJ"}, "source": ["The sound is stereo: it has two columns=two channels: the left one and the right one.\n", "\n", "Let's plot this signal. Oscilations are so fast, that we only see their contours. Such plot is called  \"waveform\" (forme d'onde), and allows to see when the sound is loud or quiet."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "a5K_xO_N73BP", "colab": {"base_uri": "https://localhost:8080/", "height": 207}, "executionInfo": {"status": "ok", "timestamp": 1675117549738, "user_tz": -60, "elapsed": 1090, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "3a0c9d8b-2f64-4fc9-9645-a519d542cb51"}, "source": ["fig,(ax0,ax1)=plt.subplots(2,1,figsize=(8,2),sharex=True)\n", "ax0.plot(sound[:,0])\n", "ax1.plot(sound[:,1])\n", "ax0.set_title(\"left chanel\")\n", "ax1.set_title(\"right chanel\")\n", "fig.tight_layout()"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "J1eZ2IJYTRVi"}, "source": ["***To you:***\n", "\n", "* $(1\\heartsuit)$ What is the duration of this sound.\n", "* $(1\\heartsuit)$ Add xticks on the above plot which indicate the time.\n", "* $(2\\heartsuit)$ Plot the very begining of this signal, to see clearly the oscilations."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "PTPA6JmBOE_F", "colab": {"base_uri": "https://localhost:8080/", "height": 214}, "executionInfo": {"status": "ok", "timestamp": 1675117550949, "user_tz": -60, "elapsed": 1216, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "aac26f13-f03e-4a1e-bcaa-702c7cc7414a"}, "source": ["\"we plot the half-amplitude-spectrum\"\n", "sound0=sound[:,0]\n", "half_spectrum=np.fft.rfft(sound0)\n", "fig,ax=plt.subplots(figsize=(8,2))\n", "N=len(half_spectrum)\n", "freqs=np.linspace(0,samplerate/2,N)\n", "ax.plot(np.abs(half_spectrum)/N);"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "dBGft704Ejqn"}, "source": ["***To you:*** $(1\\heartsuit)$ What is the meaning of the pick at 0 ?"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "EwcjlbSHHr6A"}, "source": ["To hear the sound:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "z48UF3CTFKDh", "colab": {"base_uri": "https://localhost:8080/", "height": 75}, "executionInfo": {"status": "ok", "timestamp": 1675117550949, "user_tz": -60, "elapsed": 13, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "9c6fb544-398c-49e8-b833-788e0817d054"}, "source": ["IPython.display.Audio('assets_signal/bornwild.wav')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "G_Qidnp6_HWS"}, "source": ["### Create a sound file"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "lBBplfJz-8NF"}, "source": ["We create an artificial sound. The reference note A (=la) has a frequency  of 440Hz, we make it with a simple sinus-wave.  We add it some harmonics: some weaker sinus-waves wich frequences are $n\\times$440Hz.  In the nature, sounds come always with harmonics due to  reasonnance phenomenums.  The dosage of harmonics is different from an instrument to an other, from a voice to another.\n", "\n", "\n", "Moreover, we produce a sound which is 'crescendo'  (more and more loud).\n", "\n", "***To you:*** $(1\\heartsuit)$ Create a decrecendo (=diminuendo) soud.\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "UlLsxRKG73D_"}, "source": ["samplerate=44100\n", "duration=3 #secondes\n", "t=np.linspace(0,duration,duration*samplerate)\n", "\n", "harmonics=[2,3,5]\n", "hamonics_intensity=[1/2,1/4,1/3]\n", "\n", "signal =  np.sin(2 * np.pi * 440 * t)\n", "\"\"\"ajout des harmoniques\"\"\"\n", "for h,h_i in zip(harmonics,hamonics_intensity):\n", "    signal+= h_i*np.sin(h* 2 * np.pi * 440 * t )"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "F_4zSkb2Cydw", "colab": {"base_uri": "https://localhost:8080/", "height": 137}, "executionInfo": {"status": "ok", "timestamp": 1675117550950, "user_tz": -60, "elapsed": 9, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "789748d8-4230-4926-9be5-5ad3f50a6d9d"}, "source": ["fig,ax=plt.subplots(figsize=(8,1))\n", "ax.plot(t[:200],signal[:200]);"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "ar0L_gheCBrj", "colab": {"base_uri": "https://localhost:8080/", "height": 139}, "executionInfo": {"status": "ok", "timestamp": 1675117551683, "user_tz": -60, "elapsed": 741, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "48ce1895-d710-4650-d6b1-b871c932bff8"}, "source": ["\"\"\"we must be carful: usualy, intensity of sound must stay in [0,1]\"\"\"\n", "maxiSig=np.max(signal)\n", "volume=t/t[-1]/maxiSig/2\n", "signal*=volume\n", "\n", "fig,ax=plt.subplots(figsize=(8,1))\n", "ax.plot(t,signal);"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "LqcWXiJ5GbUm"}, "source": ["sf.write('la440.wav', signal, samplerate)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "RBY-eAMFEwtX", "colab": {"base_uri": "https://localhost:8080/", "height": 75}, "executionInfo": {"status": "ok", "timestamp": 1675117551684, "user_tz": -60, "elapsed": 12, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "07601219-7f30-4809-d5f5-33574932cf40"}, "source": ["IPython.display.Audio('la440.wav')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "Wckw695nFFFj"}, "source": ["### Create a music\n", "\n", "To create a music, we have to concatenate several note. But  transitions must be smooth to avoid some short noise 'tack'.  Observe:"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "HN-oFqztIoJQ"}, "source": ["samplerate = 11025\n", "\n", "duration0=1.3\n", "duration1=2.6\n", "\n", "nb0=int(duration0*samplerate)\n", "nb1=int(duration1*samplerate)\n", "nb=nb0+nb1\n", "t=np.linspace(0,duration0+duration1,nb)\n", "signal0=np.sin(2*np.pi*t*2)\n", "signal1=np.sin(2*np.pi*t*5)\n", "\n", "window0 = np.zeros(nb)\n", "window1 = np.zeros(nb)\n"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "lpzsyIzTJfJF"}, "source": ["\"\"\"transition abrupte\"\"\"\n", "window0[:nb0]=1\n", "window1[nb0:]=1"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "X3n8gYSXI4k8", "colab": {"base_uri": "https://localhost:8080/", "height": 435}, "executionInfo": {"status": "ok", "timestamp": 1675117579074, "user_tz": -60, "elapsed": 611, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "85a37468-e788-4f6c-d00b-2f1ee071f444"}, "source": ["def plot_all():\n", "    plt.subplot(3,1,1)\n", "    plt.plot(window0)\n", "    plt.plot(window0*signal0)\n", "    plt.ylim([-2,2])\n", "\n", "    plt.subplot(3,1,2)\n", "    plt.plot(window1)\n", "    plt.plot(window1*signal1)\n", "    plt.ylim([-2, 2])\n", "\n", "    plt.subplot(3,1,3)\n", "    plt.plot(window0+window1)\n", "    plt.plot(window0*signal0+window1*signal1)\n", "    plt.ylim([-2, 2])\n", "\n", "plot_all()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "x1Ma5LA5KTvl"}, "source": ["sf.write(\"raw_transi.wav\",window0*signal0+window1*signal1,samplerate)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "CqxRYSBbKmuH", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1588154359743, "user_tz": -120, "elapsed": 14308, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "3ec79150-3b7d-4fd5-f850-a87dee88246f"}, "source": ["IPython.display.Audio(\"raw_transi.wav\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "bj0nNjP-LUgE"}, "source": ["The previous sound is not audible (too low frequency), but you can hear the raw transition."], "outputs": []}, {"cell_type": "code", "metadata": {"id": "y81QyQSBJvgs"}, "source": ["demiTransition = int(0.1 * samplerate)\n", "montee = np.linspace(0, 1, 2 * demiTransition)\n", "descente = 1 - montee\n", "window0[:nb0 - demiTransition] = 1\n", "window0[nb0 - demiTransition:nb0 + demiTransition] = descente\n", "window1[nb0 + demiTransition:] = 1\n", "window1[nb0 - demiTransition:nb0 + demiTransition] = montee"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "T2_wb-jrJyYZ", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1588154359744, "user_tz": -120, "elapsed": 14302, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "55913f2c-0e17-4d02-ff19-3678921fbd4f"}, "source": ["plot_all()"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "xp76zGmCLG-q"}, "source": ["sf.write(\"soft_transi.wav\",window0*signal0+window1*signal1,samplerate)"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "hGPGOOJILJJk", "colab": {"base_uri": "https://localhost:8080/"}, "executionInfo": {"status": "ok", "timestamp": 1588154359745, "user_tz": -120, "elapsed": 14297, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "776a3433-fead-480f-a647-c40168547ec7"}, "source": ["IPython.display.Audio(\"soft_transi.wav\")"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "94ahE0pwLfjL"}, "source": ["Now the transition is soft, we get a perfect silence."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "FIl2uDu8L4y3"}, "source": ["***To you:*** $(2\\heartsuit)$ Remake these two transitions, but with audible sounds."], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "jw0RxhOxS6P0"}, "source": ["***Bonus:*** Write a little melody. The correspondance \"note $\\to$ frequency\" can be easily found on the net. To win:\n", "\n", "* $4\\star$ for a five notes melody with smooth transition of course.\n", "* $4\\star$ more, if we recognise a true musical melody  \n", "* $4\\star$ more if you optimize the previous code:  I have created one long vector per note: instead, you can create only one long vector and change it part by part to make the melody, or create several short vectors and concatenate them (but this second solution is only for sharp transition).  \n", "\n", "Structure de l'algo\n", "        #transition brutale\n", "        np.concatenate(notes)\n", "        #ou notes est une liste de petit signaux\n", "\n", "        #transition douce\n", "        signal_total=np.zeros()\n", "        for note in notes\n", "            signal_total[deb,fin]+=note"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "w3q2873rUQRN"}, "source": ["### Spectrogram"], "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "MBcexf05VGkj"}, "source": ["To analyse long signal, it is often better to make a spectrogram than a simple Fourier Transform. Here is the process:\n", "\n", "* We cut the signal in short slices, sufficiently short so that, in every slice, the signal is homogenious (like a simple mixture of sinus-waves).\n", "* Then we compute the fft for every slice.\n", "*  fft are stack as in columns of a matrix\n", "* This matrix is plot with a colormap.\n", "\n", "Such process is also called a \"time-frequency analysis\""], "outputs": []}, {"cell_type": "code", "metadata": {"id": "bvw7NQMeUSL2", "colab": {"base_uri": "https://localhost:8080/", "height": 472}, "executionInfo": {"status": "ok", "timestamp": 1645433815098, "user_tz": -60, "elapsed": 1072, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "d25a05f0-1924-45cc-cf71-8c231e9eb8c2"}, "source": ["import scipy.signal\n", "\n", "epsilon = 0.0001\n", "t = np.arange(0, 1, epsilon)\n", "\n", "sig_debut = 0.5 * np.sin(t * 2 * np.pi * 440) + np.sin(t * 2 * np.pi * 220)\n", "sig_fin = 0.5 * np.sin(t * 2 * np.pi * 880) + np.sin(t * 2 * np.pi * 440)\n", "sig=np.concatenate((sig_debut, sig_fin))\n", "\n", "\n", "\"\"\"from the official help : https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.spectrogram.html \"\"\"\n", "f, t, Sxx = scipy.signal.spectrogram(sig, 1/epsilon)\n", "plt.pcolormesh(t, f, Sxx)\n", "plt.ylabel('Frequency [Hz]')\n", "plt.xlabel('Time [sec]')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "LiAIYN3ZWr6M"}, "source": ["***To you:*** $(3\\heartsuit)$ Plot the spectrogram of some  short sounds of your choice (put it before in your working directory). Try to link what you hear and what you see."], "outputs": []}, {"cell_type": "code", "source": ["#example with born to be wilde\n", "f, t, Sxx = scipy.signal.spectrogram(sound[:,0], 1/epsilon)\n", "plt.pcolormesh(t, f, Sxx)\n", "plt.ylabel('Frequency [Hz]')\n", "plt.xlabel('Time [sec]')"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 472}, "id": "rpX7hiy3fpox", "executionInfo": {"status": "ok", "timestamp": 1645433846522, "user_tz": -60, "elapsed": 833, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "39557473-08bd-4b82-d7d9-e8ad2399f4f4"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["***A vous:*** O\u00f9 voit-on que le chanteur utilise des \"effets de voix\"?"], "metadata": {"id": "e0Zliymd7URj"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "QY0jLdbrYE3h"}, "source": ["### Exo: Sound filtering"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "WA_k3EVKYcYA", "colab": {"base_uri": "https://localhost:8080/", "height": 50}, "executionInfo": {"status": "ok", "timestamp": 1588154894882, "user_tz": -120, "elapsed": 815, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "46720313-48ad-4136-8a70-a779f39c9c98"}, "source": ["sound, samplerate = sf.read('assets_signal/sound_surprise.wav')\n", "sound.shape,samplerate"], "execution_count": null, "outputs": []}, {"cell_type": "code", "metadata": {"id": "69wQvihtYvP0", "colab": {"base_uri": "https://localhost:8080/", "height": 92}, "executionInfo": {"status": "ok", "timestamp": 1588154896231, "user_tz": -120, "elapsed": 742, "user": {"displayName": "vincent vigon", "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjWmkl9xE6h20aXXKcXJ2aRKlPXKcQHtSOjba3oFg=s64", "userId": "09456169185020192907"}}, "outputId": "2fddd04d-1cb6-427c-9fb4-dee04e07cc30"}, "source": ["IPython.display.Audio('assets_signal/sound_surprise.wav')"], "execution_count": null, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "bYTp0pRWZNID"}, "source": ["***To you:***\n", "* What is the duration of the signal. Justify!\n", "* Plot the whole sound, with the good scale of time\n", "* Plot the very begining of this sound, to see the oscillations.\n", "* Plot the half-amplitude-spectrum with the good scale of frequencies\n", "* What is the musical name of this sound. How many \"harmonics\"?\n", "* With the help of fft, suppress all harmonics to keep only a \"pure\"\n", "sound.  \n", "* Transform the initial sound to make a \"crescendo\" effect (= more and more loud)\n", "* Plot the spectrogram of the transformed sound"], "outputs": []}]}