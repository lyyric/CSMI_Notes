{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "toc_visible": true, "authorship_tag": "ABX9TyN/TZQX4Fs8cXIJL+Dd49Jg"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "execution_count": 93, "metadata": {"id": "YCJLJECgMkWs", "executionInfo": {"status": "ok", "timestamp": 1755707877765, "user_tz": -120, "elapsed": 135, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["%reset -f"]}, {"cell_type": "code", "source": ["import flax.linen as nn\n", "import jax\n", "import jax.numpy as jnp\n", "import jax.random as jr"], "metadata": {"id": "w08HzAGqQVTr", "executionInfo": {"status": "ok", "timestamp": 1755707877778, "user_tz": -120, "elapsed": 12, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 94, "outputs": []}, {"cell_type": "markdown", "source": ["## Data"], "metadata": {"id": "dMpGJWN-QSg3"}, "outputs": []}, {"cell_type": "markdown", "source": ["Des dimensions fix\u00e9es:"], "metadata": {"id": "r_W04MtIVPll"}, "outputs": []}, {"cell_type": "code", "source": ["INP_DIM = 2\n", "OUT_DIM = 3"], "metadata": {"id": "qZ-gyS9JQWgW", "executionInfo": {"status": "ok", "timestamp": 1755707877782, "user_tz": -120, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 95, "outputs": []}, {"cell_type": "markdown", "source": ["Une fonction au pif. On va essayer d'ajuster un r\u00e9seau de neurone \u00e0 cette fonction."], "metadata": {"id": "nw48xE-zVSjw"}, "outputs": []}, {"cell_type": "code", "source": ["def target_fn(inpV):\n", "    outV0=jnp.sin(5*inpV[:,0]) * jnp.cos(8*inpV[:,1])\n", "    outV1=jnp.sin(2*inpV[:,0]) + jnp.cos(4*inpV[:,1])**2\n", "    outV2=jnp.sin(2*inpV[:,0]) - jnp.cos(7*inpV[:,1])*4\n", "    return jnp.stack([outV0,outV1,outV2],axis=1)\n", "\n", "\n", "target_fn(jnp.zeros([7,INP_DIM])).shape"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "B-dpm7XnSmPa", "executionInfo": {"status": "ok", "timestamp": 1755707877798, "user_tz": -120, "elapsed": 10, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "56a5aaa9-8697-4431-bbc0-133505fa9f7a"}, "execution_count": 96, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "47185c1c"}, "source": ["## D\u00e9finition du mod\u00e8le\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "df06c036", "executionInfo": {"status": "ok", "timestamp": 1755707877871, "user_tz": -120, "elapsed": 71, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "7c57e164-44aa-4e3a-9fe9-c27799ea8dcc"}, "source": ["\n", "class SimpleNN(nn.Module):\n", "    out_dim: int\n", "\n", "    @nn.compact\n", "    def __call__(self, x):\n", "        x = nn.Dense(features=128)(x)\n", "        x = nn.relu(x)\n", "        x = nn.Dense(features=64)(x)\n", "        x = nn.relu(x)\n", "        return nn.Dense(features=self.out_dim)(x)\n", "\n", "\n", "dummy_input = jnp.ones((1, INP_DIM)) # Assuming flattened MNIST images\n", "model = SimpleNN(OUT_DIM)\n", "params = model.init(jr.key(0), dummy_input)\n", "print(jax.tree.map(jnp.shape, params))\n", "print(\"Model initialized successfully.\")"], "execution_count": 97, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "70f476e3"}, "source": ["## D\u00e9finition de l'optimiseur\n", "\n"], "outputs": []}, {"cell_type": "code", "metadata": {"id": "54617a2d", "executionInfo": {"status": "ok", "timestamp": 1755707877872, "user_tz": -120, "elapsed": 1, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["import optax\n", "\n", "learning_rate = 0.01\n", "optimizer = optax.adam(learning_rate)"], "execution_count": 98, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "8e394273"}, "source": ["## D\u00e9finition de la fonction d'entra\u00eenement\n", "\n"], "outputs": []}, {"cell_type": "code", "source": ["@jax.jit\n", "def loss_fn(params,inpV, outV_true):\n", "    outV_pred = model.apply(params, inpV)\n", "    return jnp.mean(jnp.square(outV_pred - outV_true))"], "metadata": {"id": "Y8FrHRJ2QA0n", "executionInfo": {"status": "ok", "timestamp": 1755707877873, "user_tz": -120, "elapsed": 1, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 99, "outputs": []}, {"cell_type": "code", "metadata": {"id": "a83dc11d", "executionInfo": {"status": "ok", "timestamp": 1755707877874, "user_tz": -120, "elapsed": 0, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "source": ["@jax.jit\n", "def train_step(params, opt_state, inpV, outV_true):\n", "    \"\"\"Performs a single training step.\"\"\"\n", "    loss_value, grads = jax.value_and_grad(loss_fn)(params,inpV, outV_true)\n", "\n", "    updates, new_opt_state = optimizer.update(grads, opt_state, params)\n", "\n", "    new_params = jax.tree.map(lambda x,y:x+y,params,updates)\n", "    #ou bien:\n", "    #new_params = optax.apply_updates(params, updates)\n", "\n", "    return new_params, new_opt_state, loss_value"], "execution_count": 100, "outputs": []}, {"cell_type": "markdown", "source": ["Note: l'optimiseur a lui aussi ses variables propres. L'ensemble de ses variables est appel\u00e9 'state'.\n", "\n", "Dans les autres lib on utiliserais un attribut `optimizer.state` que l'on mettrait \u00e0 jour de mani\u00e8re `inplace` (et cach\u00e9).\n", "\n", "En JAX on veut coder des fonctions pures. Cela donne la syntaxe ci-dessus, qui ne cache rien !"], "metadata": {"id": "GsiE0CaTWK8z"}, "outputs": []}, {"cell_type": "markdown", "source": ["## Boucle d'entrainement"], "metadata": {"id": "UTF8-r7vOt9U"}, "outputs": []}, {"cell_type": "code", "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "6wKWn3iiNpfB", "executionInfo": {"status": "ok", "timestamp": 1755707880887, "user_tz": -120, "elapsed": 3012, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "fe130287-e49f-4a75-ebb6-e57ff005c4be"}, "source": ["# Step 1: Initialize the optimizer state\n", "opt_state = optimizer.init(params)\n", "\n", "batch_size = 32\n", "rkey=jr.key(0)\n", "losses=[]\n", "\n", "for step in range(1000):\n", "    rkey, subkey = jr.split(rkey)\n", "    inV=jr.uniform(subkey,(batch_size,INP_DIM))\n", "    outV_true=target_fn(inV)\n", "    params, opt_state, loss = train_step(params, opt_state, inV, outV_true)\n", "    losses.append(loss)\n", "    if step % 100 == 0:\n", "        print(f\"Step {step}, Loss: {loss}\")"], "execution_count": 101, "outputs": []}, {"cell_type": "code", "source": ["import matplotlib.pyplot as plt\n", "fig,ax=plt.subplots()\n", "ax.set_xlabel(\"Epoch\")\n", "ax.set_ylabel(\"Loss\")\n", "ax.set_yscale(\"log\")\n", "ax.plot(losses);"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 449}, "id": "4eOfEbBVU7-6", "executionInfo": {"status": "ok", "timestamp": 1755707881201, "user_tz": -120, "elapsed": 306, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "ba695bf6-dc1b-40f6-9969-10601924a631"}, "execution_count": 102, "outputs": []}, {"cell_type": "markdown", "source": ["## D\u00e9fi prog.\n", "\n", "Transformer ce programme pour qu'il fonctionne avec `INP_DIM=2` et `OUT_DIM=2`.\n", "\n", "Changez notamment la `target_fn`. Illustrez l'apprentissage optenu en tra\u00e7ant en niveau de couleur la `target_fn` \u00e0 c\u00f4t\u00e9 de la fonction pr\u00e9dite: `inp->model(params,inp)`"], "metadata": {"id": "UH9wqVmGXDsW"}, "outputs": []}]}