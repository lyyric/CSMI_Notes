{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "gpuType": "T4", "toc_visible": true, "authorship_tag": "ABX9TyOqqyi7seP4d8QBXMktEG0R"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}, "accelerator": "GPU"}, "cells": [{"cell_type": "markdown", "source": ["# Rechercher les meilleurs hyper-param\u00e8tres"], "metadata": {"id": "jCTqLacMJkE0"}, "outputs": []}, {"cell_type": "code", "execution_count": 1, "metadata": {"id": "sWCSV3zE_Hjp", "executionInfo": {"status": "ok", "timestamp": 1755811877161, "user_tz": -120, "elapsed": 855, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "outputs": [], "source": ["import hashlib\n", "import os\n", "import shutil\n", "import time\n", "from dataclasses import dataclass\n", "from typing import Callable\n", "from matplotlib import pyplot as plt\n", "pp=print\n", "import numpy as np\n", "import jax.numpy as jnp\n", "import optax\n", "import pickle\n", "import jax\n", "from jax.example_libraries import stax\n", "from datetime import datetime"]}, {"cell_type": "markdown", "source": ["## Data"], "metadata": {"id": "4zBVJ9hGl8ft"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Un probl\u00e8me de regression\n", "\n", "On veut faire coller un mod\u00e8le \u00e0 une fonction toute simple."], "metadata": {"id": "B46wgZVTJqzx"}, "outputs": []}, {"cell_type": "code", "source": ["n_data=20_000\n", "X = jnp.linspace(0, 1, n_data)[:, None]\n", "Y = jnp.sin(10 * X)\n", "nb_data_train = int(n_data * 0.8)\n", "idx=np.random.permutation(n_data)\n", "X_=X[idx]\n", "Y_=Y[idx]\n", "X_train = X_[:nb_data_train]\n", "Y_train = Y_[:nb_data_train]\n", "X_val = X_[nb_data_train:]\n", "Y_val = Y_[nb_data_train:]"], "metadata": {"id": "baJBjQruLIX8", "executionInfo": {"status": "ok", "timestamp": 1755811885176, "user_tz": -120, "elapsed": 3113, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": ["fig,ax=plt.subplots()\n", "ax.plot(X,Y);"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "Nm-6PGevMv33", "executionInfo": {"status": "ok", "timestamp": 1755811890886, "user_tz": -120, "elapsed": 484, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "62a341d1-bfa5-4821-a122-4e8e9ed8dc85"}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": ["### Distributeur de batch"], "metadata": {"id": "ijcfgElBmHzV"}, "outputs": []}, {"cell_type": "markdown", "source": ["On va distribuer les donn\u00e9es avec une double boucle. Une boucle sur les \u00e9poques. A chaque \u00e9poque les donn\u00e9es sont r\u00e9parties dans les batchs."], "metadata": {"id": "AaIJXdM6mMaM"}, "outputs": []}, {"cell_type": "code", "source": ["def batchs_for_one_epoch(X_all,Y_all,batch_size):\n", "    nb_batches=len(X_all)//batch_size\n", "    shuffle_index=np.random.permutation(len(X_all))\n", "    X_all_shuffle=X_all[shuffle_index]\n", "    Y_all_shuffle=Y_all[shuffle_index]\n", "    for i in range(nb_batches):\n", "        yield X_all_shuffle[i*batch_size:(i+1)*batch_size],Y_all_shuffle[i*batch_size:(i+1)*batch_size]"], "metadata": {"id": "4LJ4bJr1i5jt", "executionInfo": {"status": "ok", "timestamp": 1755811917826, "user_tz": -120, "elapsed": 42, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": ["## Mod\u00e8le et fonctions d'entrainement"], "metadata": {"id": "_M42CBHvmd6w"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Un MLP en stax\n", "\n", "\n"], "metadata": {"id": "vhLGaBTlJz3g"}, "outputs": []}, {"cell_type": "markdown", "source": ["Un r\u00e9seau neuronal est une fonction param\u00e9trique $f(\\theta,x)$. En jax, on l'impl\u00e9mente tr\u00e8s explicitement: en se donnant une fonction `model_init()` qui renverra un jeu initial de param\u00e8tre `model_param` =$\\theta$  et la fonction `model_call(model_param,x)` =$f(\\theta,x)$."], "metadata": {"id": "0x6Gma3VJ5gU"}, "outputs": []}, {"cell_type": "markdown", "source": ["Ici on va utiliser la librarie 'stax' qui est ultra-simple. Elle est consid\u00e9rer comme une librairie  'exemple'."], "metadata": {"id": "2I3CtSIbjHQs"}, "outputs": []}, {"cell_type": "code", "source": ["stax_activation_layers={\n", "    \"tanh\":stax.Tanh,\"relu\":stax.Relu, \"exp\": stax.Exp,\"log_softmax\": stax.LogSoftmax,\n", "    \"softmax\": stax.Softmax, \"softplus\": stax.Softplus, \"sigmoid\": stax.Sigmoid, \"elu\": stax.Elu,\n", "   \"leaky_relu\": stax.LeakyRelu, \"selu\": stax.Selu, \"gelu\": stax.Gelu\n", "}\n", "\n", "#On va utiliser un Multi-layer-perceptron.\n", "def MLP_stax(dim_in,dim_hidden,dim_out,n_layer,*,activation_name=\"relu\"):\n", "    layers = []\n", "    activation_layer=stax_activation_layers[activation_name]\n", "    for i in range(n_layer - 1):\n", "        layers.append(stax.Dense(dim_hidden))\n", "        layers.append(activation_layer)\n", "    layers.append(stax.Dense(dim_out))\n", "    model_init_stax, model_call= stax.serial(*layers)\n", "\n", "    def model_init(rand_key=None):\n", "        if rand_key is None:\n", "            rand_key=jax.random.key(int(datetime.now().timestamp()*1_000_000))\n", "        _, params = model_init_stax(rand_key, (-1, dim_in))\n", "        return params\n", "\n", "    return model_init,model_call"], "metadata": {"id": "YeSGBOOAJyP2", "executionInfo": {"status": "ok", "timestamp": 1755812054407, "user_tz": -120, "elapsed": 39, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": ["model_init,model_call=MLP_stax(dim_in=1,dim_hidden=64,dim_out=1,n_layer=3)\n", "model_param=model_init()\n", "Y_pred=model_call(model_param,X)\n", "\n", "fig,ax=plt.subplots()\n", "ax.plot(X,Y_pred);"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 430}, "id": "IRKttjeENDd0", "executionInfo": {"status": "ok", "timestamp": 1755812060045, "user_tz": -120, "elapsed": 3168, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "623a0701-2364-4517-de1a-0e09ce73f80c"}, "execution_count": 6, "outputs": []}, {"cell_type": "markdown", "source": ["Sans entrainement, la courbe est al\u00e9atoire."], "metadata": {"id": "MeyOh_LWNgGh"}, "outputs": []}, {"cell_type": "markdown", "source": ["Ensuite, il faut trouver le bon param\u00e8tre $\\theta$ pour que le r\u00e9seau neuronal colle aux donn\u00e9es. Cette recherche se fait \u00e0 l'aide d'une descente de gradient.\n", "\n", "Mais pour r\u00e9ussir au mieux, il faut aussi bien calibrer l'architecture du r\u00e9seau de neurone (`n_layer`, `hidden_dim`, `activation_name`) param\u00e8tres de l'optimisation (`learning_rate`, `batch_size`, etc.). On nommera tous ces param\u00e8tres \"hyper-param\u00e8tres\" pour les diff\u00e9rencier des param\u00e8tres du mod\u00e8les.\n", "\n", "\n"], "metadata": {"id": "O3Cj9qCpJ-tA"}, "outputs": []}, {"cell_type": "markdown", "source": ["Nous cherchons \u00e0 organiser notre code pour pouvoir tester diff\u00e9rents mod\u00e8les et diff\u00e9rents modes d'apprentissages. On aimerait trouver le bon \u00e9quilibre entre \"tout automatiser\" et  \"tout faire \u00e0 la main\".\n", "\n", "On aimerait aussi que les param\u00e8tres des mod\u00e8les entrain\u00e9s soient sauvegard\u00e9s pour pouvoir prolonger un entrainement. Et on veut aussi se souvenir de tous les hyper-param\u00e8tres qui ont \u00e9t\u00e9 test\u00e9."], "metadata": {"id": "yTS_d5CwKNmW"}, "outputs": []}, {"cell_type": "markdown", "source": ["### De l'Hyper-param\u00e8tre au mod\u00e8le"], "metadata": {"id": "IrdRVD3cnkbA"}, "outputs": []}, {"cell_type": "code", "source": ["def make_model(hyper_param):\n", "    model_init,model_call=MLP_stax(dim_in=1, dim_hidden=hyper_param[\"layer_size\"], dim_out=1, n_layer=hyper_param[\"n_layer\"], activation_name=hyper_param[\"activation_name\"])\n", "    return model_init,model_call\n"], "metadata": {"id": "_pnb_YMbLOiL"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["### fonction loss et update"], "metadata": {"id": "qVCevl3mLTFx"}, "outputs": []}, {"cell_type": "code", "source": ["def jit_creator(model_call,optimizer):\n", "    @jax.jit\n", "    def loss_compute(params, X,Y):\n", "        Y_pred=model_call(params,X)\n", "        return jnp.mean((Y_pred-Y)**2)\n", "\n", "    @jax.jit\n", "    def update_model_param(optimizer_state, model_param, X,Y):\n", "        grads = jax.grad(loss_compute)(model_param, X,Y)\n", "        updates, optimizer_state = optimizer.update(grads, optimizer_state)\n", "        #here the model_param is modified\n", "        model_param = optax.apply_updates(model_param, updates)\n", "        return optimizer_state, model_param\n", "\n", "    return loss_compute,update_model_param"], "metadata": {"id": "7m_cTlMPLVTL"}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": ["## L'Agent\n", "\n", "J'utilise le mot 'Agent' pour un objet qui permet l'entrainement.\n", "\n", "J'ai l'impression que maintenant la plupart des gens utilisent le mot 'Trainer'.\n", "\n", "\n", "Appelons la technique que l'on va utiliser 'ful-folder'. Tout ce qui est produit durant l'entrainement est sauv\u00e9 dans un folder."], "metadata": {"id": "2PXqHF0jK4pr"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Fonctions de sauvegarde"], "metadata": {"id": "Mb1GOjcmK-sB"}, "outputs": []}, {"cell_type": "code", "source": ["def save_as_pickle(file_name,serializable):\n", "    pickle.dump(serializable,open(file_name,\"wb\"))\n", "def load_from_pickle(file_name):\n", "    return pickle.load(open(file_name,\"rb\"))\n", "def save_as_str(file_name,serializable):\n", "    with open(file_name, \"wt\") as f:\n", "        f.write(str(serializable))\n", "def load_from_str(file_name):\n", "    with open(file_name, \"rt\") as f:\n", "        res = eval(f.read())\n", "    return res"], "metadata": {"id": "xRl3y94NK9Sr", "executionInfo": {"status": "ok", "timestamp": 1755812153246, "user_tz": -120, "elapsed": 39, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": ["### L'Agent en personne"], "metadata": {"id": "rjNptirZLaH7"}, "outputs": []}, {"cell_type": "code", "source": ["@dataclass\n", "class AgentMiniResult:\n", "    hyper_param:dict\n", "    best_loss:float\n", "    model_param:dict\n", "    model_call:Callable\n", "\n", "\n", "class AgentMini:\n", "    @staticmethod\n", "    def load(folder):\n", "        assert os.path.exists(folder),f\"folder:{folder} does not exist\"\n", "        model_param = load_from_pickle(f\"{folder}/model_param\")\n", "        best_loss = load_from_str(f\"{folder}/best_loss\")\n", "        model_param=load_from_pickle(f\"{folder}/model_param\")\n", "        hyper_param=load_from_str(f\"{folder}/hyper_param\")\n", "        _, model_call = make_model(hyper_param)\n", "        return AgentMiniResult(hyper_param,best_loss,model_param,model_call)\n", "\n", "    @staticmethod\n", "    def train(folder,hyper_param,n_epoch,verbose):\n", "\n", "        model_init, model_call = make_model(hyper_param)\n", "        optimizer = optax.adam(hyper_param[\"learning_rate\"])\n", "        batch_size = hyper_param[\"batch_size\"]\n", "\n", "        if os.path.exists(folder):\n", "            if verbose:\n", "                print(f\"Existing folder:{folder}, we load model_param and best_loss from if\")\n", "            model_param = load_from_pickle(f\"{folder}/model_param\")\n", "            best_loss =load_from_str(f\"{folder}/best_loss\")\n", "\n", "        else:#c'est la premi\u00e8re fois qu'on teste cet hyper_param\u00e8tre.\n", "            os.makedirs(folder, exist_ok=True)\n", "            if verbose:\n", "                print(f\"New folder:{folder}, model_param are randomly initialized\")\n", "            model_param=model_init()\n", "            best_loss=1e10\n", "            save_as_pickle(f\"{folder}/model_param\", model_param)\n", "            save_as_str(f\"{folder}/best_loss\", best_loss)\n", "\n", "        save_as_str(f\"{folder}/hyper_param\", hyper_param)\n", "        optimizer_state=optimizer.init(model_param)\n", "        loss_compute, update_model_param=jit_creator(model_call,optimizer)\n", "\n", "        for _ in range(n_epoch):\n", "            for x,y in batchs_for_one_epoch(X_train,Y_train,batch_size):\n", "                optimizer_state, model_param = update_model_param(optimizer_state, model_param, x,y)\n", "\n", "            val_loss=float(loss_compute(model_param, X_val, Y_val))\n", "            if val_loss <= best_loss:\n", "                best_loss=val_loss\n", "                if verbose:\n", "                    print(f\"\u2b0a{val_loss:.3g}\", end=\"\")\n", "                save_as_pickle(f\"{folder}/model_param\",model_param)\n", "                save_as_str(f\"{folder}/best_loss\",best_loss)\n", "            else:\n", "                if verbose:\n", "                    print(\".\",end=\"\")\n", "        if verbose:\n", "            print(\"| end of the optimization loop.\")\n", "        return best_loss"], "metadata": {"id": "vcg52BBsLfNt", "executionInfo": {"status": "ok", "timestamp": 1755812195536, "user_tz": -120, "elapsed": 15, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 11, "outputs": []}, {"cell_type": "markdown", "source": ["## Les entrainements"], "metadata": {"id": "AmtCHdzXoLDg"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Entrainement pour 1 hyper-param\u00e8tre\n", "\n"], "metadata": {"id": "bqzpIzvZkArI"}, "outputs": []}, {"cell_type": "code", "source": ["def one_training(folder):\n", "    # noinspection PyDictCreation\n", "    hyper_param = {\"n_layer\": 2, \"layer_size\": 32,\"batch_size\":512,\"learning_rate\":1e-3,\"activation_name\":\"relu\"}\n", "\n", "    #Pour que ce ne soit pas un r\u00e9-entrainement.\n", "    shutil.rmtree(folder,ignore_errors=True)\n", "    AgentMini.train(folder,hyper_param,20,verbose=True)"], "metadata": {"id": "DJHIcfsFkTiU", "executionInfo": {"status": "ok", "timestamp": 1755812337484, "user_tz": -120, "elapsed": 40, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": ["folder=\"data/mon_premier_test\"\n", "one_training(folder)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "-EnE4NaqkP6z", "executionInfo": {"status": "ok", "timestamp": 1755812340920, "user_tz": -120, "elapsed": 1249, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "6518dfcc-374f-41d5-be1c-1371dd324380"}, "execution_count": 18, "outputs": []}, {"cell_type": "code", "source": ["def eval_training(folder):\n", "    result=AgentMini.load(folder)\n", "    fig, axs = plt.subplots(1, 1, sharex=\"all\")\n", "    Y_pred=result.model_call(result.model_param,X)\n", "    axs.plot(X,Y_pred)\n", "    axs.plot(X,Y)\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"id": "RzWKWJ8bkOQu", "executionInfo": {"status": "ok", "timestamp": 1755812337803, "user_tz": -120, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": ["eval_training(folder)"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 487}, "id": "fePMH150kjTs", "executionInfo": {"status": "ok", "timestamp": 1755812352892, "user_tz": -120, "elapsed": 223, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "bef8541c-8246-4d4e-c31e-3d118cdd36c4"}, "execution_count": 19, "outputs": []}, {"cell_type": "markdown", "source": ["\u21d1 pas terrible"], "metadata": {"id": "plEOl9ERn1jl"}, "outputs": []}, {"cell_type": "markdown", "source": ["### Une rechercher en grille"], "metadata": {"id": "1IABalR0Li0d"}, "outputs": []}, {"cell_type": "code", "source": ["def manual_loop(mother_folder):\n", "    # noinspection PyDictCreation\n", "    hyper_params = [\n", "        {\"n_layer\": 2, \"layer_size\": 32},\n", "        {\"n_layer\": 3, \"layer_size\": 32},\n", "        {\"n_layer\": 4, \"layer_size\": 32}\n", "    ]\n", "    for hyper_param in hyper_params:\n", "        hyper_param[\"batch_size\"] = 512\n", "        # noinspection PyTypeChecker\n", "        hyper_param[\"learning_rate\"] = 1e-3\n", "        # noinspection PyTypeChecker\n", "        hyper_param[\"activation_name\"] = \"relu\"\n", "\n", "    for i,hyper_param in enumerate(hyper_params):\n", "        folder=f\"{mother_folder}/test_{i}\"\n", "        shutil.rmtree(folder,ignore_errors=True)\n", "        AgentMini.train(folder,hyper_param,20,verbose=True)"], "metadata": {"id": "Bdb8XWc6Lm3S", "executionInfo": {"status": "ok", "timestamp": 1755812510129, "user_tz": -120, "elapsed": 42, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 24, "outputs": []}, {"cell_type": "code", "source": ["manual_loop(\"data/manual_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "JoiYUnCUL1BA", "executionInfo": {"status": "ok", "timestamp": 1755812530429, "user_tz": -120, "elapsed": 5222, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "b320c46f-9c06-43bf-b079-1df126a28147"}, "execution_count": 25, "outputs": []}, {"cell_type": "code", "source": ["def hyper_param_to_str(hyper_param):\n", "    return f\"bs:{hyper_param['batch_size']},n_lay:{hyper_param['n_layer']},lay_size:{hyper_param['layer_size']},lr:{hyper_param['learning_rate']:.3g}\"\n"], "metadata": {"id": "ggt7XHk_k2OH", "executionInfo": {"status": "ok", "timestamp": 1755812537987, "user_tz": -120, "elapsed": 41, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 26, "outputs": []}, {"cell_type": "code", "source": ["def eval_trainings(mother_folder):\n", "    folders=list(os.listdir(mother_folder))\n", "    loss_results=[]\n", "    for i,_folder in enumerate(folders):\n", "        folder=f\"{mother_folder}/{_folder}\"\n", "        result=AgentMini.load(folder)\n", "        loss_results.append((result.best_loss,result))\n", "    loss_results=sorted(loss_results,key=lambda a:a[0])\n", "    results=[a[1] for a in loss_results]\n", "    ni = 3\n", "    some_results=[results[0],results[len(results)//2],results[-1]]\n", "    fig, axs = plt.subplots(ni, 1, sharex=\"all\", figsize=(6, ni * 4))\n", "    titles=[\"best\",\"intermediate\",\"worst\"]\n", "\n", "    for i,result in enumerate(some_results):\n", "        Y_pred=result.model_call(result.model_param,X)\n", "        axs[i].plot(X,Y_pred)\n", "        axs[i].plot(X,Y)\n", "        axs[i].set_title(titles[i]+':'+hyper_param_to_str(result.hyper_param))\n", "    fig.tight_layout()\n", "    plt.show()"], "metadata": {"id": "dgiMgdvDk61c", "executionInfo": {"status": "ok", "timestamp": 1755812538962, "user_tz": -120, "elapsed": 4, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 27, "outputs": []}, {"cell_type": "code", "source": ["eval_trainings(\"data/manual_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "c4r18Lnuk-wR", "executionInfo": {"status": "ok", "timestamp": 1755812547870, "user_tz": -120, "elapsed": 986, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "2eb4d688-7ebe-418c-a434-3afd33388010"}, "execution_count": 28, "outputs": []}, {"cell_type": "markdown", "source": ["### Utilisation d'une libraire d'optimisation"], "metadata": {"id": "4d6Uzm8MLoqT"}, "outputs": []}, {"cell_type": "markdown", "source": ["Hyper-op est une librairie d'optimisation bayesienne. Ce genre d'optimisation est utile lorsque vous essayez de trouver le minimum (ou le maximum) d'une fonction dont l'\u00e9valuation prend du temps et dont vous ne connaissez pas la forme exacte (la \"bo\u00eete noire\").\n", "\n", "Ici on cherche le minimum de la fonction qui \u00e0 un hyper-param\u00e8tre associe la 'best-loss' obtenue pendant l'entrainement."], "metadata": {"id": "by0A5qPKn9IH"}, "outputs": []}, {"cell_type": "code", "source": ["def hyperop_loop(mother_folder):\n", "    n_epoch=20\n", "    def objective(hyper_param):\n", "        #un nome de fichier par rapport au temps\n", "        #attention,il faut que les trainings durent plus d'une seconde\n", "        n_second=str(time.time()).split(\".\")[0][5:]\n", "        folder=f\"{mother_folder}/test_{n_second}\"\n", "        return AgentMini.train(folder,hyper_param,n_epoch,False)\n", "\n", "    from hyperopt import hp,fmin, tpe, space_eval\n", "    space = {\n", "        'batch_size': hp.choice('batch_size', [128,256,512]),\n", "        'n_layer': hp.choice('n_layer', [2,3,4]),\n", "        'layer_size': hp.choice('layer_size', [64,128,256]),\n", "        'activation_name':'relu',\n", "        'learning_rate':hp.loguniform('learning_rate',np.log(5e-4),np.log(1e-2))\n", "    }\n", "    best = fmin(objective, space, algo=tpe.suggest, max_evals=10)\n", "    print(\"best hyper_parameter found:\")\n", "    print(space_eval(space, best))"], "metadata": {"id": "ByUpcI1nLsG7", "executionInfo": {"status": "ok", "timestamp": 1755812632300, "user_tz": -120, "elapsed": 3, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}}, "execution_count": 30, "outputs": []}, {"cell_type": "code", "source": ["hyperop_loop(\"data/hyperop_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/"}, "id": "a-5ndD8YMJ9M", "executionInfo": {"status": "ok", "timestamp": 1755812661022, "user_tz": -120, "elapsed": 28339, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "c9a89e28-e382-4a57-b135-5c6f4db0d190"}, "execution_count": 31, "outputs": []}, {"cell_type": "code", "source": ["eval_trainings(\"data/hyperop_loop\")"], "metadata": {"colab": {"base_uri": "https://localhost:8080/", "height": 1000}, "id": "rsV3Z21SlzAs", "executionInfo": {"status": "ok", "timestamp": 1755812686445, "user_tz": -120, "elapsed": 1100, "user": {"displayName": "vincent vigon", "userId": "09456169185020192907"}}, "outputId": "1f2278df-2aa3-413a-e330-04293afbf26a"}, "execution_count": 32, "outputs": []}, {"cell_type": "markdown", "source": ["### Optimisation Bay\u00e9sienne (explication math\u00e9matique)\n", "\n", "\n", "Par Gemini (\u00e0 destinations des plus t\u00e9m\u00e9raires, ne sera pas \u00e9valu\u00e9).\n", "\n", "\n", "L'optimisation bay\u00e9sienne est une technique d'optimisation s\u00e9quentielle pour les fonctions bo\u00eete noire co\u00fbteuses \u00e0 \u00e9valuer. On cherche \u00e0 minimiser une fonction inconnue $f(x)$, o\u00f9 $x$ est un vecteur d'hyperparam\u00e8tres et $f(x)$ est la valeur de la fonction objectif (par exemple, la perte de validation) pour ces hyperparam\u00e8tres. L'\u00e9valuation de $f(x)$ est co\u00fbteuse.\n", "\n", "1.  **Mod\u00e8le de substitution (Surrogate Model):** On utilise g\u00e9n\u00e9ralement un processus Gaussien (GP) pour mod\u00e9liser $f(x)$. Un GP est caract\u00e9ris\u00e9 par une moyenne $\\mu(x)$ et une covariance (ou noyau) $k(x, x')$. Apr\u00e8s avoir \u00e9valu\u00e9 la fonction \u00e0 $n$ points $D_n = \\{(x_i, y_i)\\}_{i=1}^n$, o\u00f9 $y_i = f(x_i)$, le GP nous donne une distribution pr\u00e9dictive sur la valeur de $f$ \u00e0 un nouveau point $x^*$. Cette distribution pr\u00e9dictive est une distribution normale avec une moyenne $\\mu_n(x^*)$ et une variance $\\sigma_n^2(x^*)$, qui d\u00e9pendent des donn\u00e9es observ\u00e9es $D_n$ et de la fonction de covariance choisie.\n", "$$\n", "P(f(x^*) | D_n) = \\mathcal{N}(\\mu_n(x^*), \\sigma_n^2(x^*))\n", "$$\n", "La moyenne $\\mu_n(x^*)$ repr\u00e9sente la meilleure estimation de $f(x^*)$ bas\u00e9e sur les donn\u00e9es observ\u00e9es, et la variance $\\sigma_n^2(x^*)$ mesure l'incertitude de cette estimation.\n"], "metadata": {"id": "LxqYLSGCq25y"}, "outputs": []}, {"cell_type": "markdown", "metadata": {"id": "4d3923f0"}, "source": ["\n", "\n", "2.  **Fonction d'acquisition (Acquisition Function):** Une fonction d'acquisition $a(x)$ est d\u00e9finie en utilisant le mod\u00e8le de substitution pour quantifier l'int\u00e9r\u00eat d'\u00e9valuer la fonction bo\u00eete noire au point $x$. L'objectif est de maximiser $a(x)$. Une fonction d'acquisition courante est l'**am\u00e9lioration attendue (Expected Improvement - EI)**. Si $y_{min}$ est la meilleure valeur observ\u00e9e jusqu'\u00e0 pr\u00e9sent ($y_{min} = \\min \\{y_i\\}_{i=1}^n$), l'am\u00e9lioration au point $x$ est d\u00e9finie comme $I(x) = \\max(y_{min} - f(x), 0)$. L'EI est l'esp\u00e9rance de cette am\u00e9lioration par rapport \u00e0 la distribution pr\u00e9dictive du GP sur $f(x)$:\n", "$$\n", "EI(x) = E[\\max(y_{min} - f(x), 0) | D_n]\n", "$$\n", "L'EI peut \u00eatre calcul\u00e9e analytiquement pour un GP. Si $f(x) \\sim \\mathcal{N}(\\mu_n(x), \\sigma_n^2(x))$, alors :\n", "$$\n", "EI(x) = \\sigma_n(x) (\\phi(Z) + Z\\Phi(Z))\n", "$$\n", "o\u00f9 $Z = \\frac{y_{min} - \\mu_n(x)}{\\sigma_n(x)}$, $\\phi$ est la fonction de densit\u00e9 de probabilit\u00e9 de la loi normale standard, et $\\Phi$ est sa fonction de r\u00e9partition cumulative.\n", "La fonction EI favorise les points o\u00f9 la moyenne pr\u00e9dictive est faible (potentiellement de nouvelles meilleures valeurs) et les points o\u00f9 l'incertitude est \u00e9lev\u00e9e (exploration de r\u00e9gions inconnues).\n", "\n", "\n", "3.  **Processus d'optimisation:**\n", "    *   Initialiser avec quelques points d'\u00e9valuation.\n", "    *   \u00c0 chaque it\u00e9ration :\n", "        *   Mettre \u00e0 jour le GP bas\u00e9 sur toutes les donn\u00e9es \u00e9valu\u00e9es.\n", "        *   Trouver le point $x_{next}$ qui maximise la fonction d'acquisition $a(x)$. Ceci est un probl\u00e8me d'optimisation plus simple que l'optimisation de $f(x)$ car nous avons une expression analytique pour $a(x)$ et ses d\u00e9riv\u00e9es.\n", "        *   \u00c9valuer la fonction bo\u00eete noire au point $x_{next}$ pour obtenir $y_{next} = f(x_{next})$.\n", "        *   Ajouter $(x_{next}, y_{next})$ aux donn\u00e9es \u00e9valu\u00e9es $D_n$.\n", "    *   R\u00e9p\u00e9ter jusqu'\u00e0 la convergence ou un nombre maximal d'it\u00e9rations.\n", "\n", "En r\u00e9sum\u00e9, l'optimisation bay\u00e9sienne utilise un mod\u00e8le probabiliste pour approximer la fonction co\u00fbteuse \u00e0 \u00e9valuer et une fonction d'acquisition pour choisir intelligemment les points \u00e0 \u00e9valuer ensuite, en \u00e9quilibrant exploration et exploitation. Cela permet de trouver de bons optimums avec un nombre d'\u00e9valuations de la fonction bo\u00eete noire souvent beaucoup plus faible qu'avec d'autres m\u00e9thodes."], "outputs": []}, {"cell_type": "markdown", "source": ["##Le d\u00e9fi prog\n", "\n", "\n", "* Une am\u00e9lioration possible dans l'agent est de stock\u00e9 aussi l'optimisateur-state. Ainsi si l'on red\u00e9marre l'entrainement, l'optimiseur sera d\u00e9j\u00e0 \u00e9chauff\u00e9.\n", "\n", "\n", "* Notre algorithme a un d\u00e9faut: si la librairie hyperop tire 2 fois un m\u00eame hyper-param\u00e8tre, alors il sera r\u00e9-entrain\u00e9. Il va alors avoir un super score artificiellement. Corrigez ce probl\u00e8me.\n", "\n", "\n", "* Cette agent 'Mini' est fait pour \u00eatre copi\u00e9-coller dans vos diff\u00e9rents projets et am\u00e9lir\u00e9. Par exemple, il pourrait aussi stock\u00e9 le temps pris par l'entrainement. Et on pourrait alors ajouter un score 'loss*temps-d'entrainement' qui serait plus honn\u00e8te pour les petits mod\u00e8les. Ou alors on peut faire les entrainements au chrono (ex: 1 minute chacun).\n", "\n", "\n", "Choisissez l'item ci-dessus qui vous inspire le plus, et codez-le.\n", "\n", "\n", "\n"], "metadata": {"id": "dyU9WWxfr6yE"}, "outputs": []}]}